<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=ISO-8859-1" />
<meta name="DOI" content="10.1045/november14-murray-rust" />
<meta name="description" content="D-Lib Magazine" /> 
<meta name="keywords" content="AMI-Diagram, Converting Graphics Primatives, XML" />
<link rel="metadata" href="11murray-rust.meta.xml" />
<link rel="metadata" href="../11bib.meta.bib" />
<link rel="metadata" href="../11ris.meta.ris" />
<link href="../../../style/style1.css" rel="stylesheet" type="text/css" />
<title>AMI-diagram: Mining Facts from Images</title>
</head>

<body>
<form action="https://www.dlib.org/cgi-bin/search.cgi" method="get">

<table width="100%" border="0" cellpadding="0" cellspacing="0" bgcolor="#2b538e">
<tr>
<td><img src="../../../img2/space.gif" alt="" width="10" height="2" /></td></tr>
</table>

<table width="100%" border="0" cellpadding="0" cellspacing="0">
<tr>
<td valign="bottom" colspan="4" align="right" bgcolor="#4078b1">

<table border="0">
<tr>
<td align="right" class="search"><img src="../../../img2/search2.gif" alt="" width="51" height="20" align="middle" />Search D-Lib:</td>

<td>
<input type="text" name="words" value="" size="25" />
</td>

<td align="left" valign="middle">
<input type="submit" name="search" value="Go!" />
<input type="hidden" name="config" value="htdig" />
<input type="hidden" name="restrict" value="" />
<input type="hidden" name="exclude" value="" /> 
</td>
</tr>
</table>

</td></tr></table>

<table width="100%" border="0" cellpadding="0" cellspacing="0">
<tr>
<td valign="bottom" colspan="4">

<table width="100%" border="0" cellpadding="0" cellspacing="0" bgcolor="#e04c1e" id="outer" summary="Main Table">
<tr>
<td><img src="../../../img2/space.gif" alt="" width="10" height="1" /></td></tr>
</table>

<table width="100%" border="0" cellpadding="0" cellspacing="0" bgcolor="#F6F6F6" id="bannertable">
  <tr>
    <td width="830" bgcolor="#4078b1" class="backBannerImage" align="left"><img src="../../../img2/D-Lib-blocks.gif" alt="D-Lib Magazine" width="450" height="100" border="0" /></td>
  </tr>
  <tr>
    <td width="830" bgcolor="#e04c1e"><img src="../../../img2/transparent.gif" alt="spacer" height="1" /></td>
  </tr>
  <tr>
    <td width="830" bgcolor="#eda443" align="left"><img src="../../../img2/magazine.gif" alt="The Magazine of Digital Library Research" width="830" height="24" border="0" /></td>
  </tr>
  <tr>
    <td width="830" bgcolor="#e04c1e"><img src="../../../img2/transparent.gif" alt="spacer" height="1" /></td>
   </tr>
</table>

<table width="100%" border="0" cellpadding="0" cellspacing="0" id="navtable">
  <tr>
    <td width="5" height="20" bgcolor="#2b538e">&nbsp;</td>
    <td width="24" height="20" bgcolor="#2b538e"><img src="../../../img2/transparent.gif" alt="" width="24" height="20" /></td>
    <td height="20" align="left" bgcolor="#2b538e" class="navtext" nowrap="nowrap"><a href="../../../dlib.html">HOME</a>&nbsp;|&nbsp;<a href="../../../about.html">ABOUT D-LIB</a>&nbsp;|&nbsp;<a href="../../../contents.html" class="navtext">CURRENT ISSUE</a>&nbsp;|&nbsp;<a href="../../../back.html">ARCHIVE</a>&nbsp;|&nbsp;<a href="../../../author-index.html">INDEXES</a>&nbsp;|&nbsp;<a href="../../../groups.html">CALENDAR</a>&nbsp;|&nbsp;<a href="../../author-guidelines.html">AUTHOR GUIDELINES</a>&nbsp;|&nbsp;<a href="https://www.dlib.org/mailman/listinfo/dlib-subscribers">SUBSCRIBE</a>&nbsp;|&nbsp;<a href="../../letters.html">CONTACT D-LIB</a></td>
    <td width="5" height="20" bgcolor="#2b538e">&nbsp;</td>
  </tr>
</table>

<table width="100%" border="0" cellpadding="0" cellspacing="0">
  <tr>
    <td width="55" height="1" bgcolor="#e04c1e"><img src="../../../img2/space.gif" alt="transparent image" width="1" height="1" /></td></tr>
</table>

<!-- CONTENT TABLE -->
<table width="100%" border="0" align="center" cellpadding="0" cellspacing="0">
  <tr>
  <td>
 
<!-- BEGIN MAIN CONTENT TABLE -->

<table width="100%" border="0" cellspacing="0" cellpadding="10" bgcolor="#ffffff">
<tr>

<td width="10"><img src="../../../img2/space.gif" alt="" width="1" height="1" /></td>

<td valign="top"> 

<h3 class="blue-space">D-Lib Magazine</h3>
<p class="blue">November/December 2014<br />
Volume 20, Number 11/12<br />
<a href="../11contents.html">Table of Contents</a>
</p> 

<div class="divider-full">&nbsp;</div>

<h3 class="blue-space">AMI-diagram: Mining Facts from Images</h3>

<p class="blue">
Peter Murray-Rust and Richard Smith-Unna<br />
University of Cambridge, UK<br />
{pm286, rds45}&#064;cam.ac.uk<br /><br />

Ross Mounce<br />
University of Bath, UK<br />
ross.mounce&#064;gmail.com

<br /><br />doi:10.1045/november14-murray-rust
 </p>

<div class="divider-full">&nbsp;</div>

<p class="blue"><a href="11murray-rust.print.html" class="fc">Printer-friendly Version</a></p>

<div class="divider-full">&nbsp;</div>

 <!-- Abstract or TOC goes here --> 

<h3 class="blue">Abstract</h3>

<p class="blue">
AMI-Diagram is a tool for mining facts from diagrams, and converting the graphics primitives into XML.  Targets include X-Y plots, barcharts, chemical structure diagrams and phylogenetic trees.  Part of the ContentMine framework for automatically extracting science from the published literature, AMI can ingest born-digital diagrams either as latent vectors, pixel diagrams or scanned documents. For high-quality/resolution diagrams the process is automatic; command line parameters can be used for noisy or complex diagrams. This article provides on overview of the tool which is currently being deployed to alpha-testers, especially in chemistry and phylogenetics.</p>

<p class="blue">Keywords: AMI-Diagram, Converting Graphics Primatives, XML</p>

<!-- Article goes next --> 

<div class="divider-full">&nbsp;</div>
<h3>1. Introduction</h3>

<p>There are at least 10 million diagrams published in the scientific literature each year and many of them represent factual information. AMI-Diagram is a flexible tool which can mine facts from diagrams and convert the graphics primitives into XML. The targets include X-Y plots, barcharts, chemical structure diagrams and phylogenetic trees. AMI can ingest born-digital diagrams either as latent vectors (converted from Postscript), pixel diagrams (PNGs and JPEGs) or scanned documents. For high-quality/resolution diagrams the process is automatic; command line parameters can be used for noisy or complex diagrams. AMI is part of the <a href="http://contentmine.org">ContentMine</a> framework for automatically extracting science from the published literature.</p>

<div class="divider-full">&nbsp;</div>
<h3>2. Background</h3>

<p>Over 1 million scientific articles are published yearly and a similar amount of theses and grey literature [<a href="11murray-rust.html#1">1</a>]. Many contain diagrams, such as graphs or domain-specific objects, representing factual information and often this is the primary way of communicating the information contained (e.g. molecular structure diagrams). Almost all diagrams are now born digital (i.e. the output is written directly from a program to file). The originating programs include generic plotting packages (GNUPlot, R, Excel), specialist editors such as JChempaint or Chemdraw for molecules, or are generated directly from instruments (e.g. spectra). The plots are usually high resolution, either scalable vectors + text (such as SVG or Postscript derivatives) or large pixel maps, often
between 1 million and 20 million pixels.</p>

<p>Since most scientific data is never published (estimates are often &gt; 80% loss; [<a href="11murray-rust.html#2">2</a>]), extraction of data from images can be a vital source of semantic data. Traditional, labour intensive approaches include pencil and ruler, or cutting out peaks and weighing the paper and these are still, unfortunately, used today. Authors are reluctant to save data publicly; the <a href="http://treebase.org/treebaseweb/home.html">Treebase</a> database of phylogenetic trees only contains 4% of published trees.</p>

<div class="divider-full">&nbsp;</div>
<h3>3. Overview</h3>

<p>Converting a semantic object to vector or pixel graphics loses most of the information. However in some domains it is possible to combine computer vision techniques with machine-learning or rules/heuristics to recover the likely generating object. Moreover, ambiguity can often be resolved by lookup against public semantic data (e.g. <a href="http://dbpedia.org">dbpedia.org</a>) or recomputing the object. We have therefore developed image and vector processing technology which can reconstruct semantic data from a wide range of diagrams. Users may start with PDF documents, PNG or JPEG diagrams, or other sources of vectors (Word or Powerpoint EWF, PostScript, etc.). AMI is a work-in-progress being deployed to alpha-testers especially in chemistry and phylogenetics.</p>

<p>The overall process is:</p>

<ol>
	<li style="padding-bottom: .5em;">Dissect and restructure PDFs and extract images.</li>

	<li style="padding-bottom: .5em;">Transform raw images into SVG.</li>

	<li style="padding-bottom: .5em;">Associate SVG with extracted captions to add semantics and classification.</li>

	<li style="padding-bottom: .5em;">From the SVG primitives, build domain-independent mid-level graphics objects (boxes, circles, grids, annotations, symbols, etc.)</li>

	<li>Use domain-specific heuristics from the classification to create high-level semantic objects (x-y plots, molecular structures, phylogenetic trees, maps, etc.)</li>
</ol>

<p>There is often an advantage in knowing the style of a journal or generating program. Collaboration is very useful here and the AMI framework is developed so that users can add in plugins (AMI uses the Visitor pattern). A Visitor can be tailored to a specific journal or domain of science.</p>

<div class="divider-full">&nbsp;</div>
<h3>4. Interpreting PDFs</h3>

<p>PDFs are made up of three streams: characters with code points or their glyphs; paths (lines and curves); and pixel images.</p>

<p>We use <a href="http://pdfbox.org">PDFBox</a> from Apache which provides these, but most STM publishers do not use Unicode fonts, and it is formally impossible to identify many character. We use a per-journal lookup which is constructed by expert classification. There is often some difficulty in identifying the pixel images and they may be layered with character codes or paths. We translate characters and paths to SVG which is an excellent intermediate format. We generally keep the images as PNGs as the SVG representation is verbose.</p>

<div class="divider-full">&nbsp;</div>
<h3>5. Interpreting pixel maps</h3>

<p>We have tried many methods including Hough line transforms, erosion (e.g BoofCV), and histogram equalisation. The following are the problems and approaches that we have found most appropriate for modern scientific articles. We warn that articles before ca. 2000 may have poor typography with less systematic presentation, and this makes it harder to
create simple heuristics.</p>

<ol>
	<li style="padding-bottom: .5em;"><b>Colours</b>. Binary (black and white only) are simplest; gradients and dotted regions can cause problems. AMI separates colours into complementary pixel maps and can process each separately. Recombination is at the domain level (e.g. differently coloured subtrees).</li>

	<li style="padding-bottom: .5em;"><b>Noise</b> (common in scanned documents), grayscales and antialiasing (very common) mean that background / threshold levels are sometimes critical. AMI can adjust these either from human control or a simple adaptive optimisation.</li>

	<li style="padding-bottom: .5em;"><b>Bleeding and cavitation</b>. Graphics primitives which are close often "bleed" into a single object; faint primitives may have holes. Where glyphs interbleed we separate them heuristically (by comparion with target glyphs)</li>

	<li style="padding-bottom: .5em;"><b>Thinning</b>. AMI reduces lines and strokes to single pixel width using the Zhang-Suen approach and then tidies some redundant pixels.</li>

	<li style="padding-bottom: .5em;"><b>Character recognition (OCR)</b>. Traditional OCR methods (machine learning, correlations, moments and Mahalanobis) don't work well with scientific characters which are often rotated, isolated, have variable fonts, italic and/or bold and cover a wide range of Unicode (maths, Greek, symbols). We have developed a topological approach which is robust to distortion and scaling and can be combined with classical methods (bitwise correlation).</li>

	<li style="padding-bottom: .5em;"><b>Separation of objects</b>. We identify objects by floodfill or by expanding borders. Overlap of different colours is often tractable especially where these are primitives (lines, circles); we can sometimes resolve overlapping objects by creating a dictionary of primitives (e.g. symbols).</li>

	<li><b>Segmentation</b>. PDFs and pixels do not support higher level primitives and AMI uses Douglas-Peuckert segmentation to approximate curved strokes, where possible trying to fit them to circles.</li>
</ol>

<div class="divider-full">&nbsp;</div>
<h3>6. Reconstructing objects</h3>

<p>Many segmented objects are suitable for domain-specific interpretation. For example:</p>

<ol start="1">
	<li style="padding-bottom: .5em;"><b>Chemical structures</b> are lines and characters, with occasional circles; we often approach 100% recall/ precision for vector or good pixel diagrams. We have successfully converted thousands of molecules, with annotations, and also chemical reactions into Chemical Markup Language (e.g. Figure A).</li>
</ol>

<div align="center">
<img src="murray-rust-fig1A.png" alt="murray-rust-fig1" width="400" height="250" class="border" vspace="10" />
<p class="indentQuote"><i>Figure A: A photograph of a chemical molecule on a poster taken with a mobile phone camera, showing varying backgrounds, line broadening and skewing. In spite of this it is automatically and accurately converted to a semantic molecule with formula C18 H18 N3 O in under a second.</i></p>
</div>

<div class="divider-gray">&nbsp;</div>

<ol start="2">
	<li style="padding-bottom: .5em;"><b>Phylogenetic trees</b> are often tractable, consisting of a single connected trees with labels close to the tip. We can process both rooted (orthogonal and circular, e.g. Figure B) and unrooted trees. For simple diagrams precision is often 100%.</li>
</ol>

<div align="center">
<img src="murray-rust-fig1B.png" alt="murray-rust-fig2" width="400" height="378" vspace="10" />
<p class="indentQuote"><i>Figure B: This circular tree is separated from its characters and correctly converted to the semantic Newick representation (image from  <a href="https://doi.org/10.1371/journal.pone.0036933">http://doi.org/10.1371/journal.pone.0036933</a>, figure 1).</i></p>
</div>

<div class="divider-gray">&nbsp;</div>

<ol start="3">
	<li><b>X-Y plots</b> are often very tractable (e.g. Figure C), again with high precision; they contain: X- and/or Y- axes each consisting of lines with tick marks, scales, quantities and units; symbols or points, perhaps with error bars and legends for each type; and an overall title.</li>
</ol>

<div align="center">
<img src="murray-rust-fig1C.png" alt="murray-rust-fig3" width="513" height="308" class="border" vspace="10" />
<p class="indentQuote"><i>Figure C: This X-Y plot is correctly decomposed into X and Y coordinates of data points and size of the corresponding error bars (image from
<a href="https://doi.org/10.1371/journal.pone.0095565">http://doi.org/10.1371/journal.pone.0095565</a>, figure 2). It is possible to create a CSV file directly from this.</i></p>
</div>

<div class="divider-full">&nbsp;</div>
<h3>7. Current status</h3>

<p>AMI is <a href="https://bitbucket.org/petermr">open source</a> under the Apache 2 license and written in pure Java. It can be deployed as a command-line option including recursion over directories and ingestion of web streams. It ingests PDF, SVG, XML, HTML and image formats and usually takes &lt;1 second per image (some documents include tens of such). It has a plugin architecture using the Visitor pattern so that domain experts can create their own image analysers without having to also write the more basic tools described here. We are actively seeking collaborators.</p>

<div class="divider-full">&nbsp;</div>
<h3>Acknowledgements</h3>

<p>Peter Murray-Rust thanks The Shuttleworth Foundation for a Fellowship and Grant and Ross Mounce thanks BBSRC for support for the PLUTo project</p>

<div class="divider-full">&nbsp;</div>
<h3>References</h3>

<p><a name="1">[1]</a> Chalmers, I. and Glasziou, P. 2009. <a href="http://www.thelancet.com/journals/lancet/article/PIIS0140-6736(09)60329-9/fulltext">Avoidable waste in the production and reporting of research evidence</a>. <i>The Lancet</i>. 374, 9683 (Jul. 2009), 86&#151;89.</p>

<p><a name="2">[2]</a> Glasziou, P. 2014. <a href="http://www.plosmedicine.org/article/info%3Adoi%2F10.1371%2Fjournal.pmed.1001651">The role of open access in reducing waste in medical research</a>. <i>PLoS Med</i>. 11, 5 (May 2014), e1001651.</p>

<div class="divider-full">&nbsp;</div>
<h3>About the Authors</h3>

<table border="0"  cellpadding="6" bgcolor="#FFFFFF"> 
<tr>
<td align="center"><img src="murray-rust.png" class="border" alt="murray-rust" width="100" height="125" /></td>
<td>
<p class="blue"><b>Peter Murray-Rust </b> is Reader in Molecular Informatics at the University of Cambridge, and Senior Research Fellow of Churchill College, Cambridge. He was educated at Bootham School and Balliol College, Oxford and obtained a Doctor of Philosophy. His research interests have involved the automated analysis of data in scientific publications, creation of virtual communities and the Semantic Web. In 2002, Dr. Murray-Rust and his colleagues proposed an electronic repository for unpublished chemical data called the World Wide Molecular Matrix (WWMM). In 2014 he was awarded a Fellowship by the Shuttleworth Foundation to develop the automated mining of science from the literature. In addition to his work in chemistry, Murray-Rust is also known for his support of open access and open data.</p>
</td>
</tr>
</table>

<div class="divider-full">&nbsp;</div>

<table border="0"  cellpadding="6" bgcolor="#FFFFFF"> 
<tr>
<td>
<p class="blue"><b>Richard Smith-Unna</b> is a PhD student (Plant Sciences) at University of Cambridge and co-founder of Solvers.io.</p>
</td>
</tr>
</table>

<div class="divider-full">&nbsp;</div>
<table border="0"  cellpadding="6" bgcolor="#FFFFFF"> 
<tr>
<td align="center"><img src="mounce.png" class="border" alt="mounce" width="100" height="103" /></td>
<td>
<p class="blue"><b>Ross Mounce</b> Ross Mounce is a postdoctoral researcher at the University of Bath. His research is on phylogenetic tree data and associated metadata extraction from the literature. He is council member of the <a href="http://systass.org/">Systematics Association</a>, subject editor for <a href="http://biodiversitydatajournal.com/">Biodiversity Data Journal</a> (Pensoft), and organising committee member of the <a href="http://www.opencon2014.org/">OpenCon 2014</a> meeting.</p>
</td>
</tr>
</table>

<div class="divider-full">&nbsp;</div>

 <!-- Standard Copyright line here  -->

<div class="center">

<p class="footer">Copyright &copy; 2014 Peter Murray-Rust, Richard Smith-Unna and Ross Mounce</p>  
  </div>
</td>
 </tr>
</table>

<table width="100%" border="0" align="center" cellpadding="0" cellspacing="0">
  <tr>
    <td height="1" bgcolor="#2b538e"><img src="../../../img2/transparent.gif" alt="transparent image" width="100" height="2" /></td>
  </tr>
</table>

</td></tr></table>
</td></tr></table>
</form>

</body>
</html>