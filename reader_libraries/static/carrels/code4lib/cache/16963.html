<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN"
"http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en-US">
	<head>
		<meta http-equiv="Content-Type" content="text/html; charset=UTF-8" />

		<title>The Code4Lib Journal &#8211; Designing Digital Discovery and Access Systems for Archival Description</title>

		<meta name="viewport" content="width=device-width, initial-scale=1" />
		<meta name="generator" content="WordPress 6.8.1" /> <!-- leave this for stats -->
    <link rel="shortcut icon" href="../wp-content/themes/c4lj-theme/images/favicon.ico" />
		<link rel="stylesheet" href="../wp-content/themes/c4lj-theme/style.css" type="text/css" media="screen, print" />
		<!--[if lte IE 7]>
		<link rel="stylesheet" href="https://journal.code4lib.org/wp-content/themes/c4lj-theme/fix-ie7.css" type="text/css" media="screen" />
		<![endif]-->
		<!--[if lte IE 6]>
		<link rel="stylesheet" href="https://journal.code4lib.org/wp-content/themes/c4lj-theme/fix-ie6.css" type="text/css" media="screen" />
		<![endif]-->
		<link rel="stylesheet" href="../wp-content/themes/c4lj-theme/print.css" type="text/css" media="print" />
		<link rel="alternate" type="application/rss+xml" title="The Code4Lib Journal Syndication Feed" href="http://feeds.feedburner.com/c4lj" />
		<link rel="pingback" href="https://journal.code4lib.org/xmlrpc.php" />

<!-- Google Scholar Stuff -->
	<meta name="citation_title" content="Designing Digital Discovery and Access Systems for Archival Description">
 <meta name="citation_author" content="Gregory Wiedeman">
<meta name="citation_publication_date" content="2023/01/20">
	<meta name="citation_journal_title" content="Code4Lib Journal">
		<meta name="citation_issue" content="55">
<!-- end  Google Scholar Stuff -->

<meta name='robots' content='max-image-preview:large' />
	<style>img:is([sizes="auto" i], [sizes^="auto," i]) { contain-intrinsic-size: 3000px 1500px }</style>
	<link rel="alternate" type="application/rss+xml" title="The Code4Lib Journal &raquo; Designing Digital Discovery and Access Systems for Archival Description Comments Feed" href="16963/feed" />
<script type="text/javascript">
/* <![CDATA[ */
window._wpemojiSettings = {"baseUrl":"https:\/\/s.w.org\/images\/core\/emoji\/15.1.0\/72x72\/","ext":".png","svgUrl":"https:\/\/s.w.org\/images\/core\/emoji\/15.1.0\/svg\/","svgExt":".svg","source":{"concatemoji":"https:\/\/journal.code4lib.org\/wp-includes\/js\/wp-emoji-release.min.js?ver=6.8.1"}};
/*! This file is auto-generated */
!function(i,n){var o,s,e;function c(e){try{var t={supportTests:e,timestamp:(new Date).valueOf()};sessionStorage.setItem(o,JSON.stringify(t))}catch(e){}}function p(e,t,n){e.clearRect(0,0,e.canvas.width,e.canvas.height),e.fillText(t,0,0);var t=new Uint32Array(e.getImageData(0,0,e.canvas.width,e.canvas.height).data),r=(e.clearRect(0,0,e.canvas.width,e.canvas.height),e.fillText(n,0,0),new Uint32Array(e.getImageData(0,0,e.canvas.width,e.canvas.height).data));return t.every(function(e,t){return e===r[t]})}function u(e,t,n){switch(t){case"flag":return n(e,"\ud83c\udff3\ufe0f\u200d\u26a7\ufe0f","\ud83c\udff3\ufe0f\u200b\u26a7\ufe0f")?!1:!n(e,"\ud83c\uddfa\ud83c\uddf3","\ud83c\uddfa\u200b\ud83c\uddf3")&&!n(e,"\ud83c\udff4\udb40\udc67\udb40\udc62\udb40\udc65\udb40\udc6e\udb40\udc67\udb40\udc7f","\ud83c\udff4\u200b\udb40\udc67\u200b\udb40\udc62\u200b\udb40\udc65\u200b\udb40\udc6e\u200b\udb40\udc67\u200b\udb40\udc7f");case"emoji":return!n(e,"\ud83d\udc26\u200d\ud83d\udd25","\ud83d\udc26\u200b\ud83d\udd25")}return!1}function f(e,t,n){var r="undefined"!=typeof WorkerGlobalScope&&self instanceof WorkerGlobalScope?new OffscreenCanvas(300,150):i.createElement("canvas"),a=r.getContext("2d",{willReadFrequently:!0}),o=(a.textBaseline="top",a.font="600 32px Arial",{});return e.forEach(function(e){o[e]=t(a,e,n)}),o}function t(e){var t=i.createElement("script");t.src=e,t.defer=!0,i.head.appendChild(t)}"undefined"!=typeof Promise&&(o="wpEmojiSettingsSupports",s=["flag","emoji"],n.supports={everything:!0,everythingExceptFlag:!0},e=new Promise(function(e){i.addEventListener("DOMContentLoaded",e,{once:!0})}),new Promise(function(t){var n=function(){try{var e=JSON.parse(sessionStorage.getItem(o));if("object"==typeof e&&"number"==typeof e.timestamp&&(new Date).valueOf()<e.timestamp+604800&&"object"==typeof e.supportTests)return e.supportTests}catch(e){}return null}();if(!n){if("undefined"!=typeof Worker&&"undefined"!=typeof OffscreenCanvas&&"undefined"!=typeof URL&&URL.createObjectURL&&"undefined"!=typeof Blob)try{var e="postMessage("+f.toString()+"("+[JSON.stringify(s),u.toString(),p.toString()].join(",")+"));",r=new Blob([e],{type:"text/javascript"}),a=new Worker(URL.createObjectURL(r),{name:"wpTestEmojiSupports"});return void(a.onmessage=function(e){c(n=e.data),a.terminate(),t(n)})}catch(e){}c(n=f(s,u,p))}t(n)}).then(function(e){for(var t in e)n.supports[t]=e[t],n.supports.everything=n.supports.everything&&n.supports[t],"flag"!==t&&(n.supports.everythingExceptFlag=n.supports.everythingExceptFlag&&n.supports[t]);n.supports.everythingExceptFlag=n.supports.everythingExceptFlag&&!n.supports.flag,n.DOMReady=!1,n.readyCallback=function(){n.DOMReady=!0}}).then(function(){return e}).then(function(){var e;n.supports.everything||(n.readyCallback(),(e=n.source||{}).concatemoji?t(e.concatemoji):e.wpemoji&&e.twemoji&&(t(e.twemoji),t(e.wpemoji)))}))}((window,document),window._wpemojiSettings);
/* ]]> */
</script>
<style id='wp-emoji-styles-inline-css' type='text/css'>

	img.wp-smiley, img.emoji {
		display: inline !important;
		border: none !important;
		box-shadow: none !important;
		height: 1em !important;
		width: 1em !important;
		margin: 0 0.07em !important;
		vertical-align: -0.1em !important;
		background: none !important;
		padding: 0 !important;
	}
</style>
<link rel='stylesheet' id='wp-block-library-css' href='../wp-includes/css/dist/block-library/style.min.css%3Fver=6.8.1.css' type='text/css' media='all' />
<style id='classic-theme-styles-inline-css' type='text/css'>
/*! This file is auto-generated */
.wp-block-button__link{color:#fff;background-color:#32373c;border-radius:9999px;box-shadow:none;text-decoration:none;padding:calc(.667em + 2px) calc(1.333em + 2px);font-size:1.125em}.wp-block-file__button{background:#32373c;color:#fff;text-decoration:none}
</style>
<style id='global-styles-inline-css' type='text/css'>
:root{--wp--preset--aspect-ratio--square: 1;--wp--preset--aspect-ratio--4-3: 4/3;--wp--preset--aspect-ratio--3-4: 3/4;--wp--preset--aspect-ratio--3-2: 3/2;--wp--preset--aspect-ratio--2-3: 2/3;--wp--preset--aspect-ratio--16-9: 16/9;--wp--preset--aspect-ratio--9-16: 9/16;--wp--preset--color--black: #000000;--wp--preset--color--cyan-bluish-gray: #abb8c3;--wp--preset--color--white: #ffffff;--wp--preset--color--pale-pink: #f78da7;--wp--preset--color--vivid-red: #cf2e2e;--wp--preset--color--luminous-vivid-orange: #ff6900;--wp--preset--color--luminous-vivid-amber: #fcb900;--wp--preset--color--light-green-cyan: #7bdcb5;--wp--preset--color--vivid-green-cyan: #00d084;--wp--preset--color--pale-cyan-blue: #8ed1fc;--wp--preset--color--vivid-cyan-blue: #0693e3;--wp--preset--color--vivid-purple: #9b51e0;--wp--preset--gradient--vivid-cyan-blue-to-vivid-purple: linear-gradient(135deg,rgba(6,147,227,1) 0%,rgb(155,81,224) 100%);--wp--preset--gradient--light-green-cyan-to-vivid-green-cyan: linear-gradient(135deg,rgb(122,220,180) 0%,rgb(0,208,130) 100%);--wp--preset--gradient--luminous-vivid-amber-to-luminous-vivid-orange: linear-gradient(135deg,rgba(252,185,0,1) 0%,rgba(255,105,0,1) 100%);--wp--preset--gradient--luminous-vivid-orange-to-vivid-red: linear-gradient(135deg,rgba(255,105,0,1) 0%,rgb(207,46,46) 100%);--wp--preset--gradient--very-light-gray-to-cyan-bluish-gray: linear-gradient(135deg,rgb(238,238,238) 0%,rgb(169,184,195) 100%);--wp--preset--gradient--cool-to-warm-spectrum: linear-gradient(135deg,rgb(74,234,220) 0%,rgb(151,120,209) 20%,rgb(207,42,186) 40%,rgb(238,44,130) 60%,rgb(251,105,98) 80%,rgb(254,248,76) 100%);--wp--preset--gradient--blush-light-purple: linear-gradient(135deg,rgb(255,206,236) 0%,rgb(152,150,240) 100%);--wp--preset--gradient--blush-bordeaux: linear-gradient(135deg,rgb(254,205,165) 0%,rgb(254,45,45) 50%,rgb(107,0,62) 100%);--wp--preset--gradient--luminous-dusk: linear-gradient(135deg,rgb(255,203,112) 0%,rgb(199,81,192) 50%,rgb(65,88,208) 100%);--wp--preset--gradient--pale-ocean: linear-gradient(135deg,rgb(255,245,203) 0%,rgb(182,227,212) 50%,rgb(51,167,181) 100%);--wp--preset--gradient--electric-grass: linear-gradient(135deg,rgb(202,248,128) 0%,rgb(113,206,126) 100%);--wp--preset--gradient--midnight: linear-gradient(135deg,rgb(2,3,129) 0%,rgb(40,116,252) 100%);--wp--preset--font-size--small: 13px;--wp--preset--font-size--medium: 20px;--wp--preset--font-size--large: 36px;--wp--preset--font-size--x-large: 42px;--wp--preset--spacing--20: 0.44rem;--wp--preset--spacing--30: 0.67rem;--wp--preset--spacing--40: 1rem;--wp--preset--spacing--50: 1.5rem;--wp--preset--spacing--60: 2.25rem;--wp--preset--spacing--70: 3.38rem;--wp--preset--spacing--80: 5.06rem;--wp--preset--shadow--natural: 6px 6px 9px rgba(0, 0, 0, 0.2);--wp--preset--shadow--deep: 12px 12px 50px rgba(0, 0, 0, 0.4);--wp--preset--shadow--sharp: 6px 6px 0px rgba(0, 0, 0, 0.2);--wp--preset--shadow--outlined: 6px 6px 0px -3px rgba(255, 255, 255, 1), 6px 6px rgba(0, 0, 0, 1);--wp--preset--shadow--crisp: 6px 6px 0px rgba(0, 0, 0, 1);}:where(.is-layout-flex){gap: 0.5em;}:where(.is-layout-grid){gap: 0.5em;}body .is-layout-flex{display: flex;}.is-layout-flex{flex-wrap: wrap;align-items: center;}.is-layout-flex > :is(*, div){margin: 0;}body .is-layout-grid{display: grid;}.is-layout-grid > :is(*, div){margin: 0;}:where(.wp-block-columns.is-layout-flex){gap: 2em;}:where(.wp-block-columns.is-layout-grid){gap: 2em;}:where(.wp-block-post-template.is-layout-flex){gap: 1.25em;}:where(.wp-block-post-template.is-layout-grid){gap: 1.25em;}.has-black-color{color: var(--wp--preset--color--black) !important;}.has-cyan-bluish-gray-color{color: var(--wp--preset--color--cyan-bluish-gray) !important;}.has-white-color{color: var(--wp--preset--color--white) !important;}.has-pale-pink-color{color: var(--wp--preset--color--pale-pink) !important;}.has-vivid-red-color{color: var(--wp--preset--color--vivid-red) !important;}.has-luminous-vivid-orange-color{color: var(--wp--preset--color--luminous-vivid-orange) !important;}.has-luminous-vivid-amber-color{color: var(--wp--preset--color--luminous-vivid-amber) !important;}.has-light-green-cyan-color{color: var(--wp--preset--color--light-green-cyan) !important;}.has-vivid-green-cyan-color{color: var(--wp--preset--color--vivid-green-cyan) !important;}.has-pale-cyan-blue-color{color: var(--wp--preset--color--pale-cyan-blue) !important;}.has-vivid-cyan-blue-color{color: var(--wp--preset--color--vivid-cyan-blue) !important;}.has-vivid-purple-color{color: var(--wp--preset--color--vivid-purple) !important;}.has-black-background-color{background-color: var(--wp--preset--color--black) !important;}.has-cyan-bluish-gray-background-color{background-color: var(--wp--preset--color--cyan-bluish-gray) !important;}.has-white-background-color{background-color: var(--wp--preset--color--white) !important;}.has-pale-pink-background-color{background-color: var(--wp--preset--color--pale-pink) !important;}.has-vivid-red-background-color{background-color: var(--wp--preset--color--vivid-red) !important;}.has-luminous-vivid-orange-background-color{background-color: var(--wp--preset--color--luminous-vivid-orange) !important;}.has-luminous-vivid-amber-background-color{background-color: var(--wp--preset--color--luminous-vivid-amber) !important;}.has-light-green-cyan-background-color{background-color: var(--wp--preset--color--light-green-cyan) !important;}.has-vivid-green-cyan-background-color{background-color: var(--wp--preset--color--vivid-green-cyan) !important;}.has-pale-cyan-blue-background-color{background-color: var(--wp--preset--color--pale-cyan-blue) !important;}.has-vivid-cyan-blue-background-color{background-color: var(--wp--preset--color--vivid-cyan-blue) !important;}.has-vivid-purple-background-color{background-color: var(--wp--preset--color--vivid-purple) !important;}.has-black-border-color{border-color: var(--wp--preset--color--black) !important;}.has-cyan-bluish-gray-border-color{border-color: var(--wp--preset--color--cyan-bluish-gray) !important;}.has-white-border-color{border-color: var(--wp--preset--color--white) !important;}.has-pale-pink-border-color{border-color: var(--wp--preset--color--pale-pink) !important;}.has-vivid-red-border-color{border-color: var(--wp--preset--color--vivid-red) !important;}.has-luminous-vivid-orange-border-color{border-color: var(--wp--preset--color--luminous-vivid-orange) !important;}.has-luminous-vivid-amber-border-color{border-color: var(--wp--preset--color--luminous-vivid-amber) !important;}.has-light-green-cyan-border-color{border-color: var(--wp--preset--color--light-green-cyan) !important;}.has-vivid-green-cyan-border-color{border-color: var(--wp--preset--color--vivid-green-cyan) !important;}.has-pale-cyan-blue-border-color{border-color: var(--wp--preset--color--pale-cyan-blue) !important;}.has-vivid-cyan-blue-border-color{border-color: var(--wp--preset--color--vivid-cyan-blue) !important;}.has-vivid-purple-border-color{border-color: var(--wp--preset--color--vivid-purple) !important;}.has-vivid-cyan-blue-to-vivid-purple-gradient-background{background: var(--wp--preset--gradient--vivid-cyan-blue-to-vivid-purple) !important;}.has-light-green-cyan-to-vivid-green-cyan-gradient-background{background: var(--wp--preset--gradient--light-green-cyan-to-vivid-green-cyan) !important;}.has-luminous-vivid-amber-to-luminous-vivid-orange-gradient-background{background: var(--wp--preset--gradient--luminous-vivid-amber-to-luminous-vivid-orange) !important;}.has-luminous-vivid-orange-to-vivid-red-gradient-background{background: var(--wp--preset--gradient--luminous-vivid-orange-to-vivid-red) !important;}.has-very-light-gray-to-cyan-bluish-gray-gradient-background{background: var(--wp--preset--gradient--very-light-gray-to-cyan-bluish-gray) !important;}.has-cool-to-warm-spectrum-gradient-background{background: var(--wp--preset--gradient--cool-to-warm-spectrum) !important;}.has-blush-light-purple-gradient-background{background: var(--wp--preset--gradient--blush-light-purple) !important;}.has-blush-bordeaux-gradient-background{background: var(--wp--preset--gradient--blush-bordeaux) !important;}.has-luminous-dusk-gradient-background{background: var(--wp--preset--gradient--luminous-dusk) !important;}.has-pale-ocean-gradient-background{background: var(--wp--preset--gradient--pale-ocean) !important;}.has-electric-grass-gradient-background{background: var(--wp--preset--gradient--electric-grass) !important;}.has-midnight-gradient-background{background: var(--wp--preset--gradient--midnight) !important;}.has-small-font-size{font-size: var(--wp--preset--font-size--small) !important;}.has-medium-font-size{font-size: var(--wp--preset--font-size--medium) !important;}.has-large-font-size{font-size: var(--wp--preset--font-size--large) !important;}.has-x-large-font-size{font-size: var(--wp--preset--font-size--x-large) !important;}
:where(.wp-block-post-template.is-layout-flex){gap: 1.25em;}:where(.wp-block-post-template.is-layout-grid){gap: 1.25em;}
:where(.wp-block-columns.is-layout-flex){gap: 2em;}:where(.wp-block-columns.is-layout-grid){gap: 2em;}
:root :where(.wp-block-pullquote){font-size: 1.5em;line-height: 1.6;}
</style>
<style id='akismet-widget-style-inline-css' type='text/css'>

			.a-stats {
				--akismet-color-mid-green: #357b49;
				--akismet-color-white: #fff;
				--akismet-color-light-grey: #f6f7f7;

				max-width: 350px;
				width: auto;
			}

			.a-stats * {
				all: unset;
				box-sizing: border-box;
			}

			.a-stats strong {
				font-weight: 600;
			}

			.a-stats a.a-stats__link,
			.a-stats a.a-stats__link:visited,
			.a-stats a.a-stats__link:active {
				background: var(--akismet-color-mid-green);
				border: none;
				box-shadow: none;
				border-radius: 8px;
				color: var(--akismet-color-white);
				cursor: pointer;
				display: block;
				font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', 'Roboto', 'Oxygen-Sans', 'Ubuntu', 'Cantarell', 'Helvetica Neue', sans-serif;
				font-weight: 500;
				padding: 12px;
				text-align: center;
				text-decoration: none;
				transition: all 0.2s ease;
			}

			/* Extra specificity to deal with TwentyTwentyOne focus style */
			.widget .a-stats a.a-stats__link:focus {
				background: var(--akismet-color-mid-green);
				color: var(--akismet-color-white);
				text-decoration: none;
			}

			.a-stats a.a-stats__link:hover {
				filter: brightness(110%);
				box-shadow: 0 4px 12px rgba(0, 0, 0, 0.06), 0 0 2px rgba(0, 0, 0, 0.16);
			}

			.a-stats .count {
				color: var(--akismet-color-white);
				display: block;
				font-size: 1.5em;
				line-height: 1.4;
				padding: 0 13px;
				white-space: nowrap;
			}
		
</style>
<link rel="https://api.w.org/" href="../wp-json/index.html" /><link rel="alternate" title="JSON" type="application/json" href="../wp-json/wp/v2/posts/16963" /><link rel="EditURI" type="application/rsd+xml" title="RSD" href="https://journal.code4lib.org/xmlrpc.php?rsd" />
<link rel="canonical" href="../index.html%3Fp=16963.html" />
<link rel='shortlink' href='../index.html%3Fp=16963.html' />
<link rel="alternate" title="oEmbed (JSON)" type="application/json+oembed" href="../wp-json/oembed/1.0/embed%3Furl=https:%252F%252Fjournal.code4lib.org%252Farticles%252F16963" />
<link rel="alternate" title="oEmbed (XML)" type="text/xml+oembed" href="../wp-json/oembed/1.0/embed%3Furl=https:%252F%252Fjournal.code4lib.org%252Farticles%252F16963&amp;format=xml" />
<style>
@media all and (max-width : 768px) {
.syntaxhighlighter a, .syntaxhighlighter div, .syntaxhighlighter code, .syntaxhighlighter table, .syntaxhighlighter table td, .syntaxhighlighter table tr, .syntaxhighlighter table tbody, .syntaxhighlighter table thead, .syntaxhighlighter table caption, .syntaxhighlighter textarea
{
	font-size: 0.95em !important;
}
}
</style>
	</head>
	<body>
		<div id="page">
			<div id="header">
				<div id="headerbackground">
					<h1><a href="../index.html"><img src="../wp-content/themes/c4lj-theme/images/logo.png" alt="The Code4Lib Journal" /></a></h1>
				</div>
				<div id="about">
					<ul>
						<li class="page_item page-item-5"><a href="../index.html%3Fp=5.html">Mission</a></li>
<li class="page_item page-item-6"><a href="../editorial-committee/index.html">Editorial Committee</a></li>
<li class="page_item page-item-8"><a href="../process/index.html">Process and Structure</a></li>
						<li><a href="http://code4lib.org/">Code4Lib</a></li>
					</ul>
				</div>
				<div class="mobile-search">
					<form method="get" id="searchform" action="../index.html">
						<div>
							<input type="text" value="" aria-labelledby="searchsubmit" name="s" id="s" />
							<input type="submit" value="Search" id="searchsubmit" />
						</div>
					</form>
				</div>
			</div>

			<div id="content">
								<div class="article" id="post-16963">
					<p id="issueDesignation"><a href="../issues/issues/issue55.html">Issue 55, 2023-1-20</a></p>
					<h1 class="articletitle">Designing Digital Discovery and Access Systems for Archival Description</h1>
					<div class="abstract">
						<p>Archival description is often misunderstood by librarians, administrators, and technologists in ways that have seriously hindered the development of access and discovery systems. It is not widely understood that there is currently no off-the-shelf system that provides discovery and access to digital materials using archival methods. This article is an overview of the core differences between archival and bibliographic description, and discusses how to design access systems for born-digital and digitized materials using the affordances of archival metadata. It offers a custom indexer as a working example that adds the full text of digital content to an Arclight instance and argues that the extensibility of archival description makes it a perfect match for automated description. Finally, it argues that building archives-first discovery systems allows us to use our descriptive labor more thoughtfully, better enable digitization on demand, and overall make a larger volume of cultural heritage materials available online.</p>
					</div>
					<div class="entry">
						<p>by <span style="font-weight: 400;">Gregory Wiedeman</span></p>
<h2>Introduction</h2>
<p>Archives are weird.</p>
<p>Or at least that seems to be the perception of many library technologists. While archives are often part of larger research libraries, archival methodologies are often misunderstood by our administrator, technologist, and librarian peers. This confusion has become more problematic as archives continue to need and develop more complex access systems to make description, digitized materials, and born-digital objects available over the web. Implementing these systems requires cross-domain partnerships, and the misunderstandings and miscommunications around archival description in particular have severely hindered the development of discovery and access systems for archives.</p>
<p>Archives access systems do not work like library catalogs or really anything else on the web and currently have major usability barriers. To those who work mostly with the bibliographic description used by libraries and most of the web, it can be unclear why archives cannot just use the same systems, or why archives systems and practices just seem so limiting for users. Archival methodology and its reasoning can be easily obscured among the more esoteric traditions of archives, like the celebration of famous men to demonstrate value to donors, Hollinger boxes, or finding aids. It is often hard to differentiate between the value and the dogma.</p>
<p>Archivists themselves often find it hard to articulate why their needs are just <em>different</em> than their librarian peers. It can be challenging even for many archival practitioners to acquire strong expertise in archival description. In the United States, archival training is a concentration within a library credential, which can mean merely one or two archives-specific courses. You might only get one single class that discusses archival description, and even that is often taught by a faculty member with a research focus rather than extensive practitioner experience. Archival description skills often need to be learned on-the-job and seem to be mostly effectively passed on through peer groups, mentorship, or other types of informal professional development that not everyone has access to. Even archivists that do have strong knowledge of archival description may not have a detailed understanding of how web applications or other technologies are designed or work in practice. While many archivists see firsthand the constant friction in current access systems, they often struggle to articulate how they can be designed better as web applications. The divide in domain knowledge between discovery systems and archival description is a challenging one to bridge.</p>
<p>I hope to clarify the core differences between archival and bibliographic description and outline a path towards more effective discovery systems. While bibliographic description is much more intuitive and commonplace in our web applications, archival methods free us to apply the valuable descriptive labor that is the main bottleneck in our digitization and born-digital acquisitions programs more thoughtfully and appropriately.[<a id="ref1" href="../index.html%3Fp=16963.html#note1">1</a>] If used properly, archival description could enable us to better provide digitization services on user request at scale and make these materials available online for future users. The extensibility of archival metadata also makes it a perfect fit for using automated description, such as optical character recognition (OCR), entity extraction, or automated transcription to enhance discovery, as it combines imprecise output with human-created records. I try to make it much clearer why archival metadata makes discovery so peculiar, highlight the cases where it can be advantageous, outline a path forward to increase the usability of archives access systems, and make the case for privileging archival description when planning and designing discovery systems.</p>
<p>The misunderstandings around archival description have hidden an enormous problem: there are no available off-the-shelf systems that provide access to digital materials using archival description. Every digital repository, Digital Asset Management System (DAMS) or Institutional Repository (IR) uses bibliographic description as an unrecognized design assumption. To illustrate this, I provide a case study of UAlbany’s existing Hyrax and Arclight implementations which use archival description for discovery by linking data from these systems over APIs. This approach works functionally but has substantial usability and maintenance issues. In working to combine these systems into a single archives discovery system, I wrote a custom indexer that adds digital materials, full-text OCR and extracted text content to Arclight as a proof-of-concept example that I hope can illustrate a path forward towards designing access systems that work directly with archival methods. Finally, I will point to some ways we can experiment with how archival inheritance is indexed to potentially mimic bibliographic usability.</p>
<h2>Archival vs. Bibliographic Description</h2>
<p>By bibliographic description, I mean the creation of individual metadata records for each object with a set of descriptive fields. This has been the intuitive method of managing information going back beyond our relevant professional history. I’m sure you could go back thousands of years and find library workers creating some kind of discrete bibliographic record describing an individual item. Library catalog cards and Online Public Access Catalogs (OPACs) are canonical examples of bibliographic description. Each record has a set of descriptive fields and is self-contained – all of the available information is contained within the record. Dublin Core states this explicitly in its “one-to-one principle,” where it declares that each discrete entity “should be described by conceptually distinct descriptions.”[<a id="ref2" href="../index.html%3Fp=16963.html#note2">2</a>] While Linked Data adds some complexity by potentially breaking up records into statements, data structures and descriptive practices usually remain the same. Most of the information on the web is displayed to users in a way that looks like bibliographic description. A search engine, a major e-commerce site, or Wikipedia will display records of objects to users that contain all the available information. These records often link to other records, but each record still describes an isolated object and is fully comprehensible by itself. The ubiquity of this format proves its intuitiveness and usability. I am sure that this is to some degree an oversimplified caricature of bibliographic practices, but it is a useful contrast to help us to better understand the impact of archival description.</p>
<p>While archives may appear to be just a specialized type of library, they have a fundamentally different methodology for managing and providing access to materials. Why did early archivists reinvent the wheel and develop incompatible practices that are less intuitive for both professionals and users? The answer is very practical: they simply had too much stuff. The early development of archival description in the United States illustrates how usability was a conscious and necessary tradeoff to be able to adequately manage the scale of records that were working with.</p>
<p>The American National Archives was first created in the 1930s and, since the government had been functioning and creating records for over 150 years, records had been previously managed by individual departments and offices, often with a variety of different methods and techniques. By 1941 archivists had accessioned 302,114 cubic feet of records from seventy-two different agencies.[<a id="ref3" href="../index.html%3Fp=16963.html#note3">3</a>] These early American archivists actually wanted to use bibliographic methods to make all these records easily accessible in familiar ways. They made multiple attempts to use various forms of card catalogs to describe materials and established a Classification Division devoted to somehow providing subject-based discovery. However, “…given the diverse mass of materials in the National Archives, classification demanded vastly more time and expense than the agency could afford,” and the division was disbanded in 1941.[<a id="ref4" href="../index.html%3Fp=16963.html#note4">4</a>] With truck after truck moving more and more records to the archives, all archivists were able to feasibly do was document the source of records and their existing arrangement. The provenance of each set of records was important because each source had a different arrangement system and discovery process. A user would have to use the “preliminary inventories” created by the archivists to find what office created the records they were seeking, and how that office arranged or maintained them to navigate that file series or records component.[<a id="ref5" href="../index.html%3Fp=16963.html#note5">5</a>] These “preliminary inventories” evolved into paper and online finding aids over time.[<a id="ref6" href="../index.html%3Fp=16963.html#note6">6</a>]</p>
<p>Of course, it would be simpler for users if all the records had a single discovery process, but to early American archivists, that was obviously (if regretfully) infeasible. Usability was a conscious trade off to make the enormous volume of materials even somewhat accessible. As a rule of thumb, the approaches used by archivists are useful primarily because of the scale of the materials they manage. Got a large but manageable amount of stuff? Use bibliographic description. Got a seemingly never-ending vast mountain of materials? Use archival description. This is an oversimplification, as archival methods are also very good at retaining context of materials, but scale alone is a useful distinction to show how archival systems are meaningfully different.[<a id="ref7" href="../index.html%3Fp=16963.html#note7">7</a>] The reality is that in our current unlimited information environment, archives and libraries have larger collecting scopes and volumes of materials than they have descriptive resources, much like the early National Archives. Even with the additional catalogers and archivists that should be hired to address this, archival methods should be reassessed in order to make the line between the available and the inaccessible more gradual, and to make a larger body of materials open for use.</p>
<h2>Archival Description in Practice</h2>
<p>Most of our librarian and technologist peers understand that archival data is structured differently, as archival data is hierarchical, with a tree structure of “components,” such as collections, file series, folders, and perhaps items. However, the way archival description <em>inherits</em> is not widely understood and has really important implications for system design. Even archivists do not often articulate how the relationships between components of description work.</p>
<p><span style="font-weight: 400;">For example, a repository might hold a folder called “Meeting Minutes, 1989 July 26.” This component only has a title and a date, which alone are not very helpful to users. Who was meeting? What were they discussing? Unlike a bibliographic record, not all of the available information is contained within the record and the relationships to other records are very meaningful. In </span><a href="https://archives.albany.edu/description/catalog/apap312aspace_c264f5e1f93f9d58e5b60483c32d76e9"><span style="font-weight: 400;">this example</span></a><span style="font-weight: 400;">, the file is part of a series titled “New Jersey Proportionality Review Project Records,” which is part of a collection titled the “Leigh B. Bienen Papers.” Both higher order components have fields where a user might learn the purpose of the meeting and its potential participants and outcomes.</span></p>
<p class="caption"><img decoding="async" src="../media/issue55/wiedeman/Image1.png" alt="Finding Aid of example of from the " /><br />
<strong>Image 1.</strong> The file is part of a series titled “New Jersey Proportionality Review Project Records,” which is part of a collection titled the “Leigh B. Bienen Papers.” <a href="https://archives.albany.edu/description/catalog/apap312aspace_c264f5e1f93f9d58e5b60483c32d76e9">https://archives.albany.edu/description/catalog/apap312aspace_c264f5e1f93f9d58e5b60483c32d76e9</a></p>
<p><span style="font-weight: 400;">Here is where we have to get into the weeds a bit. At all levels, components may use twenty-five elements that are described in the archives content standard, Describing Archives: A Content Standard (DACS). </span><a href="https://saa-ts-dacs.github.io/dacs/06_part_I/02_chapter_01.html#multilevel-required"><span style="font-weight: 400;">Eleven of these elements are required fields</span></a><span style="font-weight: 400;">. The standard also outlines a set of </span><a href="https://saa-ts-dacs.github.io/dacs/06_part_I/02_chapter_01.html#requirements-for-multilevel-descriptions"><span style="font-weight: 400;">Requirements for Multilevel Descriptions</span></a><span style="font-weight: 400;"> that articulates rules for the relationships between multilevel archival components like the above example. This section of DACS is particularly impactful, but it is challenging for non-experts to fully appreciate its meaning. What is not often understood here is that, while most of the eleven required elements are often only used at the collection level in practice, each component is required to be described by every one of these fields. Even the above “Meeting Minutes, 1989 July 26” example needs to have a Name of Creator(s), a scope and content note, an access conditions note, etc. This example is actually described by those elements, they are just stored outside of the record in higher order components. Lower-level components only use DACS elements if they supersede or are more granular than the higher order component. If this is not the case, the element from the higher-level component applies. Thus, the Scope and Content element from the New Jersey Proportionality Review Project Records series component and several elements from the Leigh B. Bienen Papers collection component also describe the “Meeting Minutes” file component. When archival repositories used paper finding aids, inherited elements were implicitly displayed using front matter, indents, and other design features that conveyed this relationship, but our current discovery systems do not account for this.</span></p>
<p><span style="font-weight: 400;">Archival description also provides us with a tremendous amount of flexibility, allowing for the discovery of full text, bibliographic records, and description automatically derived from digital materials within a single descriptive schema and discovery system. DACS allows archivists to use bibliographic metadata, such as Dublin Core fields, to further describe materials when there is a user-driven reason to do so. It just requires a clear and explicit relationship between these records and the archival component that describes them. This allows archivists to create high-quality descriptive records when appropriate. An archival collection can easily contain one series of lower-value or rarely used materials that are only generally described by the series description, and another series of high valued items containing high quality detailed metadata for each item that you would expect in a library catalog. Instead of allocating a similar amount of descriptive labor to all materials as bibliographic description often does, archival description empowers archivists to use their appraisal skills and spend their valuable time in proportion to the value of materials they are working with. For rarely used items with less value, materials can still be accessible, just with a higher usability cost.[<a id="ref8" href="../index.html%3Fp=16963.html#note8">8</a>]</span></p>
<p><span style="font-weight: 400;">Because archival methodology accommodates lower quality descriptive records, this also makes it a perfect fit for automated approaches that derive description from digital materials. This includes full text, technical metadata, or the output of computational techniques such as entities extracted using Natural Language Processing (NLP). Archival description is also a perfect fit for using emerging machine learning techniques for extracting meaningful information from digital images and documents for discovery if these tools can be used without causing harm. There have been some experiments that have used automated approaches to describe special collections materials. However, no matter how sophisticated, automated methods alone produce lower-quality records that limit discoverability and usability in bibliographic systems.[<a id="ref9" href="../index.html%3Fp=16963.html#note9">9</a>]</span><span style="font-weight: 400;"> In archival description, these records would always be linked with higher-level metadata created by a human professional. The flexibility of archival description also makes it easy to manually enhance automated description when needed. For lower value materials that would not receive detailed description, automated description can also be better than nothing. Archivists are also welcome to use automated description at first while assessing its use and potentially enhancing the description later as appropriate. Yet, as I’ll discuss later, while archival description encourages these practices, the current systems available for managing digital materials are designed only to work with bibliographic description, thus they are blocking the use of automated approaches in practice.</span></p>
<p><span style="font-weight: 400;">Archival methods do have significant drawbacks. This is an idealized vision of archival description. Systems that support the creation of quality archival description are a relatively new phenomenon and a lack of training and support can mean that archival methods are sometimes inconsistently mixed with bibliographic approaches, or just poorly applied. Additionally, even if we design discovery systems that make use of archival description, there is a usability cost that may be unavoidable when we compare it to the simplicity of bibliographic description. When you compare catalog cards to finding aids or OPACs to ArchivesSpace, bibliographic description is often more familiar and comfortable for most users. The usability problems of online finding aids and archives access systems are very well-documented.[<a id="ref10" href="../index.html%3Fp=16963.html#note10">10</a>]</span><span style="font-weight: 400;"> The more complex relationships in archival data are simply just more challenging to navigate and display intuitively. Yet, there are paths forward if we design digital repositories to match the affordances of archival description, then we may be able to improve the usability of discovery systems to where the advantages are well worth the costs to users.</span></p>
<h2>The Current Landscape of Digital Repositories</h2>
<p><span style="font-weight: 400;">When we apply a strong understanding of archival description to the current landscape of digital repositories, we see that there are several digital repositories available, but no system allows for the discovery of digital material using archival description. This is true across both open source and proprietary systems. Using archival methods for discovery is simply not currently possible without substantial customization. Most repositories are designed as Digital Asset Management Systems (DAMS) like </span><a href="https://www.oclc.org/en/contentdm.html"><span style="font-weight: 400;">ContentDM</span></a><span style="font-weight: 400;"> for the upload and discovery of digital objects or designed as Institutional Repositories (IRs) like </span><a href="https://www.islandora.ca/"><span style="font-weight: 400;">Islandora</span></a><span style="font-weight: 400;">, </span><a href="https://samvera.org/"><span style="font-weight: 400;">Samvera</span></a><span style="font-weight: 400;">-based applications, or </span><a href="https://bepress.com/products/digital-commons/"><span style="font-weight: 400;">Bepress Digital Commons</span></a><span style="font-weight: 400;"> that have built-in multi-user submission workflows. Every single one of these systems is designed with bibliographic description in mind. Each assumes that librarians or archivists will enter a set of descriptive metadata fields when uploading digital objects. Each tool also envisions itself as a self-contained system for this description. No complete off-the-shelf system expects description to be managed and made discoverable outside of its interface.</span></p>
<p><span style="font-weight: 400;">Remember that if an item is described by an archival component, DACS requires a clear and explicit relationship between that item and its higher-level components so that users can use those inherited descriptive fields, and it is reasonable for a user to expect at least a navigable link here. A common workflow is for archivists to digitize an item that is already described by an archival component, but since all DAMS and IRs assume they are self-contained, the archivist then has to spend additional time and labor to create a separate set of Dublin Core or other bibliographic elements for a digital repository. This both duplicates effort and creates an obvious usability barrier. Users often must navigate both a system for archival description and a separate system for digital content. This problem is particularly acute for small repositories, as to make digital content available, they are incentivised to change their local descriptive practices to match the system used by whatever consortial repository is available to them.</span></p>
<p><span style="font-weight: 400;">It is probably correct to say that none of the current tools, including  ContentDM, Islandora, </span><a href="https://dspace.lyrasis.org/"><span style="font-weight: 400;">DSpace</span></a><span style="font-weight: 400;">, Bepress Digital Commons, or Samvera-based systems like </span><a href="https://hyrax.samvera.org/"><span style="font-weight: 400;">Hyrax</span></a><span style="font-weight: 400;"> or </span><a href="https://hyku.samvera.org/"><span style="font-weight: 400;">Hyku</span></a><span style="font-weight: 400;">, are compliant with DACS. Archivists have no options. This is a major use case that is simply not being met with available tools, likely because of the divide in domain knowledge between archivists and administrators, librarians, and technologists. There is no off-the-shelf product that provides access and discovery for digital materials using archival repositories’ existing description methods and systems.</span></p>
<p><span style="font-weight: 400;">Over the last decade or so, there has been a lot of progress in designing and developing systems to manage archival description, with the development of </span><a href="https://archivesspace.org/"><span style="font-weight: 400;">ArchivesSpace</span></a><span style="font-weight: 400;"> being a major success. However, ArchivesSpace, </span><a href="https://www.accesstomemory.org"><span style="font-weight: 400;">Access to Memory</span></a><span style="font-weight: 400;"> (AToM), and </span><a href="https://library.stanford.edu/projects/arclight"><span style="font-weight: 400;">Arclight</span></a><span style="font-weight: 400;"> all only manage and/or provide access to description, not digital content. While these tools all help provide us with an important piece to the access puzzle, users want to access materials, not just descriptive records. In-person research will always be a key part of archival repositories, but more and more archival research is being done primarily or solely online, with the COVID-19 pandemic possibly being a major turning point. The closure of reading rooms finally forced many archives to regularly accommodate digitization requests on-demand. This is a major advancement in user services, yet many of these materials are often sent directly to users and not uploaded into digital repositories for future use. This is because these systems are not able to accommodate items without additional descriptive labor, despite them already having archival description and the fact that they were already discovered by a user.[<a id="ref11" href="../index.html%3Fp=16963.html#note11">11</a>]</span></p>
<p><span style="font-weight: 400;">Archival repositories need systems that manage digital content to </span><i><span style="font-weight: 400;">do less</span></i><span style="font-weight: 400;"> – focus on asset management, file serving, and interoperability. Archivists are already able to create and manage complex archival description in tools like ArchivesSpace or AToM. Archives need digital repositories to manage digital content but be interoperable with and rely on their existing description systems. The </span><a href="https://iiif.io/"><span style="font-weight: 400;">International Image Interoperability Framework</span></a><span style="font-weight: 400;"> (IIIF) is a great way to make these connections. There are some important roles that repositories should take on, such as processing or ingest workflows and technical metadata, but digital repositories as currently constituted cannot serve as the primary end-user discovery system for archival materials. It also could be advantageous to designate digital repositories and discovery systems as separate concerns, as repositories can better serve as a “back-end” systems that may better provide or are more interoperable with preservation functions. In the future this may help us avoid design problems like the Samvera architecture, which too tightly coupled preservation and access functionality though ActiveFedora.[<a id="ref12" href="../index.html%3Fp=16963.html#note12">12</a>]</span><span style="font-weight: 400;"> This separation may also make it easier for systems to manage access restrictions, as archivists need to manage and preserve digital materials that cannot currently be made publicly available, as “Virtual Reading Rooms” or limited or controlled access systems are another important piece of the access puzzle.[<a id="ref13" href="../index.html%3Fp=16963.html#note13">13</a>]</span><span style="font-weight: 400;"> But most importantly, separating discovery from asset management may also provide us with the space and flexibility to design access systems that allow end-users to discover and navigate that content using archival description.</span></p>
<h2>UAlbany Case Study</h2>
<p><span style="font-weight: 400;">A case study of the Espy Papers from UAlbany illustrates both the potential for using archival description to manage digital objects, particularly by enabling digitization on demand, as well as the practical challenges that arose attempting this with current systems. M. Watt Espy spent most of his life documenting capital punishment in the United States. He dug up information for every death row inmate he could find from corrections records, county histories, court proceedings, and popular publications, and summarized each case on index cards – colorfully documenting victims, alleged perpetrators, and circumstances. At his height he had a large network of collaborators that sent him documentation sourced from all over the country. This collection represented the most complete documentation of executions in what is now the United States dating back to European colonization. In 1984 the National Science Foundation (NSF) awarded a grant to the University of Alabama to create a computational dataset based on the materials, which was first released as </span><i><span style="font-weight: 400;">Executions in the United States, 1608-1987: The ESPY File</span></i><span style="font-weight: 400;">.</span><span style="font-weight: 400;">  On Espy’s death, the original source materials along with other papers were donated to UAlbany’s National Death Penalty Archive and in 2010 it received detailed folder-level processing with funding from the National Historical Publications and Records Commission (NHPRC).[<a id="ref15" href="../index.html%3Fp=16963.html#note15">15</a>]</span></p>
<p><span style="font-weight: 400;">While the ESPY File dataset became a canonical source for criminal justice researchers, abstracting the stories of these thousands of individuals onto a spreadsheet took away a lot of meaning and serviced only certain types of research. Some researchers had found issues with the dataset and reference staff had heard a number of anecdotes from users about discrepancies they found between the index cards and the ESPY File data. Seeing so many users willing to travel to see the index cards, along with the potential of leveraging the existing metadata from the dataset made it a strong candidate for digitization and in 2016, UAlbany was awarded a Council on Library and Information Resources (CLIR) Hidden Collections grant to digitize two file series and make them openly available online.[<a id="ref16" href="../index.html%3Fp=16963.html#note16">16</a>]</span></p>
<p><span style="font-weight: 400;">Since the collection had previously received detailed folder-level processing and the materials were the source for an existing dataset, it seemed wasteful and duplicative to create additional item-level records with bibliographic metadata for what would be about 125,000 digital objects. The ESPY File dataset was not created as descriptive metadata to our current standards and did not map to the paper materials in a machine-actionable way, so it was not useful as a drop-in replacement for bibliographic metadata in a DAMS. Thus, the collection seemed like an excellent candidate for using existing archival description to provide access to the digital scans, as it could make practical use of the problematic ESPY File data.</span></p>
<p><span style="font-weight: 400;">Our existing systems provided no way to use the existing description to provide discovery and access to digital scans. We had recently completed migrating our archival description to ArchivesSpace and were using </span><a href="https://xtf.cdlib.org/"><span style="font-weight: 400;">eXtensible Text Framework</span></a><span style="font-weight: 400;"> (XTF) and the </span><a href="http://www.lunaimaging.com/"><span style="font-weight: 400;">LUNA DAMS</span></a><span style="font-weight: 400;"> for access, but neither XTF or LUNA were interoperable or sustainably customizable and no digital repository was available that used archival description for discovery out-of-the-box. The ArchivesSpace REST API provided the potential to use archival description in new ways, and we were eager to fully leverage our descriptive labor already dedicated to the collection to benefit users and make our work more impactful. We decided to implement an open-source digital repository that would be more customizable to use folder-level description from ArchivesSpace along with the ESPY File dataset. For much of the source materials series, we thought that the quality folder-level description already existed should be sufficient to provide access. Also, if we could implement a successful process for using existing archival description for digitization, we hoped that we could do the same for other collections, and potentially even provide digitization services on request for single folders without having to create detailed bibliographic metadata.</span></p>
<p><span style="font-weight: 400;">We decided to implement a lightly customized Hyrax repository which uses the Samvera framework. Hyrax is not a “turnkey” system, but a fully featured set of open components that can be implemented into a digital repository. We hoped the openness of Hyrax would make it easily adaptable to our existing archival description. Over the course of the project, the </span><a href="https://library.stanford.edu/blogs/digital-library-blog/2017/06/arclight-mvp-work-cycle-completed"><span style="font-weight: 400;">Arclight MVP project</span></a><span style="font-weight: 400;"> made Arclight into a viable option for providing access to archival description. Because it uses a similar Ruby on Rails stack as Hyrax, it became easier to implement Arclight and integrate it with Hyrax than doing a similar level of customization with the ArchivesSpace Public User Interface (PUI). We needed data to be passed both ways, from Hyrax to Arclight and from Arclight to Hyrax, and both systems exposed JSON metadata with REST APIs, which was an invaluable feature we could not have done without. Since both systems used the same technology, much of what we learned customizing one system could also be applied towards the other.</span></p>
<p><span style="font-weight: 400;">We did not quite know what we were getting into. The project was significantly under-resourced in both outside funding and internal expertise. However, despite some delays, data problems, and the challenges of learning new technologies, the systems we implemented were a major success. The </span><a href="https://archives.albany.edu/espy/"><span style="font-weight: 400;">Espy Project Execution Records website</span></a><span style="font-weight: 400;"> provides open access and discovery to the Espy Papers. Our University Libraries also gained a lot of skills and capacity to implement and host open-source applications that would be applicable to other projects, we developed a more productive relationship with the university-level Information Technology Services division, and we are better able to utilize our on-campus virtualized data center. The need to support these systems was successfully used in 2019 to justify filling a vacant technologist position that otherwise was not likely to have received university-level approval. The project enabled us to use existing archival description for digitized and born-digital items and allowed us to provide online access to a much greater volume of materials.</span></p>
<p><span style="font-weight: 400;">On the Hyrax side, we had to develop multiple custom data models to handle both legacy materials from our existing DAMS as well as objects that would rely only on a link to a component of archival description. It was relatively straightforward to create Image and AV models to handle the schemas used in our existing DAMS, but Hyrax’s use of linked data URIs was a barrier to creating a sensible digital archival object (DAO) model for archival description.[<a id="ref17" href="../index.html%3Fp=16963.html#note17">17</a>]</span><span style="font-weight: 400;"> To make connections between digital objects and components of archival description, we used the 32-character ref_id generated by ArchivesSpace and indexed into Arclight. Each folder-level component would have a ref_id for itself, could have multiple ref_ids for higher level series and subseries components, and always had a collection identifier for the top-level collection. We thus needed three identifier fields, one containing multiple IDs where the order mattered, and each having a separate meaning. It also made sense to store the name of each component in the model as a string. This was challenging to model using linked data URIs since Hyrax requires a unique URI for each field. Once we got a set of URIs that Hyrax accepted, we essentially ignored the URIs downstream and relied on local meanings for the fields. I am skeptical that even a perfectly designed or customized ontology would have provided any value to this project, and trying to use any form of the Records in Context (RiC-O) ontology currently being designed by the International Council on Archives Experts Group on Archival Description (ICA EGAD) would have been a nightmare.[<a id="ref18" href="../index.html%3Fp=16963.html#note18">18</a>]</span></p>
<p><span style="font-weight: 400;">Once the DAO model was complete, we customized the workflow page where an archivist would upload and describe a digital object. This worker would enter the ref_id for the component of archival description, the collection identifier, and click a “Load Record” button. This button would make a JavaScript AJAX call to the Arclight JSON API and automatically fill most of the descriptive fields. The worker would then only be required to add a resource type and a license or rights statement before uploading the object.</span></p>
<p class="caption"><img decoding="async" src="../media/issue55/wiedeman/Image2.png" alt="Screen shot of DAO Model form" /><br />
<strong>Image 2.</strong> DAO Model.</p>
<p><span style="font-weight: 400;">We also customized the display page for each object to pull relevant archival description from Arclight also using client-side JavaScript calls. When an object page loads, it uses the ref_id and collection identifier to query the archival description component and all of its parent components. The page then displays the names and links for all higher-level components as any Scope and Content notes. The use of client-side AJAX calls is imperfect but allowed us to integrate the two systems without much more complex customization within the Rails applications.</span></p>
<p><span style="font-weight: 400;">If a worker was digitizing </span><a href="https://archives.albany.edu/concern/daos/jd473d78n"><span style="font-weight: 400;">an item</span></a><span style="font-weight: 400;">, they would just have to find the ref_id and collection number for the folder in ArchivesSpace or Arclight, and enter those fields in Hyrax with a resource type and rights statement. For descriptive metadata Hyrax would then only contain a title (example: Skandalon, Vol. 3, No. 9) and date (example: 1965 March 10), which by itself would not be very helpful to users. When a user accesses the item, Hyrax will query and display Scope and Content notes for the Skandalon and the University Publications Collection. A user could then read that this is a single issue from a bi-weekly journal of news and opinion published by Campus Christian Council, which was part of an artificial collection of student publications. </span></p>
<p><span style="font-weight: 400;">This minimal descriptive workflow, along with rapid lower-quality scanning allowed for digitization on user request. We later implemented a new Digital Reproduction Fee Schedule that charged by the time required for digitization rather than page counts.[<a id="ref19" href="../index.html%3Fp=16963.html#note19">19</a>]</span><span style="font-weight: 400;"> Since we were using existing archival description for metadata and avoiding page count estimates with back-and-forth emails, in many cases we were able to digitize an item in about the same time as a traditional reference request and make requests that take under 30 minutes free to users. This practice improved user experience, allowed us to digitize a much larger volume of materials and make them accessible online, and has the added benefit of making our digitization labor more transparent to users. In this example, I received a request for one issue and digitized the whole run of 42 issues in an afternoon merely because I had some extra time and thought the materials were interesting and worth digitizing.</span></p>
<p><span style="font-weight: 400;">In addition digitizing individual items on request, we also developed a </span><a href="https://wiki.albany.edu/display/SCA/Processing+Ingested+Digital+Files"><span style="font-weight: 400;">batch upload workflow</span></a><span style="font-weight: 400;"> for large sets of items sent to an outside vendor for digitization. The process relied mostly on spreadsheets. Here we also used existing archival description so the materials did not require item-level bibliographic metadata. This proved to be really useful for university publications, for example, where we had existing volume and issue lists. We had an </span><a href="https://github.com/UAlbanyArchives/asInventory"><span style="font-weight: 400;">existing tool</span></a><span style="font-weight: 400;"> for exporting this metadata from the ArchivesSpace API, so we added on a process where an archivist could paste in the corresponding access file for each issue and a script would generate another spreadsheet that could be uploaded into Hyrax using a rake task. This workflow enabled us to rapidly digitize large collections or file series that were really valuable for reference use, such as student newspapers, university publications, commencement programs, university organizational charts, press releases, and university senate legislation. While additional descriptive care would have improved discoverability as always, making these materials discoverable using existing archival description plus full text OCR and extracted text was a major advancement.</span></p>
<p><span style="font-weight: 400;">While our Arclight and Hyrax implementations were very successful in providing access to digital materials using archival description, they also have a number of practical limitations. The most obvious problem is that users still must navigate two separate systems, one for archival description and another for digital materials. We implemented a “bento” style discovery layer based on QuickSearch to make search results from both ArcLight and Hyrax available from a single search box but found that users still had trouble navigating back and forth between the two systems.[<a id="ref20" href="../index.html%3Fp=16963.html#note20">20</a>]</span><span style="font-weight: 400;"> A redesign in early 2022 based on the Duke University Arclight implementation addressed some minor issues with this integration, but the core problem remains.[<a id="ref21" href="../index.html%3Fp=16963.html#note21">21</a>]</span></p>
<p><span style="font-weight: 400;">Additionally, getting data from Hyrax back into Arclight is challenging. It was easy to modify Arclight templates to point to Hyrax for digital materials, but once an archivist uploaded a new object into Hyrax, that URI had to be added to a new ArchivesSpace Digital Object record. We were also storing separate preservation copies for each object outside of Hyrax so we needed to download the object, store it as a local Archival Information Package (AIP), and add an identifier that references the AIP into Hyrax. Since Hyrax does not provide an API for this, we were only able to automate this using a very wonky script that queries the Hyrax Solr index, adds a new Digital Object in ArchivesSpace, schedules it to be indexed to Arclight, downloads and stores the object as an AIP and adds the identifier to Hyrax by literally scraping the Hyrax login and edit pages and POSTing data to the edit form using the Python requests module. It worked, but it was a hack.</span></p>
<p><span style="font-weight: 400;">This process along with overall support for Hyrax creates major sustainability risks. Our Library Systems department has struggled to maintain Hyrax without anyone with a strong Ruby or Rails background on staff. Major cuts to library staff in 2020-2022 only minimally impacted applications support, but with overall library staff reduced by about 30% due to unfilled retirements, our long-term support for customized applications should be questioned, particularly when we are adapting systems like Hyrax and not using them quite as they are intended. Overall, there is a need for this setup to be simplified.</span></p>
<h2>A Discovery System Designed for Archival Description</h2>
<p><span style="font-weight: 400;">Archivists need a discovery system for digital materials that uses archival description. A true archival discovery system would query archival description along with item-level bibliographic metadata and automated description derived from digital materials, such as extracted text, OCR text, and A/V transcripts in a single search interface. Arclight has the potential to be this system. Currently Arclight is an access system for archival description based on Blacklight. It does not manage digital assets but returns individual components of archival description and lets users navigate through connected records. Since Arclight merely displays data indexed in Solr just like Blacklight, it also has the potential to display and return search results for digital objects, including full text.</span></p>
<p><a href="https://github.com/UAlbanyArchives/description_indexer"><span style="font-weight: 400;">description_indexer</span></a><span style="font-weight: 400;"> is an experimental tool that overrides the default Arclight indexing pipeline. Out-of-the-box, Arclight uses </span><a href="https://github.com/traject/traject"><span style="font-weight: 400;">Traject</span></a><span style="font-weight: 400;"> to index archival description from EAD-XML files, often exported from ArchivesSpace. While Traject is set up to be easily configurable to select which XPath to use for each Solr field, it is not easily customizable to add the significant logic needed to index archival description or data from other sources. Instead, description_indexer is a Python library that uses </span><a href="https://github.com/archivesspace-labs/ArchivesSnake"><span style="font-weight: 400;">ArchivesSnake</span></a><span style="font-weight: 400;"> and </span><a href="https://github.com/django-haystack/pysolr"><span style="font-weight: 400;">PySolr</span></a><span style="font-weight: 400;"> to index archival description directly from the ArchivesSpace API. This approach is potentially very useful for individual repository instances but may be less so for consortial aggregators because of the high permissions levels currently needed to access the ArchivesSpace API. description_indexer contains two very basic JSON data models, </span><a href="https://github.com/UAlbanyArchives/description_indexer/blob/main/description_indexer/models/description.py"><span style="font-weight: 400;">one for archival description</span></a><span style="font-weight: 400;"> and </span><a href="https://github.com/UAlbanyArchives/description_indexer/blob/main/description_indexer/models/arclight.py"><span style="font-weight: 400;">another for the Arclight Solr index</span></a><span style="font-weight: 400;">. This extra layer of abstraction is useful, as any data source that can map to the archival description model would then be automatically indexable into Arclight. The archival description model is very much a draft and is likely too simple to be comprehensive, but community consensus around a model like this is key to consistently representing digital materials in the Arclight index.</span></p>
<p><span style="font-weight: 400;">The description_indexer main branch is set up to be a “drop-in” replacement for the current Traject indexer. The </span><a href="https://github.com/UAlbanyArchives/description_indexer/tree/dao-indexing"><span style="font-weight: 400;">dao-indexing branch</span></a><span style="font-weight: 400;"> is designed to be a more experimental branch that flexibly indexes from digital repositories or other systems that manage digital assets. It is designed to be extensible, since individual implementations will likely need to index asset data from a number of different sources, you can write your own plugin-in to index digital assets from your local system. Once description_indexer is installed, you can add a custom class in a .py file in your home directory or using an environment variable that will allow for local logic to override how digital objects are indexed. The UAlbany example that is included queries JSON from our Hyrax instance to index links to content and other item-level data not managed in ArchivesSpace. description_indexer also contains multiple “extractors” for pulling content from digital files using </span><a href="https://tika.apache.org/"><span style="font-weight: 400;">Apache Tika</span></a><span style="font-weight: 400;"> and/or </span><a href="https://github.com/tesseract-ocr/tesseract"><span style="font-weight: 400;">Tesseract</span></a><span style="font-weight: 400;">, however running these during indexing is a challenge and a better design would be to extract and store this data while processing digital files and make it available to the indexer via a file system or a REST service. Here is also where there is the potential to experiment with new tools for extracting useful information from documents for discovery using NLP or models generated with machine learning. The data pipeline to the indexer needs further consensus and standardization.</span></p>
<p><span style="font-weight: 400;">In writing description_indexer, I discovered that digital objects, files, and file versions are under-theorized in archival description and archivists need to better define these objects and their relationships. The </span><a href="https://pcdm.org/2016/04/18/models"><span style="font-weight: 400;">Portland Common Data Model</span></a><span style="font-weight: 400;"> (PCDM) provides helpful definitions of objects and files, and should be incorporated as much as possible, but the relationships between objects and archival components in lieu of PCDM collections is ill-defined and current practice is inconsistent.[<a id="ref22" href="../index.html%3Fp=16963.html#note22">22</a>]</span><span style="font-weight: 400;"> ArchivesSpace attaches Digital Objects to archival components, but allows component attributes such as subjects and note fields to be attached to Digital Objects as well. Digital Objects also do not have href or URL attributes but contain File Versions which have File URI attributes. Both Digital Objects and File Versions also have is_representative Boolean attributes that are likely useful for Digital Objects. Overall, it should be clearer that Digital Objects are an abstraction that do not necessarily correspond to a file, and Digital Objects should probably have a field for an International Image Interoperability Framework (IIIF) manifest, as that also can be an abstraction and should be the preferred method of linking archival description to digital materials. Attributes for how files and versions are displayed in the absence of a IIIF manifests are also likely necessary, and overall, it was challenging to model this and broader and more complex community use cases are needed.[<a id="ref23" href="../index.html%3Fp=16963.html#note23">23</a>]</span></p>
<p><span style="font-weight: 400;">The biggest barriers to enabling the discovery of digital materials in Arclight are establishing consensus data models and data pipelines. Once content from digital materials is indexed into an Arclight Solr index, we can display those objects in Arclight with only some minor customizations and a IIIF-compliant image server. I implemented a simple </span><a href="https://archives.albany.edu/demo/"><span style="font-weight: 400;">demonstration application</span></a><span style="font-weight: 400;"> that illustrates what this could look like in practice. This system returns results based both on archival description and full-text content extracted from digital objects. This implementation has data and design limitations, but I hope that this can be a useful model that shows the potential for what Arclight can be going forward.</span></p>
<h2>Privileging Archival Description in Discovery Systems</h2>
<p><span style="font-weight: 400;">Academic libraries and other cultural heritage institutions also manage digital objects using bibliographic description. To avoid implementing and maintaining multiple discovery systems, archival materials are often forced into off-the-shelf IRs and DAMS designed for bibliographic description. A better understanding of archival description shows that it is actually more appropriate to do the reverse, and index bibliographic records into systems designed for archival materials. Here, it might be helpful to see archival description as an organizational schema for managing materials which have many different organizational schemas. In the same way that the early National Archives used archival description to manage different descriptive methods used by different government agencies, archival systems can also accommodate bibliographic metadata that provides more usable and familiar access. This provides the best of both worlds. We can have one discovery system that provides both a strong user experience for higher value materials while still providing some level of access for materials that do not receive wide interest and otherwise would not receive detailed descriptive care.</span></p>
<p><span style="font-weight: 400;">This also works from a purely technical perspective. While it is possible to model archival description in digital repositories like Hyrax, the more complex structure of archival data makes this very challenging. It is comparably much simpler to model bibliographic metadata into archival systems than the reverse. With well-defined data models, we can easily add bibliographic metadata to an Arclight index, just like with a Blacklight instance. These records could stand alone or also be linked to archival description. This provides Arclight with the potential to unify bibliographic and archival metadata in a single user environment, offering the usability of detailed records with the extensibility of archival hierarchy. This would provide us with the full potential of archival description to flexibly allocate our descriptive labor based on the value of materials and user needs. Navigating complex archival data structures for items with lesser value may still be challenging for users. If we can make decisions based on the value of materials, rather than systems limitations, this should actually be an effective allocation of our limited descriptive resources.</span></p>
<p><span style="font-weight: 400;">There are also additional opportunities to improve the usability of archival description. Since Arclight is just an extension of Blacklight, it presents description to users in search results as discrete units much like bibliographic metadata. What we can do is experiment with how archival tree structures are indexed to better match how DACS envisions inheritance. Since DACS expects notes that are usually only applied at collection or series levels—like Scope and Content or Historical notes—to apply to lower-level components as well, we can experiment with indexing these notes as part of lower-level components too and just return them with lower relevancy scores. Arclight currently indexes parent access and use notes like this but does not use them to return search results. This has the potential to return better results for minimally-described materials, but would need to be part of an iterative usability testing process so that results are weighted appropriately. These are exciting possibilities, but we cannot do usability testing on archival discovery systems until they exist.</span></p>
<h2>Conclusion</h2>
<p><span style="font-weight: 400;">Archival description takes a very different approach to description than what is commonly used elsewhere – whether that be in library catalogs, digital repositories, or on the web. Archival methodology has key strengths that make it very useful for managing the vast quantity of digital materials held by libraries and avoiding a digital divide in an era where pandemics and the emissions costs of travel may limit in-person research. Our descriptive labor, no matter how extensive it is or should be, has limits. If academic libraries continue to prioritize bibliographic approaches to metadata and apply the same level of descriptive care to objects one by one regardless of value, there will always be a hard line between what is accessible and what is not. Archival description provides flexibility that empowers us to apply that valuable descriptive care based on the needs of users and prepares us to experiment with automated metadata approaches and iterative workflows. Archival methods simply more accurately and appropriately model our descriptive resources to our materials.</span></p>
<p><span style="font-weight: 400;">Unfortunately, it is currently very challenging to use archival description to manage and provide access to digital materials, as current digital repositories are not designed to work with archival description. Archivists manage description for materials in systems like ArchivesSpace that are designed for archival description, but DAMS and similar digital repository systems expect them to create additional bibliographic metadata for any digital material they manage, whether that is an appropriate use of resources or not. There is usually no easy way to link that metadata from two different systems together. In practice, this means that lower-valued items or the increasing number of items digitized by archives on user request are not made available or discoverable for future users because they do not have the value needed to receive detailed bibliographic description. This is silly considering archival description already exists for them.</span></p>
<p><span style="font-weight: 400;">Since archives data structures can accommodate bibliographic metadata, but the reverse is very challenging, discovery systems design must privilege archival description. Currently, there is no easy way to integrate archival description from systems like ArchivesSpace with digital materials managed in digital repositories into a single discovery point for users. UAlbany’s approach of using a “bento” style discovery layer on top of these two systems works functionally but has substantial usability limitations and sustainability concerns.</span></p>
<p><span style="font-weight: 400;">The misunderstandings around archival description have marginalized archival systems in academic libraries. Because our digital access systems never have worked for archival methods, libraries long took shortcuts by establishing whole separate programs to manage unique digital materials and limiting archives and special collections to a very traditional understanding of their collecting scopes. Instead of working </span><i><span style="font-weight: 400;">with</span></i><span style="font-weight: 400;"> archives, libraries often worked around them – often causing needless duplication in metadata work, digitization, asset management, and digital preservation across different reporting structures. </span></p>
<p><span style="font-weight: 400;">Arclight has the potential to unify discovery of archival and bibliographic description and provide a single discovery point for physical and digital materials that allows archivists to fully leverage the affordances of archival description. We need further community consensus on a data model for archival description – most notably for digital objects, files, and file versions. I hope description_indexer can be a helpful example that can be iterated upon, that further work can be done to index digital materials in the Arclight index, and that we can experiment more with indexing archival description in general. While not really discussed here, archival description’s focus on agents and functions behind the creation of records has the potential for opening new patterns for discovery.[<a id="ref24" href="../index.html%3Fp=16963.html#note24">24</a>]</span><span style="font-weight: 400;"> Overall, we need examples of digital materials in Arclight alongside archival and bibliographic description for iterative usability testing.</span></p>
<h2>About the Author</h2>
<p><span style="font-weight: 400;">Gregory Wiedeman is the university archivist at the University at Albany, SUNY where he helps ensure long-term access to the school’s public records. He manages the University Archives and supports born-digital collecting, web archives, and systems implementation for the department’s outside collecting areas. He currently serves as co-chair of the Technical Subcommittee for Describing Archives: A Content Standard (TS-DACS).</span></p>
<h2>Endnotes</h2>
<p>[<a id="note1" href="../index.html%3Fp=16963.html#ref1">1</a>] Joyce Chapman, Kinza Masood, Chrissy Rissmeyer, Dan Zelner, “Digitization Cost Calculator Raw Data,” Digital Library Federation (DLF) Assessment Interest Group (2015). <a href="https://dashboard.diglib.org/data/">https://dashboard.diglib.org/data/</a>. Amanda J. Wilson, “Toward Releasing the Metadata Bottleneck: A Baseline Evaluation of Contributor-supplied Metadata,” Library Resources &amp; Technical Services Vol. 51, No. 1 (2007). <a href="https://journals.ala.org/index.php/lrts/article/view/5384/6604">https://journals.ala.org/index.php/lrts/article/view/5384/6604</a>.</p>
<p>[<a id="note2" href="../index.html%3Fp=16963.html#ref2">2</a>] “DCMI: One-to-One Principle,” Dublin Core Metadata Innovation. <a href="https://web.archive.org/web/20220627093857/https://www.dublincore.org/resources/glossary/one-to-one_principle/">https://web.archive.org/web/20220627093857/https://www.dublincore.org/resources/glossary/one-to-one_principle/</a></p>
<p>[<a id="note3" href="../index.html%3Fp=16963.html#ref3">3</a>] McCoy states that “…the National Archives had to deal with the greatest volume of records in the world; the unparalleled diversity of their origins, arrangement, and types; and their widely scattered locations in 1935.” Donald R. McCoy, <em>The National Archives: America’s Ministry of Documents 1934-1968</em> (Chapel Hill, NC: The University of North Carolina Press, 1978), 45, 69.</p>
<p>[<a id="note4" href="../index.html%3Fp=16963.html#ref4">4</a>] McCoy, 78-80. Philip M. Hamer, “Finding Mediums in the National Archives: An Appraisal of Six Years’ Experience,” The American Archivist, Vol. 5, No. 2 (1942): 86-87.</p>
<p>[<a id="note5" href="../index.html%3Fp=16963.html#ref5">5</a>] <span style="font-weight: 400;">The National Archives, </span><i><span style="font-weight: 400;">Guide to the Material in The National Archives</span></i><span style="font-weight: 400;"> (Washington, DC: United States Government Printing Office, 1940), ix.</span></p>
<p>[<a id="note6" href="../index.html%3Fp=16963.html#ref6">6</a>] <span style="font-weight: 400;">This process is discussed in more depth in Gregory Wiedeman, “The Historical Hazards of Finding Aids,” </span><i><span style="font-weight: 400;">The American Archivist</span></i><span style="font-weight: 400;">, Vol. 82, No. 2 (2019): 381-420. </span><a href="https://doi.org/10.17723/aarc-82-02-20"><span style="font-weight: 400;">https://doi.org/10.17723/aarc-82-02-20</span></a><span style="font-weight: 400;">.</span></p>
<p>[<a id="note7" href="../index.html%3Fp=16963.html#ref7">7</a>] <span style="font-weight: 400;">In addition to working well at scale, archival description is also more effective at maintaining contextual relationships between records, their creators, and the activities that created them. This is further discussed in Jodi Allison-Bunnell, Maureen Cresci Callahan, Gretchen Gueguen, John Kunze, Krystyna K. Matusiak, and Gregory Wiedeman, “Lost Without Context: Representing Relationships between Archival Materials in the Digital Environment,” </span><i><span style="font-weight: 400;">The Lighting the Way Handbook: Case Studies, Guidelines, and Emergent Futures for Archival Discovery and Delivery</span></i><span style="font-weight: 400;">, eds. M.A. Matienzo and Dinah Handel (Stanford, CA: Stanford University Libraries, 2021). </span><a href="https://doi.org/10.25740/gg453cv6438"><span style="font-weight: 400;">https://doi.org/10.25740/gg453cv6438</span></a><span style="font-weight: 400;">.</span></p>
<p>[<a id="note8" href="../index.html%3Fp=16963.html#ref8">8</a>] <span style="font-weight: 400;">This practice is best described in Daniel A. Santamaria, </span><i><span style="font-weight: 400;">Extensible Processing for Archives and Special Collections: Reducing Processing Backlogs</span></i><span style="font-weight: 400;"> (Chicago: Neal-Schuman, 2015). Shan C. Sutton also discusses the further extension of this to digitization in Shan C. Sutton, “Balancing Boutique-Level Quality and Large-Scale Production: The Impact </span><span style="font-weight: 400;">of “More Product, Less Process” on Digitization in Archives and Special Collections,” </span><i><span style="font-weight: 400;">RBM: A Journal of Rare Books, Manuscripts, and Cultural Heritage</span></i><span style="font-weight: 400;"> Vol. 13, No. 1 (2012). </span><a href="https://doi.org/10.5860/rbm.13.1.369"><span style="font-weight: 400;">https://doi.org/10.5860/rbm.13.1.369</span></a><span style="font-weight: 400;">.</span></p>
<p>[<a id="note9" href="../index.html%3Fp=16963.html#ref9">9</a>] <span style="font-weight: 400;">Paul Kelly, “Better Together: Improving the Lives of Metadata Creators with Natural Language Processing,” in </span><i><span style="font-weight: 400;">Code4Lib Journal</span></i><span style="font-weight: 400;"> Issue 51 (June 14, 2021), </span><a href="../index.html%3Fp=15946.html"><span style="font-weight: 400;">https://journal.code4lib.org/articles/15946</span></a><span style="font-weight: 400;">. Kaldeli, Eirini, Orfeas Menis-Mastromichalakis, Spyros Bekiaris, Maria Ralli, Vassilis Tzouvaras, Giorgos Stamou, and Evaggelos Spyrou, “CrowdHeritage: Crowdsourcing for Improving the Quality of Cultural Heritage Metadata,” </span><i><span style="font-weight: 400;">Information</span></i><span style="font-weight: 400;"> Vol. 12, No. 2 (February 2021).</span></p>
<p>[<a id="note10" href="../index.html%3Fp=16963.html#ref10">10</a>] <span style="font-weight: 400;">Christopher J. Prom, “User Interactions with Electronic Finding Aids in a Controlled Setting,” </span><i><span style="font-weight: 400;">American Archivist</span></i><span style="font-weight: 400;"> 67, no. 2 (2004): 234–68, </span><a href="https://doi.org/10.17723/aarc.67.2.7317671548328620"><span style="font-weight: 400;">https://doi.org/10.17723/aarc.67.2.7317671548328620</span></a><span style="font-weight: 400;">. Anne J. Gilliland-Swetland, “Popularizing the Finding Aid: Exploiting EAD to Enhance Online Discovery and Retrieval in Archival Information Systems by Diverse User Groups,” </span><i><span style="font-weight: 400;">Journal of Internet Cataloging</span></i><span style="font-weight: 400;"> 4, nos. 3–4 (2001): 199–225, </span><a href="https://doi.org/10.1300/J141v04n03_12"><span style="font-weight: 400;">https://doi.org/10.1300/J141v04n03_12</span></a><span style="font-weight: 400;">. Luanne Freund and Elaine G. Toms, “Interacting with Archival Finding Aids,” </span><i><span style="font-weight: 400;">Journal of the Association for Information Science and Technology</span></i><span style="font-weight: 400;"> 67, no. 4 (2016): 1007, </span><a href="https://doi.org/10.1002/asi.23436"><span style="font-weight: 400;">https://doi.org/10.1002/asi.23436</span></a><span style="font-weight: 400;">. Wendy Scheir, “First Entry: Report on a Qualitative Exploratory Study of Notice User Experience with Online Finding Aids,” </span><i><span style="font-weight: 400;">Journal of Archival Organization</span></i><span style="font-weight: 400;"> 3, no. 4 (2005): 49–85, </span><a href="https://doi.org/10.1300/J201v03n04_04"><span style="font-weight: 400;">https://doi.org/10.1300/J201v03n04_04</span></a><span style="font-weight: 400;">. Joyce Celeste Chapman, “Observing Users: An Empirical Analysis of User Interaction with Online Finding Aids,” </span><i><span style="font-weight: 400;">Journal of Archival Organization</span></i><span style="font-weight: 400;"> 8 (2010): 4–30, </span><a href="https://doi.org/10.1080/15332748.2010.484361"><span style="font-weight: 400;">https://doi.org/10.1080/15332748.2010.484361</span></a><span style="font-weight: 400;">.</span></p>
<p>[<a id="note11" href="../index.html%3Fp=16963.html#ref11">11</a>] <span style="font-weight: 400;">James E. Murphy, Carla J. Lewis, Christena A. McKillop, and Marc Stoeckle, “Expanding digital academic library and archive services at the University of Calgary in response to the COVID-19 pandemic,” IFLA Journal Vol. 48, No. 1 (2021). </span><a href="https://doi.org/10.1177/03400352211023067"><span style="font-weight: 400;">https://doi.org/10.1177/03400352211023067</span></a><span style="font-weight: 400;">. Florence Sloan, “Special Collections Practice in Response to the Challenges of COVID-19: Problems, Opportunities, and Future Implications for Digital Collections at the Louis Round Wilson Library at the University of North Carolina at Chapel Hill,” Masters Thesis, University of North Carolina at Chapel Hill School of Information and Library Science (April 30, 2021). </span><a href="https://cdr.lib.unc.edu/concern/masters_papers/1z40m3313"><span style="font-weight: 400;">https://cdr.lib.unc.edu/concern/masters_papers/1z40m3313</span></a><span style="font-weight: 400;">. The infeasibility of creating item level records is also discussed in Stephanie Becker, Anne Kumer, and Naomi Langer, “Access is People: How Investing in Digital Collections Labor Improves Archival Discovery &amp; Delivery,”</span><i><span style="font-weight: 400;"> The Lighting the Way Handbook: Case Studies, Guidelines, and Emergent Futures for Archival Discovery and Delivery</span></i><span style="font-weight: 400;">, eds. M.A. Matienzo and Dinah Handel (Stanford, CA: Stanford University Libraries, 2021), 33. </span><a href="https://doi.org/10.25740/gg453cv6438"><span style="font-weight: 400;">https://doi.org/10.25740/gg453cv6438</span></a><span style="font-weight: 400;">.</span></p>
<p>[<a id="note12" href="../index.html%3Fp=16963.html#ref12">12</a>] <span style="font-weight: 400;">Esmé Cowles, “Valkyrie, Reimagining the Samvera Community,” </span><a href="https://library.princeton.edu/news/digital-collections/2018-06-05/valkyrie-reimagining-samvera-community"><span style="font-weight: 400;">https://library.princeton.edu/news/digital-collections/2018-06-05/valkyrie-reimagining-samvera-community</span></a><span style="font-weight: 400;">.</span></p>
<p>[<a id="note13" href="../index.html%3Fp=16963.html#ref13">13</a>] <span style="font-weight: 400;">Elvia Arroyo-Ramírez, Annalise Berdini, Shelly Black, Greg Cram, Kathryn Gronsbell, Nick Krabbenhoeft, Kate Lynch, Genevieve Preston, and Heather Smedberg, “Speeding Towards Remote Access: Developing Shared</span></p>
<p><span style="font-weight: 400;">Recommendations for Virtual Reading Rooms,” </span><i><span style="font-weight: 400;">The Lighting the Way Handbook: Case Studies, Guidelines, and Emergent Futures for Archival Discovery and Delivery</span></i><span style="font-weight: 400;">, eds. M.A. Matienzo and Dinah Handel (Stanford, CA: Stanford University Libraries, 2021). </span><a href="https://doi.org/10.25740/gg453cv6438"><span style="font-weight: 400;">https://doi.org/10.25740/gg453cv6438</span></a><span style="font-weight: 400;">.</span></p>
<p>[<a id="note14" href="../index.html%3Fp=16963.html#ref14">14</a>] <span style="font-weight: 400;"> M. Watt Espy, John Ortiz Smykla, </span><i><span style="font-weight: 400;">Executions in the United States, 1608-2002: The ESPY File</span></i><span style="font-weight: 400;"> (ICPSR 8451), (Ann Arbor, MI: Inter-university Consortium for Political and Social Research (distributor), 2016-07-20). </span><a href="https://doi.org/10.3886/ICPSR08451.v5"><span style="font-weight: 400;">https://doi.org/10.3886/ICPSR08451.v5</span></a><span style="font-weight: 400;">. </span></p>
<p>[<a id="note15" href="../index.html%3Fp=16963.html#ref15">15</a>] <span style="font-weight: 400;"> M. Watt Espy Papers, 1730-2008. M.E. Grenander Department of Special Collections and Archives, University Libraries, University at Albany, State University of New York. <a href="https://archives.albany.edu/description/catalog/apap301">https://archives.albany.edu/description/catalog/apap301</a>. “Commission Recommends $7 Million In Grants,” The U.S. National Archives and Records Administration, 2010 June 1. <a href="https://web.archive.org/web/20220307211150/https://www.archives.gov/press/press-releases/2010/nr10-107.html">https://web.archive.org/web/20220307211150/https://www.archives.gov/press/press-releases/2010/nr10-107.html</a>.</span></p>
<p>[<a id="note16" href="../index.html%3Fp=16963.html#ref16">16</a>] <span style="font-weight: 400;">Blackman and McLaughlin summarize the widespread praise for Espy’s work, while also highlighting some of the ESPY File’s limitations and criticizing its use for quantitative analysis. Blackman and McLaughlin, “The Espy File on American Executions: User Beware,” Homicide Studies Vol. 15, No. 3 (2011): 209-227.</span></p>
<p>[<a id="note17" href="../index.html%3Fp=16963.html#ref17">17</a>] <span style="font-weight: 400;">Models for the UAlbany Hyrax instance. </span><a href="https://github.com/UAlbanyArchives/hyrax-UAlbany/tree/main/app/models"><span style="font-weight: 400;">https://github.com/UAlbanyArchives/hyrax-UAlbany/tree/main/app/models</span></a><span style="font-weight: 400;">.</span></p>
<p>[<a id="note18" href="../index.html%3Fp=16963.html#ref18">18</a>] <span style="font-weight: 400;">EGAD &#8211; Expert Group on Archival Description, “Records in Contexts – Ontology,” July 22, 2021. </span><a href="https://www.ica.org/en/records-in-contexts-ontology"><span style="font-weight: 400;">https://www.ica.org/en/records-in-contexts-ontology</span></a><span style="font-weight: 400;">.</span></p>
<p>[<a id="note19" href="../index.html%3Fp=16963.html#ref19">19</a>] <span style="font-weight: 400;">“Request Items for Digitization,” M.E. Grenander Department of Special Collections &amp; Archives, University at Albany, SUNY. </span><a href="https://archives.albany.edu/web/reproductions/"><span style="font-weight: 400;">https://archives.albany.edu/web/reproductions/</span></a><span style="font-weight: 400;">.</span></p>
<p>[<a id="note20" href="../index.html%3Fp=16963.html#ref20">20</a>] <span style="font-weight: 400;">“QuickSearch,” North Carolina State University Libraries. </span><a href="https://www.lib.ncsu.edu/projects/quicksearch"><span style="font-weight: 400;">https://www.lib.ncsu.edu/projects/quicksearch</span></a><span style="font-weight: 400;">.</span></p>
<p>[<a id="note21" href="../index.html%3Fp=16963.html#ref21">21</a>] <span style="font-weight: 400;">Sean Aery, “ArcLight at the End of the Tunnel,” November 15</span><span style="font-weight: 400;">th</span><span style="font-weight: 400;">, 2019. </span><a href="https://blogs.library.duke.edu/bitstreams/2019/11/15/arclight-at-the-end-of-the-tunnel/"><span style="font-weight: 400;">https://blogs.library.duke.edu/bitstreams/2019/11/15/arclight-at-the-end-of-the-tunnel/</span></a><span style="font-weight: 400;">.</span></p>
<p>[<a id="note22" href="../index.html%3Fp=16963.html#ref22">22</a>] <span style="font-weight: 400;">Portland Common Data Model (April 18, 2016), </span><a href="https://web.archive.org/web/20220912065008/https://pcdm.org/2016/04/18/models"><span style="font-weight: 400;">https://web.archive.org/web/20220912065008/https://pcdm.org/2016/04/18/models</span></a><span style="font-weight: 400;">.</span></p>
<p>[<a id="note23" href="../index.html%3Fp=16963.html#ref23">23</a>] <span style="font-weight: 400;">description_indexer experimental archival description model, </span><a href="https://github.com/UAlbanyArchives/description_indexer/blob/dao-indexing/description_indexer/models/description.py"><span style="font-weight: 400;">https://github.com/UAlbanyArchives/description_indexer/blob/dao-indexing/description_indexer/models/description.py</span></a><span style="font-weight: 400;">.</span></p>
<p>[<a id="note24" href="../index.html%3Fp=16963.html#ref24">24</a>] <span style="font-weight: 400;">The Rockefeller Archive Center’s DIMES access system is a really interesting step in this direction by emphasizing agent records and requiring users to click through archival components to convey description inheritance. Renee Pappous, Hannah Sistrunk, and Darren Young, “Connecting on Principles: Building and Uncovering Relationships through a New Archival Discovery System,” </span><i><span style="font-weight: 400;">The Lighting the Way Handbook: Case Studies, Guidelines, and Emergent Futures for Archival Discovery and Delivery</span></i><span style="font-weight: 400;">, eds. M.A. Matienzo and Dinah Handel (Stanford, CA: Stanford University Libraries, 2021). The Records in Contexts – Conceptual Model (RiC-CM) also has a very intriguing focus on agents and functions for discovery that deserves further practical exploration. “Records in Contexts &#8211; Conceptual Model.” Expert Group on Archival Description (EGAD), </span><a href="https://web.archive.org/web/20221007020234/https://www.ica.org/en/records-in-contexts-conceptual-model"><span style="font-weight: 400;">https://web.archive.org/web/20221007020234/https://www.ica.org/en/records-in-contexts-conceptual-model</span></a><span style="font-weight: 400;">.</span></p>
					</div>
														</div>
				<!-- You can start editing here. -->

<div class="comments">
	<p class="subscriptionlinks">Subscribe to comments: <a href="16963/feed">For this article</a> | <a href="http://feeds.feedburner.com/c4lj/comments">For all articles</a></p>

			<!-- If comments are open, but there are no comments. -->

	 

<h3 id="respond">Leave a Reply</h3>


<form action="https://journal.code4lib.org/wp-comments-post.php" method="post" id="commentform">


<p><input type="text" name="author" id="author" value=""/>
<label for="author">Name (required)</label></p>

<p><input type="text" name="email" id="email" value="" />
<label for="email">Mail (will not be published) (required)</label></p>

<p><input type="text" name="url" id="url" value="" />
<label for="url">Website</label></p>


<p><textarea autocomplete="new-password"  aria-label="Comment box" id="f127f6ccbe"  name="f127f6ccbe"   cols="50" rows="10"></textarea><textarea id="comment" aria-label="hp-comment" aria-hidden="true" name="comment" autocomplete="new-password" style="padding:0 !important;clip:rect(1px, 1px, 1px, 1px) !important;position:absolute !important;white-space:nowrap !important;height:1px !important;width:1px !important;overflow:hidden !important;" tabindex="-1"></textarea><script data-noptimize>document.getElementById("comment").setAttribute( "id", "a1098bfdcbfbf0d97d816f2b6025a839" );document.getElementById("f127f6ccbe").setAttribute( "id", "comment" );</script></p>

<p><input name="submit" type="submit" id="submit"  value="Submit Comment" />
<input type="hidden" name="comment_post_ID" value="16963" />
</p>
<p style="display: none;"><input type="hidden" id="akismet_comment_nonce" name="akismet_comment_nonce" value="2157909a9e" /></p><p style="display: none !important;" class="akismet-fields-container" data-prefix="ak_"><label>&#916;<textarea name="ak_hp_textarea" cols="45" rows="8" maxlength="100"></textarea></label><input type="hidden" id="ak_js_1" name="ak_js" value="41"/><script>document.getElementById( "ak_js_1" ).setAttribute( "value", ( new Date() ).getTime() );</script></p>
</form>


</div>
							</div>

			<div id="meta">
				<div id="issn">
					<p>ISSN 1940-5758</p>
				</div>
				<div class="search-sidebar">
				<form method="get" id="searchform" action="../index.html">
					<div>
						<input type="text" value="" aria-labelledby="searchsubmit" name="s" id="s" />
						<input type="submit" value="Search" id="searchsubmit"/>
					</div>
				</form>
				</div>
				<div id="archives">
					<h2>Current Issue</h2>
						<ul>
							<li><a href="../issues/issues/issue60.html">Issue 60, 2025-04-14</a></li>
						</ul>

					<h2>Previous Issues</h2>
						<ul>
              <li><a href="../issues/issues/issue59.html">Issue 59, 2024-10-07</a></li><li><a href="../issues/issues/issue58.html">Issue 58, 2023-12-04</a></li><li><a href="../issues/issues/issue57.html">Issue 57, 2023-08-29</a></li><li><a href="../issues/issues/issue56.html">Issue 56, 2023-04-21</a></li>              <li><a href="../index.html%3Fp=2476.html">Older Issues</a></li>
						</ul>
				</div>
				<div id="forauthors">
					<h2>For Authors</h2>
					<ul>
						<li class="page_item page-item-4"><a href="../index.html%3Fp=4.html">Call for Submissions</a></li>
<li class="page_item page-item-7"><a href="../index.html%3Fp=7.html">Article Guidelines</a></li>
					</ul>
				</div>
			</div>
						<div id="footer">
				<p id="login"><a href="../wp-login.php.html">Log in</a></p>
				<p id="copyright">This work is licensed under a <a rel="license" href="http://creativecommons.org/licenses/by/3.0/us/">Creative Commons Attribution 3.0 United States License</a>.<br /><a rel="license" href="http://creativecommons.org/licenses/by/3.0/us/"><img alt="Creative Commons License" src="http://i.creativecommons.org/l/by/3.0/us/80x15.png" /></a></p>
			</div>
			<script type="speculationrules">
{"prefetch":[{"source":"document","where":{"and":[{"href_matches":"\/*"},{"not":{"href_matches":["\/wp-*.php","\/wp-admin\/*","\/wp-content\/uploads\/*","\/wp-content\/*","\/wp-content\/plugins\/*","\/wp-content\/themes\/c4lj-theme\/*","\/*\\?(.+)"]}},{"not":{"selector_matches":"a[rel~=\"nofollow\"]"}},{"not":{"selector_matches":".no-prefetch, .no-prefetch a"}}]},"eagerness":"conservative"}]}
</script>
<script defer type="text/javascript" src="../wp-content/plugins/akismet/_inc/akismet-frontend.js%3Fver=1748382734" id="akismet-frontend-js"></script>
		</div>
	</body>
</html>
