<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN"
"http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en-US">
	<head>
		<meta http-equiv="Content-Type" content="text/html; charset=UTF-8" />

		<title>The Code4Lib Journal &#8211; Ontology for Voice, Instruments, and Ensembles (OnVIE): Revisiting the Medium of Performance Concept for Enhanced Discoverability</title>

		<meta name="viewport" content="width=device-width, initial-scale=1" />
		<meta name="generator" content="WordPress 6.8.1" /> <!-- leave this for stats -->
    <link rel="shortcut icon" href="../wp-content/themes/c4lj-theme/images/favicon.ico" />
		<link rel="stylesheet" href="../wp-content/themes/c4lj-theme/style.css" type="text/css" media="screen, print" />
		<!--[if lte IE 7]>
		<link rel="stylesheet" href="https://journal.code4lib.org/wp-content/themes/c4lj-theme/fix-ie7.css" type="text/css" media="screen" />
		<![endif]-->
		<!--[if lte IE 6]>
		<link rel="stylesheet" href="https://journal.code4lib.org/wp-content/themes/c4lj-theme/fix-ie6.css" type="text/css" media="screen" />
		<![endif]-->
		<link rel="stylesheet" href="../wp-content/themes/c4lj-theme/print.css" type="text/css" media="print" />
		<link rel="alternate" type="application/rss+xml" title="The Code4Lib Journal Syndication Feed" href="http://feeds.feedburner.com/c4lj" />
		<link rel="pingback" href="https://journal.code4lib.org/xmlrpc.php" />

<!-- Google Scholar Stuff -->
	<meta name="citation_title" content="Ontology for Voice, Instruments, and Ensembles (OnVIE): Revisiting the Medium of Performance Concept for Enhanced Discoverability">
 <meta name="citation_author" content="Kimmy Szeto">
<meta name="citation_publication_date" content="2022/08/29">
	<meta name="citation_journal_title" content="Code4Lib Journal">
		<meta name="citation_issue" content="54">
<!-- end  Google Scholar Stuff -->

<meta name='robots' content='max-image-preview:large' />
	<style>img:is([sizes="auto" i], [sizes^="auto," i]) { contain-intrinsic-size: 3000px 1500px }</style>
	<link rel="alternate" type="application/rss+xml" title="The Code4Lib Journal &raquo; Ontology for Voice, Instruments, and Ensembles (OnVIE): Revisiting the Medium of Performance Concept for Enhanced Discoverability Comments Feed" href="16608/feed" />
<script type="text/javascript">
/* <![CDATA[ */
window._wpemojiSettings = {"baseUrl":"https:\/\/s.w.org\/images\/core\/emoji\/15.1.0\/72x72\/","ext":".png","svgUrl":"https:\/\/s.w.org\/images\/core\/emoji\/15.1.0\/svg\/","svgExt":".svg","source":{"concatemoji":"https:\/\/journal.code4lib.org\/wp-includes\/js\/wp-emoji-release.min.js?ver=6.8.1"}};
/*! This file is auto-generated */
!function(i,n){var o,s,e;function c(e){try{var t={supportTests:e,timestamp:(new Date).valueOf()};sessionStorage.setItem(o,JSON.stringify(t))}catch(e){}}function p(e,t,n){e.clearRect(0,0,e.canvas.width,e.canvas.height),e.fillText(t,0,0);var t=new Uint32Array(e.getImageData(0,0,e.canvas.width,e.canvas.height).data),r=(e.clearRect(0,0,e.canvas.width,e.canvas.height),e.fillText(n,0,0),new Uint32Array(e.getImageData(0,0,e.canvas.width,e.canvas.height).data));return t.every(function(e,t){return e===r[t]})}function u(e,t,n){switch(t){case"flag":return n(e,"\ud83c\udff3\ufe0f\u200d\u26a7\ufe0f","\ud83c\udff3\ufe0f\u200b\u26a7\ufe0f")?!1:!n(e,"\ud83c\uddfa\ud83c\uddf3","\ud83c\uddfa\u200b\ud83c\uddf3")&&!n(e,"\ud83c\udff4\udb40\udc67\udb40\udc62\udb40\udc65\udb40\udc6e\udb40\udc67\udb40\udc7f","\ud83c\udff4\u200b\udb40\udc67\u200b\udb40\udc62\u200b\udb40\udc65\u200b\udb40\udc6e\u200b\udb40\udc67\u200b\udb40\udc7f");case"emoji":return!n(e,"\ud83d\udc26\u200d\ud83d\udd25","\ud83d\udc26\u200b\ud83d\udd25")}return!1}function f(e,t,n){var r="undefined"!=typeof WorkerGlobalScope&&self instanceof WorkerGlobalScope?new OffscreenCanvas(300,150):i.createElement("canvas"),a=r.getContext("2d",{willReadFrequently:!0}),o=(a.textBaseline="top",a.font="600 32px Arial",{});return e.forEach(function(e){o[e]=t(a,e,n)}),o}function t(e){var t=i.createElement("script");t.src=e,t.defer=!0,i.head.appendChild(t)}"undefined"!=typeof Promise&&(o="wpEmojiSettingsSupports",s=["flag","emoji"],n.supports={everything:!0,everythingExceptFlag:!0},e=new Promise(function(e){i.addEventListener("DOMContentLoaded",e,{once:!0})}),new Promise(function(t){var n=function(){try{var e=JSON.parse(sessionStorage.getItem(o));if("object"==typeof e&&"number"==typeof e.timestamp&&(new Date).valueOf()<e.timestamp+604800&&"object"==typeof e.supportTests)return e.supportTests}catch(e){}return null}();if(!n){if("undefined"!=typeof Worker&&"undefined"!=typeof OffscreenCanvas&&"undefined"!=typeof URL&&URL.createObjectURL&&"undefined"!=typeof Blob)try{var e="postMessage("+f.toString()+"("+[JSON.stringify(s),u.toString(),p.toString()].join(",")+"));",r=new Blob([e],{type:"text/javascript"}),a=new Worker(URL.createObjectURL(r),{name:"wpTestEmojiSupports"});return void(a.onmessage=function(e){c(n=e.data),a.terminate(),t(n)})}catch(e){}c(n=f(s,u,p))}t(n)}).then(function(e){for(var t in e)n.supports[t]=e[t],n.supports.everything=n.supports.everything&&n.supports[t],"flag"!==t&&(n.supports.everythingExceptFlag=n.supports.everythingExceptFlag&&n.supports[t]);n.supports.everythingExceptFlag=n.supports.everythingExceptFlag&&!n.supports.flag,n.DOMReady=!1,n.readyCallback=function(){n.DOMReady=!0}}).then(function(){return e}).then(function(){var e;n.supports.everything||(n.readyCallback(),(e=n.source||{}).concatemoji?t(e.concatemoji):e.wpemoji&&e.twemoji&&(t(e.twemoji),t(e.wpemoji)))}))}((window,document),window._wpemojiSettings);
/* ]]> */
</script>
<style id='wp-emoji-styles-inline-css' type='text/css'>

	img.wp-smiley, img.emoji {
		display: inline !important;
		border: none !important;
		box-shadow: none !important;
		height: 1em !important;
		width: 1em !important;
		margin: 0 0.07em !important;
		vertical-align: -0.1em !important;
		background: none !important;
		padding: 0 !important;
	}
</style>
<link rel='stylesheet' id='wp-block-library-css' href='../wp-includes/css/dist/block-library/style.min.css%3Fver=6.8.1.css' type='text/css' media='all' />
<style id='classic-theme-styles-inline-css' type='text/css'>
/*! This file is auto-generated */
.wp-block-button__link{color:#fff;background-color:#32373c;border-radius:9999px;box-shadow:none;text-decoration:none;padding:calc(.667em + 2px) calc(1.333em + 2px);font-size:1.125em}.wp-block-file__button{background:#32373c;color:#fff;text-decoration:none}
</style>
<style id='global-styles-inline-css' type='text/css'>
:root{--wp--preset--aspect-ratio--square: 1;--wp--preset--aspect-ratio--4-3: 4/3;--wp--preset--aspect-ratio--3-4: 3/4;--wp--preset--aspect-ratio--3-2: 3/2;--wp--preset--aspect-ratio--2-3: 2/3;--wp--preset--aspect-ratio--16-9: 16/9;--wp--preset--aspect-ratio--9-16: 9/16;--wp--preset--color--black: #000000;--wp--preset--color--cyan-bluish-gray: #abb8c3;--wp--preset--color--white: #ffffff;--wp--preset--color--pale-pink: #f78da7;--wp--preset--color--vivid-red: #cf2e2e;--wp--preset--color--luminous-vivid-orange: #ff6900;--wp--preset--color--luminous-vivid-amber: #fcb900;--wp--preset--color--light-green-cyan: #7bdcb5;--wp--preset--color--vivid-green-cyan: #00d084;--wp--preset--color--pale-cyan-blue: #8ed1fc;--wp--preset--color--vivid-cyan-blue: #0693e3;--wp--preset--color--vivid-purple: #9b51e0;--wp--preset--gradient--vivid-cyan-blue-to-vivid-purple: linear-gradient(135deg,rgba(6,147,227,1) 0%,rgb(155,81,224) 100%);--wp--preset--gradient--light-green-cyan-to-vivid-green-cyan: linear-gradient(135deg,rgb(122,220,180) 0%,rgb(0,208,130) 100%);--wp--preset--gradient--luminous-vivid-amber-to-luminous-vivid-orange: linear-gradient(135deg,rgba(252,185,0,1) 0%,rgba(255,105,0,1) 100%);--wp--preset--gradient--luminous-vivid-orange-to-vivid-red: linear-gradient(135deg,rgba(255,105,0,1) 0%,rgb(207,46,46) 100%);--wp--preset--gradient--very-light-gray-to-cyan-bluish-gray: linear-gradient(135deg,rgb(238,238,238) 0%,rgb(169,184,195) 100%);--wp--preset--gradient--cool-to-warm-spectrum: linear-gradient(135deg,rgb(74,234,220) 0%,rgb(151,120,209) 20%,rgb(207,42,186) 40%,rgb(238,44,130) 60%,rgb(251,105,98) 80%,rgb(254,248,76) 100%);--wp--preset--gradient--blush-light-purple: linear-gradient(135deg,rgb(255,206,236) 0%,rgb(152,150,240) 100%);--wp--preset--gradient--blush-bordeaux: linear-gradient(135deg,rgb(254,205,165) 0%,rgb(254,45,45) 50%,rgb(107,0,62) 100%);--wp--preset--gradient--luminous-dusk: linear-gradient(135deg,rgb(255,203,112) 0%,rgb(199,81,192) 50%,rgb(65,88,208) 100%);--wp--preset--gradient--pale-ocean: linear-gradient(135deg,rgb(255,245,203) 0%,rgb(182,227,212) 50%,rgb(51,167,181) 100%);--wp--preset--gradient--electric-grass: linear-gradient(135deg,rgb(202,248,128) 0%,rgb(113,206,126) 100%);--wp--preset--gradient--midnight: linear-gradient(135deg,rgb(2,3,129) 0%,rgb(40,116,252) 100%);--wp--preset--font-size--small: 13px;--wp--preset--font-size--medium: 20px;--wp--preset--font-size--large: 36px;--wp--preset--font-size--x-large: 42px;--wp--preset--spacing--20: 0.44rem;--wp--preset--spacing--30: 0.67rem;--wp--preset--spacing--40: 1rem;--wp--preset--spacing--50: 1.5rem;--wp--preset--spacing--60: 2.25rem;--wp--preset--spacing--70: 3.38rem;--wp--preset--spacing--80: 5.06rem;--wp--preset--shadow--natural: 6px 6px 9px rgba(0, 0, 0, 0.2);--wp--preset--shadow--deep: 12px 12px 50px rgba(0, 0, 0, 0.4);--wp--preset--shadow--sharp: 6px 6px 0px rgba(0, 0, 0, 0.2);--wp--preset--shadow--outlined: 6px 6px 0px -3px rgba(255, 255, 255, 1), 6px 6px rgba(0, 0, 0, 1);--wp--preset--shadow--crisp: 6px 6px 0px rgba(0, 0, 0, 1);}:where(.is-layout-flex){gap: 0.5em;}:where(.is-layout-grid){gap: 0.5em;}body .is-layout-flex{display: flex;}.is-layout-flex{flex-wrap: wrap;align-items: center;}.is-layout-flex > :is(*, div){margin: 0;}body .is-layout-grid{display: grid;}.is-layout-grid > :is(*, div){margin: 0;}:where(.wp-block-columns.is-layout-flex){gap: 2em;}:where(.wp-block-columns.is-layout-grid){gap: 2em;}:where(.wp-block-post-template.is-layout-flex){gap: 1.25em;}:where(.wp-block-post-template.is-layout-grid){gap: 1.25em;}.has-black-color{color: var(--wp--preset--color--black) !important;}.has-cyan-bluish-gray-color{color: var(--wp--preset--color--cyan-bluish-gray) !important;}.has-white-color{color: var(--wp--preset--color--white) !important;}.has-pale-pink-color{color: var(--wp--preset--color--pale-pink) !important;}.has-vivid-red-color{color: var(--wp--preset--color--vivid-red) !important;}.has-luminous-vivid-orange-color{color: var(--wp--preset--color--luminous-vivid-orange) !important;}.has-luminous-vivid-amber-color{color: var(--wp--preset--color--luminous-vivid-amber) !important;}.has-light-green-cyan-color{color: var(--wp--preset--color--light-green-cyan) !important;}.has-vivid-green-cyan-color{color: var(--wp--preset--color--vivid-green-cyan) !important;}.has-pale-cyan-blue-color{color: var(--wp--preset--color--pale-cyan-blue) !important;}.has-vivid-cyan-blue-color{color: var(--wp--preset--color--vivid-cyan-blue) !important;}.has-vivid-purple-color{color: var(--wp--preset--color--vivid-purple) !important;}.has-black-background-color{background-color: var(--wp--preset--color--black) !important;}.has-cyan-bluish-gray-background-color{background-color: var(--wp--preset--color--cyan-bluish-gray) !important;}.has-white-background-color{background-color: var(--wp--preset--color--white) !important;}.has-pale-pink-background-color{background-color: var(--wp--preset--color--pale-pink) !important;}.has-vivid-red-background-color{background-color: var(--wp--preset--color--vivid-red) !important;}.has-luminous-vivid-orange-background-color{background-color: var(--wp--preset--color--luminous-vivid-orange) !important;}.has-luminous-vivid-amber-background-color{background-color: var(--wp--preset--color--luminous-vivid-amber) !important;}.has-light-green-cyan-background-color{background-color: var(--wp--preset--color--light-green-cyan) !important;}.has-vivid-green-cyan-background-color{background-color: var(--wp--preset--color--vivid-green-cyan) !important;}.has-pale-cyan-blue-background-color{background-color: var(--wp--preset--color--pale-cyan-blue) !important;}.has-vivid-cyan-blue-background-color{background-color: var(--wp--preset--color--vivid-cyan-blue) !important;}.has-vivid-purple-background-color{background-color: var(--wp--preset--color--vivid-purple) !important;}.has-black-border-color{border-color: var(--wp--preset--color--black) !important;}.has-cyan-bluish-gray-border-color{border-color: var(--wp--preset--color--cyan-bluish-gray) !important;}.has-white-border-color{border-color: var(--wp--preset--color--white) !important;}.has-pale-pink-border-color{border-color: var(--wp--preset--color--pale-pink) !important;}.has-vivid-red-border-color{border-color: var(--wp--preset--color--vivid-red) !important;}.has-luminous-vivid-orange-border-color{border-color: var(--wp--preset--color--luminous-vivid-orange) !important;}.has-luminous-vivid-amber-border-color{border-color: var(--wp--preset--color--luminous-vivid-amber) !important;}.has-light-green-cyan-border-color{border-color: var(--wp--preset--color--light-green-cyan) !important;}.has-vivid-green-cyan-border-color{border-color: var(--wp--preset--color--vivid-green-cyan) !important;}.has-pale-cyan-blue-border-color{border-color: var(--wp--preset--color--pale-cyan-blue) !important;}.has-vivid-cyan-blue-border-color{border-color: var(--wp--preset--color--vivid-cyan-blue) !important;}.has-vivid-purple-border-color{border-color: var(--wp--preset--color--vivid-purple) !important;}.has-vivid-cyan-blue-to-vivid-purple-gradient-background{background: var(--wp--preset--gradient--vivid-cyan-blue-to-vivid-purple) !important;}.has-light-green-cyan-to-vivid-green-cyan-gradient-background{background: var(--wp--preset--gradient--light-green-cyan-to-vivid-green-cyan) !important;}.has-luminous-vivid-amber-to-luminous-vivid-orange-gradient-background{background: var(--wp--preset--gradient--luminous-vivid-amber-to-luminous-vivid-orange) !important;}.has-luminous-vivid-orange-to-vivid-red-gradient-background{background: var(--wp--preset--gradient--luminous-vivid-orange-to-vivid-red) !important;}.has-very-light-gray-to-cyan-bluish-gray-gradient-background{background: var(--wp--preset--gradient--very-light-gray-to-cyan-bluish-gray) !important;}.has-cool-to-warm-spectrum-gradient-background{background: var(--wp--preset--gradient--cool-to-warm-spectrum) !important;}.has-blush-light-purple-gradient-background{background: var(--wp--preset--gradient--blush-light-purple) !important;}.has-blush-bordeaux-gradient-background{background: var(--wp--preset--gradient--blush-bordeaux) !important;}.has-luminous-dusk-gradient-background{background: var(--wp--preset--gradient--luminous-dusk) !important;}.has-pale-ocean-gradient-background{background: var(--wp--preset--gradient--pale-ocean) !important;}.has-electric-grass-gradient-background{background: var(--wp--preset--gradient--electric-grass) !important;}.has-midnight-gradient-background{background: var(--wp--preset--gradient--midnight) !important;}.has-small-font-size{font-size: var(--wp--preset--font-size--small) !important;}.has-medium-font-size{font-size: var(--wp--preset--font-size--medium) !important;}.has-large-font-size{font-size: var(--wp--preset--font-size--large) !important;}.has-x-large-font-size{font-size: var(--wp--preset--font-size--x-large) !important;}
:where(.wp-block-post-template.is-layout-flex){gap: 1.25em;}:where(.wp-block-post-template.is-layout-grid){gap: 1.25em;}
:where(.wp-block-columns.is-layout-flex){gap: 2em;}:where(.wp-block-columns.is-layout-grid){gap: 2em;}
:root :where(.wp-block-pullquote){font-size: 1.5em;line-height: 1.6;}
</style>
<style id='akismet-widget-style-inline-css' type='text/css'>

			.a-stats {
				--akismet-color-mid-green: #357b49;
				--akismet-color-white: #fff;
				--akismet-color-light-grey: #f6f7f7;

				max-width: 350px;
				width: auto;
			}

			.a-stats * {
				all: unset;
				box-sizing: border-box;
			}

			.a-stats strong {
				font-weight: 600;
			}

			.a-stats a.a-stats__link,
			.a-stats a.a-stats__link:visited,
			.a-stats a.a-stats__link:active {
				background: var(--akismet-color-mid-green);
				border: none;
				box-shadow: none;
				border-radius: 8px;
				color: var(--akismet-color-white);
				cursor: pointer;
				display: block;
				font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', 'Roboto', 'Oxygen-Sans', 'Ubuntu', 'Cantarell', 'Helvetica Neue', sans-serif;
				font-weight: 500;
				padding: 12px;
				text-align: center;
				text-decoration: none;
				transition: all 0.2s ease;
			}

			/* Extra specificity to deal with TwentyTwentyOne focus style */
			.widget .a-stats a.a-stats__link:focus {
				background: var(--akismet-color-mid-green);
				color: var(--akismet-color-white);
				text-decoration: none;
			}

			.a-stats a.a-stats__link:hover {
				filter: brightness(110%);
				box-shadow: 0 4px 12px rgba(0, 0, 0, 0.06), 0 0 2px rgba(0, 0, 0, 0.16);
			}

			.a-stats .count {
				color: var(--akismet-color-white);
				display: block;
				font-size: 1.5em;
				line-height: 1.4;
				padding: 0 13px;
				white-space: nowrap;
			}
		
</style>
<link rel="https://api.w.org/" href="../wp-json/index.html" /><link rel="alternate" title="JSON" type="application/json" href="../wp-json/wp/v2/posts/16608" /><link rel="EditURI" type="application/rsd+xml" title="RSD" href="https://journal.code4lib.org/xmlrpc.php?rsd" />
<link rel="canonical" href="../index.html%3Fp=16608.html" />
<link rel='shortlink' href='../index.html%3Fp=16608.html' />
<link rel="alternate" title="oEmbed (JSON)" type="application/json+oembed" href="../wp-json/oembed/1.0/embed%3Furl=https:%252F%252Fjournal.code4lib.org%252Farticles%252F16608" />
<link rel="alternate" title="oEmbed (XML)" type="text/xml+oembed" href="../wp-json/oembed/1.0/embed%3Furl=https:%252F%252Fjournal.code4lib.org%252Farticles%252F16608&amp;format=xml" />
<style>
@media all and (max-width : 768px) {
.syntaxhighlighter a, .syntaxhighlighter div, .syntaxhighlighter code, .syntaxhighlighter table, .syntaxhighlighter table td, .syntaxhighlighter table tr, .syntaxhighlighter table tbody, .syntaxhighlighter table thead, .syntaxhighlighter table caption, .syntaxhighlighter textarea
{
	font-size: 0.95em !important;
}
}
</style>
	</head>
	<body>
		<div id="page">
			<div id="header">
				<div id="headerbackground">
					<h1><a href="../index.html"><img src="../wp-content/themes/c4lj-theme/images/logo.png" alt="The Code4Lib Journal" /></a></h1>
				</div>
				<div id="about">
					<ul>
						<li class="page_item page-item-5"><a href="../index.html%3Fp=5.html">Mission</a></li>
<li class="page_item page-item-6"><a href="../editorial-committee/index.html">Editorial Committee</a></li>
<li class="page_item page-item-8"><a href="../process/index.html">Process and Structure</a></li>
						<li><a href="http://code4lib.org/">Code4Lib</a></li>
					</ul>
				</div>
				<div class="mobile-search">
					<form method="get" id="searchform" action="../index.html">
						<div>
							<input type="text" value="" aria-labelledby="searchsubmit" name="s" id="s" />
							<input type="submit" value="Search" id="searchsubmit" />
						</div>
					</form>
				</div>
			</div>

			<div id="content">
								<div class="article" id="post-16608">
					<p id="issueDesignation"><a href="../issues/issues/issue54.html">Issue 54, 2022-08-29</a></p>
					<h1 class="articletitle">Ontology for Voice, Instruments, and Ensembles (OnVIE): Revisiting the Medium of Performance Concept for Enhanced Discoverability</h1>
					<div class="abstract">
						<p>Medium of performance—instruments, voices, and devices—is a frequent starting point in library users’ search for music resources. However, content and encoding standards for library cataloging have not been developed in a way that enables clear and consistent recording of medium of performance information. Consequently, unless specially configured, library discovery systems do not display medium of performance or provide this access point. Despite efforts to address this issue in the past decade in RDA, MARC, and the linked data environment, medium of performance information continues to be imprecise, dispersed across multiple fields or properties, and implied in other data elements. This article proposes revised definitions for “part,” “medium,” “performer,” and “ensemble,” along with a linked data model, the Ontology for Voice, Instruments, and Ensembles (OnVIE), that captures precise and complete medium of performance data reflecting music compositional practices, performance practices, and publishing conventions. The result is an independent medium of performance framework for recording searchable and machine-actionable metadata that can be hooked on to established library metadata ontologies and is widely applicable to printed and recorded classical, popular, jazz, and folk music. The clarity, simplicity, and extensibility of this model enable machine parsing so that the data can be searched, filtered, sorted, and displayed in multiple, creative ways.</p>
					</div>
					<div class="entry">
						<p>By <a href="https://orcid.org/0000-0002-2947-8652">Kimmy Szeto</a></p>
<h2>Introduction</h2>
<p>Medium of performance—the instruments, voices, and devices at the library users’ disposal—is a frequent starting point in their search for music resources, and an identifying element of musical works and expressions (<a id="ref1" href="../index.html%3Fp=16608.html#note1">Ostrove, 2001</a>). However, the limited availability and functionality of medium of performance as an access point has persisted from the physical card catalog, through the MARC era, into current developments of linked data ontologies.</p>
<p>Uniquely important to music resources, medium of performance refers to the tools involved in expressing a musical work. Historically, the term “medium” is not well defined in cataloging rules, and some instructions and practices are incompatible with linked data modeling practice today. Medium of performance has been recorded as supplemental information in the title area (<a id="ref2" href="../index.html%3Fp=16608.html#note2">Coyle, 2011</a>) and in the subject area (<a id="ref3" href="../index.html%3Fp=16608.html#note3">Subject Analysis Committee, 2017</a>), and did not receive much attention as an independent data element until the release of the current generation of library cataloging standard Resource Description and Access (RDA) in 2010. Inheriting the basic outline from earlier standards, RDA instructs catalogers to record a list of instruments, voices, and ensembles, followed by the number of parts and total number, and, when necessary, further identifying characteristics.</p>
<p>Cataloging practice continues to treat medium of performance as a single entity. The reality, however, is not as simple. Tracing a musical work from its composition to performance, subsumed in what is broadly termed “medium of performance” is a network of relationships involving the composer (musical parts), the publisher (published scores and parts), the instruments/voices (mediums), the performers, and the ensembles. From the library users’ standpoint, the single list of instruments/voices and numbers in the data does not always match the score and parts in the actual publication, and often does not provide enough information about the specific instruments, devices, and players required for planning a reading or a performance.</p>
<p>While these more complex relationships pose a challenge for the MARC format to encode, linked data models offer the capability. Linked data —a set of technologies and practices that foster publishing and connecting structured data on the web— have been increasingly embraced in the past decade by the library community as a means to provide open access to its richly curated bibliographic catalogs. Although some attempts have been made to refine the medium of performance element in linked data models, such as in the Performed Music Ontology (PMO), so far, no library linked data model has been built out beyond alignment with RDA/MARC format and conversion of existing data.</p>
<p>In the context of expanding the conception of the medium of performance element, this article lays out broadened definitions for “part,” “performer” and “ensemble” as described in <a id="ref4" href="../index.html%3Fp=16608.html#note4">Szeto (2017)</a>, proposes a revised definition for the term “medium,” and, based on these revised definitions, presents a new data model, the Ontology for Voices, Instruments, and Ensembles (OnVIE). OnVIE gives medium of performance additional dimensions by simultaneously capturing and relating the composer’s intended performing forces, published parts, specific instruments, voices, and devices required/used, as well as specific performers. The clarity, simplicity, and extensibility of this model enable more nuanced machine parsing so that the data can be searched and displayed in multiple, creative ways.</p>
<h2>Modeling Medium of Performance</h2>
<p>This paper will first discuss the development of OnVIE in the context of RDA, the current content standard, as encoded in MARC field 382. The next section will turn to the Performed Music Ontology, an extension for music resources specifically developed as an extension for BIBFRAME, the general linked data model being developed for library bibliographic data to replace MARC.</p>
<h3>Recent Cataloging Practice</h3>
<p>Prior to the 2000s, the tripartite division of author, title, and subject of the card catalog resulted in cataloging rules and decades of practices that embedded medium of performance information in the uniform title when it is necessary to distinguish between identical titles and in subject heading form subdivisions (<a id="ref5" href="../index.html%3Fp=16608.html#note5">Elmer, 1960</a>). The MARC format did offer field 048 for medium of performance, but the fields held only codes and numbers for voices, instruments, and ensembles, which were not readily decipherable to catalogers and users alike. This coded field fell into disuse, and users mainly relied on a free text note and clues from the title and subject headings. The dispersal of structured data complicated display and indexing, resulting in a limited ability for users to search directly or filter medium of performance search results (<a id="ref3" href="../index.html%3Fp=16608.html#note3">Subject Analysis Committee, 2017</a>). This is particularly problematic for compilations, vocal music, folk music, jazz, and recorded popular music where medium of performance is generally not explicitly stated bibliographically (<a id="ref6" href="../index.html%3Fp=16608.html#note6">Newcomer et al., 2013, section II.D</a>).</p>
<p>These limitations led to coordinated efforts to raise the visibility of this data element. In 2007, the Library of Congress, collaborating with a range of stakeholders, initiated developments in three areas: a dedicated faceted vocabulary Library of Congress Medium of Performance Thesaurus (LCMPT) was launched in 2014 (<a id="ref7" href="../index.html%3Fp=16608.html#note7">Library of Congress, 2014</a>), a new MARC field 382 for an expanded encoding of medium of performance data based on RDA instructions was established in 2010 (<a id="ref8" href="../index.html%3Fp=16608.html#note8">Library of Congress, 2020</a>), and programmatic changes that extracted existing authority data from the uniform title to be placed into the 382 field took place on WorldCat (<a id="ref9" href="../index.html%3Fp=16608.html#note9">Library of Congress, 2012</a>). With these three areas in place, programmatic retrospective implementation of faceted vocabulary in both authority and bibliographic records continues to this day (<a id="ref10" href="../index.html%3Fp=16608.html#note10">Mullin, 2018</a>; <a id="ref11" href="../index.html%3Fp=16608.html#note11">Subject Analysis Committee, 2022</a>).</p>
<p>Below is an excerpt from a MARC record on WorldCat (<a id="ref12" href="../index.html%3Fp=16608.html#note12">OCLC number 989164116</a>) that illustrates how medium of performance information is recorded in the uniform title (field 240) and the subject headings (field 650) and coded in fields 048 and 382. It might not be immediately apparent, from the way the uniform title and subject headings are constructed and structured, that this record is based on a musical score for solo harpsichord with piano accompaniment. (There is no string orchestra!) What might (or might not!) help library users is the note in field 500, a phrase typically used for this situation in music cataloging practice. Unfortunately, the note is not present in the actual WorldCat record, but was added here by the author to illustrate the difficulties posed to human readers and computer algorithms alike. The issue with clarity of semantics was identified and critiqued in Coyle (<a href="../index.html%3Fp=16608.html#note2">2011</a>), and the retrospective implementation of LCMPT and field 382 to address this issue was detailed in Mullin (<a id="ref10" href="../index.html%3Fp=16608.html#note10">2018</a>).</p>
<pre>
048 ##  $b kc01 $a ka01
240 10  $a Concertos, $m harpsichord, string orchestra, $n BWV 1052, $r D minor; $o arranged
382 01  $b harpsichord $n 1 $a piano $n 1 $s 2 $2 lcmpt
500 ##  $a Acc. arr. for piano. 
650 #0  $a Concertos (Harpsichord with string orchestra) $v Solo with piano.
</pre>
<h3>Data Modeling Considerations</h3>
<p>While these efforts have enabled structured medium of performance data in bibliographic records using LCMPT as the controlled vocabulary, the implementation remains less than ideal. RDA inherited the broad outlines from earlier standards—”the instrument, instruments, voice, voices, etc. for which a musical work was originally conceived” (<a id="ref13" href="../index.html%3Fp=16608.html#note13">RDA 6.15.1.1</a>), and then “record each instrument…” (<a href="../index.html%3Fp=16608.html#note13">RDA 6.15.1.4</a>) or “record an/the appropriate term…” that groups instruments and voices by family or into an ensemble (<a href="../index.html%3Fp=16608.html#note13">RDA 6.15.1.6 to 6.15.1.10</a>). These terms, depending on their characteristics, are encoded in MARC 382 subfields $a, $d, $d, and $p. After each term, RDA instructs the cataloger to record the number of parts (<a href="../index.html%3Fp=16608.html#note13">RDA 6.15.1.3</a>). This number is then encoded in MARC 382 subfields $e, $n or $r, which are defined for the number of performers or ensembles. In addition, MARC 382 offers subfields $s and $t for the total numbers of performers and ensembles.</p>
<p>This practice creates some data subfields that are not unambiguous in some cases and not atomic in some others. In the course of resolving ambiguity and atomicity issues, two fundamental principles of linked data design for the semantic web, it became apparent that separate definitions for part, medium, performer, and ensemble could offer the overarching solution.</p>
<h4>Ambiguity and Atomicity Issues</h4>
<p>The RDA instruction to record the number of “parts” which is then encoded in the “number of performers” subfield $n in MARC field 382 creates a semantic ambiguity. The OnVIE model will treat part and performer as two separate concepts. Another conflation occurs in the usage of terms such as “percussion” and “continuo” as mediums, when these mediums are actually parts referring to a group of instruments. The OnVIE model will provide clarity by allowing the individual instruments to be linked to these parts.</p>
<p>Another ambiguous practice is conflating individual instruments/voices with ensembles, and encoding them in the same MARC subfields, even though ensembles are not themselves instruments or voices. However, it is not always clear what exactly forms an ensemble. Is the string quartet an ensemble of instruments? Is it a group of performers? Or is it a group of parts? In the OnVIE model, individual parts are used as the starting point, and a group of parts will form an ensemble. This way, all of the ensemble’s constituent parts will always be known, as will the mediums be linked to each part.</p>
<p>Separate instructions are given in RDA for music intended for one performer to a part as opposed to more than one performer to a part. The attributes of “solo” and “accompaniment” are also treated separately. However, these are not characteristics of the mediums, but are characteristics of the parts. (For example, the instrument violin itself cannot possess the quality of “solo” but a violin part can.) In OnVIE, the number of performers to a part, the solo status, and the accompaniment status will all be treated as refinements to the part, rather than as separate classes of entities.</p>
<p>More specifically, RDA instructs the cataloger to omit the accompanying keyboard instrument (such as a piano) in a classical song for solo voice (<a href="../index.html%3Fp=16608.html#note13">RDA 6.15.1.11</a>). While the piano is not an unreasonable assumption among musicians, such an arbitrary exception causes the discovery system to return incomplete results, which could complicate a library user’s search, especially for a vocalist looking for repertoire regardless of the accompaniment.</p>
<h4>Special Issue: Number of Hands</h4>
<p>RDA instructs the “number of hands,” if other than two, to be recorded (<a href="../index.html%3Fp=16608.html#note13">RDA 6.15.1.5.1</a>). This poses an impossibility in the encoding mechanism in MARC field 382. While the number of performers is encoded in subfield $n, there is nowhere to encode the number of instruments, or which hand is being used. While “piano, 4 hands,” where two pianists use all four hands on a single piano, is a fairly common genre, piano duets—two pianos and two pianists—is not uncommon either, especially in more recent repertoire with the two pianos tuned a quarter tone apart (for example, <em>Chiaroscuro for two pianos (one tuned down a 1/4 tone)</em> by John Corigliano (<a id="ref14" href="../index.html%3Fp=16608.html#note14">published 2011</a>)). Yet these are encoded identically as “$a piano $n 2,” and library users will need to inspect the free text notes, the subject heading, or the title. Suppose a piece of music was composed for two pianos with two players, each using only the left hand, or, suppose another piece of music was composed for two pianos with two players, one using both hands, the other using only the left hand, the result is still the same: “$a piano $n 2.” Figure 1, adapted from Szeto (<a id="ref15" href="../index.html%3Fp=16608.html#note15">2016, slide 22</a>), further illustrates this issue with combinations of two pianos and six hands. Meanwhile, a piece of music composed for two pianos and one player (for example, <em>Trois hommages for 2 pianos (tuned a quarter tone apart) 2 hands</em> by Georg Friedrich Haas (<a id="ref16" href="../index.html%3Fp=16608.html#note16">published 2009</a>)) would be encoded as “$a piano $n 1,” identical to solo piano music (one piano, one player).</p>
<p><img decoding="async" src="../media/issue54/szeto/figure1.png" /></p>
<p class="caption"><strong>Figure 1.</strong> Combinations of pianos and hands that cannot be differentiated in RDA descriptions or encoded in MARC field 382.</p>
<p>At present, when these distinctions, or any other distinctions discussed above, cannot be expressed in the MARC 382 field, the cataloger is instructed to provide clarification in a free text note in subfield $v. In the OnVIE model, separate treatments for part and performer will remove this issue.</p>
<h4>Additional RDA Medium of Performance Characteristics</h4>
<p>RDA includes instructions for three more attributes: pitch and range of instruments, doubling, and alternative.</p>
<h5>Pitch and Range</h5>
<p>The “pitch” of the instrument here refers to musical instruments that are “transposed,” where playing with the same set of fingering and sound production techniques on the instrument yields a different set of pitches (for example, clarinet in B-flat). What RDA referred to as “range” refers to instruments that come in common sizes (for example, the saxophone family includes soprano, alto, tenor, and baritone). Pitch and range are recorded only when the cataloger considers them important for identification and access (<a href="../index.html%3Fp=16608.html#note13">RDA 6.15.1.5.1</a>) and appears in MARC field 382 as a free text note in subfield $v. The OnVIE model will include further refined properties for these, applied separately to parts and mediums.</p>
<h5>Doubling</h5>
<p>Instrumental doubling refers to a musical part that instructs a single performer to use more than one instrument. When recorded, the medium is encoded in MARC 382 subfield $d. This structure seems straightforward for a traditional orchestral doubling, such as a flute player who also plays the piccolo. This is not so straightforward for other parts that are less clearly defined, for example, an orchestral percussion part where multiple players share a set of percussion instruments, or where a timpani player occasionally joins other percussionists (timpani is recorded separately from percussion). Currently, the instruction is to record the term “percussion” alone. Neither RDA nor MARC offers a solution for this entanglement between performers, mediums, and parts. Separating them in the OnVIE model will remove this issue.</p>
<h5>Alternative</h5>
<p>RDA instructions for “alternative instruments” (<a href="../index.html%3Fp=16608.html#note13">RDA 6.15.1.5.3</a>) invite further refinement. In current practice, “alternative” is used for a range of situations where one or more mediums deviate from the original. While some composers expressly indicate that the identical part may be used on more than one instrument (for example, the “Flute or Violin” part in the jazz composition <em>Out of the Cool</em> by David Heath (<a id="ref17" href="../index.html%3Fp=16608.html#note17">as published in 1986</a>)), in most cases, what are also considered alternatives range from slightly different (for example, clarinet music transcribed for the viola; see <a id="ref18" href="../index.html%3Fp=16608.html#note18">Swanson, 2003, pp. 13-15</a> for the process of compiling the repertoire list which could have been aided by a direct medium of performance search), to quite different (for example, a continuo part realized for piano), to drastically different (for example, orchestra music in operatic works arranged for piano with no change in the vocal parts). The OnVIE model will be able to precisely indicate the first case where the part is identical, and a hook is provided for future extensions that capture the various degrees of change. There are also situations where the alternative involves a role change in one or more parts (for example, the arrangements of the <em>Scherzo</em> movement in Robert Schumann’s second symphony (as published in Szeto, <a id="ref19" href="../index.html%3Fp=16608.html#note19">2010a</a> and <a id="ref20" href="../index.html%3Fp=16608.html#note20">2010b</a>) where the first violin part could be a solo part or an ensemble part; the arrangement of the overture to Leoš Janácek’s <em>From the House of the Dead</em> (as published in <a id="ref21" href="../index.html%3Fp=16608.html#note21">Szeto, 2013</a>), where the violin part changed to solo and the trumpet part could optionally be offstage). Currently, data cannot be simultaneously encoded as alternative (in $p) and as solo (in $b) in MARC field 382, whereas OnVIE imposes no restrictions on these refinements. Equally important is the consideration of whether the alternative is so different that the music should be considered a separate musical expression or an entirely new musical work. This is outside the scope of this article but was discussed in more detail in <a href="../index.html%3Fp=16608.html#note4">Szeto (2017)</a>, and the data modeling is an active area of investigation under various keywords such as music information retrieval, arrangement, versions, and annotation (<a id="ref22" href="../index.html%3Fp=16608.html#note22">Weiß et al., 2021</a>; <a id="ref23" href="../index.html%3Fp=16608.html#note23">Lewis et al., 2022</a>).</p>
<p>More specifically, the Library of Congress Policy Statements for <a href="../index.html%3Fp=16608.html#note13">RDA 6.18.1.4</a> instructs catalogers whether or not to consider alternatives or arrangements in a range of conditions, such as slight alterations to instrumentation in an orchestral piece, early music composed before 1800 performed on modern instruments, and a change from vocal to instrumental in the popular music idiom. While such practices to make an either/or judgment are essential for the classification and collocation of physical materials, the OnVIE model will remove much of these artificial criteria by simply allowing all parts and mediums to be recorded completely and precisely.</p>
<p>Another common situation is alternative voices (such as a song for soprano sung by a tenor, or for alto sung by a bass). This is an ambiguity issue where the voice part is the same but the property of the medium differs. In the OnVIE model, soprano/alto/tenor/bass can be indicated as refinements to the medium “voice.”</p>
<h3>BIBFRAME and the Performed Music Ontology</h3>
<p>The Bibliographic Framework Initiative (BIBFRAME) is a Library of Congress initiative to develop a linked data alternative to MARC. The Library of Congress initially worked with the Music Library Association to model the medium of performance element but later abandoned the effort. Instead, the BIBFRAME model left “hooks” for a full model to be developed by a third party (<a id="ref24" href="../index.html%3Fp=16608.html#note24">Szeto et al., 2016, p. 32</a>).</p>
<p>In response, the Performed Music Ontology (<a id="ref25" href="../index.html%3Fp=16608.html#note25">PMO, 2021</a>) was developed as an extension of the BIBFRAME ontology with a focus on describing performed music. The medium of performance portion of the PMO model tracks closely with RDA and MARC practices. PMO begins with making the distinction between the declared medium, which is stated by the composer or in a reference source, and the performed medium, which was used in the actual performance and not necessarily the same as the declared medium. The PMO has separate properties for individual and ensemble mediums, a separate class for “part,” as well as properties to connect performers to their instruments, voices, and dramatic roles. However, PMO follows RDA instructions where solo, alternative, and doubling are separately addressed, while other attributes are recorded as literals (free text) in a single catch-all “part type” property. The OnVIE model will break away from the RDA/MARC structure, and will provide an extensible structure for characteristics to be encoded as linked data with clear semantics.</p>
<p>Unlike PMO where medium of performance classes depend on linking to the parent ontology at multiple points (<em>bf:NotatedMusic</em> for <em>pmo:DeclaredMedium</em>, <em>bf:Audio</em> for <em>pmo:PerformedMedium</em>, <em>bf:Contribution</em> for the <em>pmo:IndividualMOP</em> and <em>pmo:MusicPart</em>), the OnVIE model exists in a self-contained, independent space requiring only a single “hook” to the musical resource being described. The first contact on this hook is “Parts.” By beginning with this layer, the OnVIE model no longer requires differentiation between mediums that were notional or actual.</p>
<h2>A New Data Model for Medium of Performance</h2>
<h3>Ontology for Voice, Instruments, and Ensembles</h3>
<p>The primary motivation, and innovation, of the OnVIE model is capturing the relationship between part, medium, performer, and ensemble, which form the four main classes of the ontology. The first three main classes follow a loop: Part connects to Medium, Medium connects to Performer, and Performer loops back to Part. The class Ensemble forms a branch by grouping one or more Part entities. These relationships are shown in Figure 2.</p>
<p><img decoding="async" src="../media/issue54/szeto/figure2.png" /></p>
<p class="caption"><strong>Figure 2.</strong> Class relationships in the Ontology for Voice, Instruments, and Ensembles.</p>
<p>All further refinements to the model fall within this framework. The list of refinements presented here consists of data that are currently recorded in cataloging practice, fixes to known issues, with many more properties that cover characteristics of specifical musical settings, parts, instruments, voices, devices, etc. OnVIE’s simple framework allows it to be readily extensible through additional refinements.</p>
<h3>Definitions</h3>
<h4>Part</h4>
<p>Class: MusicPart<br />
Scope: a series of musical events, abstracted from a musical work/expression, generally independent from other such abstractions from the same musical work/expression, which holds a consistent association with one or more mediums and/or performers<br />
Note: A part is not equivalent to, but may be related to, a “printed part” (sheet music for an individual voice/instrument that does not contain notation for other voices/instruments of an ensemble), or a “voice” or “line” (individual melodies of polyphonic musical composition)<br />
Examples: &#8220;Violin&#8221; ; &#8220;Percussion&#8221; ; &#8220;Mezzo-Soprano&#8221; ; &#8220;Horns&#8221;</p>
<h4>Medium</h4>
<p>Class: MusicMedium<br />
Scope: a tool of sound production for a musical work/expression<br />
Note: Mediums include human voices, musical instruments, devices, and other means<br />
Examples: &#8220;violin&#8221; ; &#8220;marimba&#8221; ; &#8220;voice&#8221; ; &#8220;saxophone&#8221; ; terms in LCMPT and UNIMARC codes for individual voice, instruments, and devices</p>
<h4>Performer</h4>
<p>Class: MusicPerformer<br />
Scope: an agent responsible for expressing or actuating one or more parts<br />
Note: Performers include humans, machines, computers, and other entities<br />
Examples: &#8220;Violinist&#8221; ; &#8220;Percussionist&#8221; ; &#8220;Vocalist&#8221; ; &#8220;Saxophonist&#8221; ; entities referring to actual persons in vocabularies such as LCNAF and VIAF</p>
<h4>Ensemble</h4>
<p>Class: MusicEnsemble<br />
Scope: a group of parts in a musical work/expression<br />
Note: in this model, only part groupings are used, even for ensembles traditionally known for the personas or the instruments (for example, string quartet)<br />
Examples: &#8220;Orchestra&#8221; ; &#8220;Percussion quartet&#8221; ; &#8220;Children&#8217;s choir&#8221; ; &#8220;Jazz combo&#8221; ; ensemble terms in LCMPT and UNIMARC codes ; LCNAF, VIAF, or other vocabularies for names</p>
<h3>Classes and Properties</h3>
<p>The OnVIE model is built with the library users’ starting point in mind: the instruments, voices, and devices (class MusicMedium). The connecting layer between the medium and the music resource is the concept of “part” (class MusicPart). The term “part” has been occasionally used in definitions and instructions, and occasionally conflated with voices, instruments, and performers, as discussed above. Here, a new definition has been developed for this layer, distinct from MusicMedium and MusicPerformer.</p>
<p>The OnVIE model begins with at least one MusicPart. A MusicPart can link to other MusicPart entities when alternatives or further subdivisions are present, or can link to printed published parts which could differ. Every MusicPart is required to have at least one MusicMedium, even if it is unmediated (such as a spectator). MusicPart can link to more than one entity in MusicMedium, such as in the case of instrumental doubling or a single percussion part calling for multiple instruments. For musical scores, it ends here. For performed music, including popular, folk, and jazz that exist only as sound recordings, performers (class MusicPerformer) are linked from MusicMedium, and each MusicPerformer loops back to one or more entities in MusicPart.</p>
<p>Ensembles are not considered mediums, but are a separate class (class MusicEnsemble), formed by an aggregate of individual parts. This departure from current cataloging practice prevents ensemble terms from being used as mediums, but rather encourages a complete accounting of mediums involved.</p>
<p>The four main properties of this model connect these classes. Refinements are provided to describe each in further detail. The list of refinement properties presented here was drawn from the current models as well as from the author’s own experience as an ensemble librarian, and is by no means exhaustive.</p>
<p>What is not included in this model are the numbers. Rather than requiring catalogers and metadata creators to supply the number of parts, performers, and ensembles, the granularity of the model enables linked data interpreter software to perform the counting. This method not only provides the flexibility to produce separate counts for parts, mediums, performers, and ensembles, it also removes the uncertainty and detailed analysis (or guesswork!) required to arrive at the number of performers needed for group-oriented parts such as percussion and continuo. By interpreting the refinements, machine counting can also provide the total, as well as further numerical breakdowns for soloists, accompanying performers, ensembles, and voice/vocal parts.</p>
<h3>The Ontology</h3>
<div class="caption"><strong>Table 1.</strong> Classes.</p>
<table align="center">
<thead>
<tr>
<th>Class</th>
<th>Subclass of</th>
</tr>
</thead>
<tbody>
<tr>
<td>MediumOfPerformance</td>
<td>Musical Works/Expressions</td>
</tr>
<tr>
<td>MusicMedium</td>
<td>MediumOfPerformance</td>
</tr>
<tr>
<td>MusicPart</td>
<td>MediumOfPerformance</td>
</tr>
<tr>
<td>MusicPerformer</td>
<td>MediumOfPerformance</td>
</tr>
<tr>
<td>MusicEnsemble</td>
<td>MediumOfPerformance</td>
</tr>
</tbody>
</table>
</div>
<p>&nbsp;</p>
<div class="caption">
<p><strong>Table 2.</strong> Properties.</p>
<table align="center">
<thead>
<tr>
<th>Property</th>
<th>Use with</th>
<th>Expected value</th>
</tr>
</thead>
<tbody>
<tr>
<td>hasMusicPart</td>
<td>MediumOfPerformance ; MusicPart</td>
<td>MusicPart</td>
</tr>
<tr>
<td>isMusicPartOf</td>
<td>MusicPart</td>
<td>MusicPart ; MediumOfPerformance</td>
</tr>
<tr>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>hasMusicMedium</td>
<td>MusicPart</td>
<td>MusicMedium</td>
</tr>
<tr>
<td>isMusicMediumOf</td>
<td>MusicMedium</td>
<td>MusicPart</td>
</tr>
<tr>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>hasMusicPerformer</td>
<td>MusicMedium</td>
<td>MusicPerformer</td>
</tr>
<tr>
<td>isMusicPerformerOf</td>
<td>MusicPerformer</td>
<td>MusicMedium</td>
</tr>
<tr>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>isResponsibleForMusicPart</td>
<td>MusicPerformer</td>
<td>MusicPart</td>
</tr>
<tr>
<td>isPerformedBy</td>
<td>MusicPart</td>
<td>MusicPerformer</td>
</tr>
</tbody>
</table>
</div>
<p>&nbsp;</p>
<div class="caption">
<p><strong>Table 3.</strong> Refinements.</p>
<table align="center">
<thead>
<tr>
<th>Property</th>
<th>Use with</th>
<th>Expected value</th>
<th>Notes</th>
<th>Examples</th>
</tr>
</thead>
<tbody>
<tr>
<td>rdfs:label</td>
<td>MediumOfPerformance ; MusicPart ; MusicMedium ; MusicEnsemble</td>
<td>literal</td>
<td></td>
<td></td>
</tr>
<tr>
<td>xml:lang</td>
<td>MediumOfPerformance ; MusicPart ; MusicMedium ; MusicEnsemble</td>
<td>URI</td>
<td>Language code of the term</td>
<td></td>
</tr>
<tr>
<td>source</td>
<td>MediumOfPerformance ; MusicPart ; MusicMedium ; MusicEnsemble</td>
<td>URI</td>
<td>Source of information</td>
<td></td>
</tr>
<tr>
<td>sourceType</td>
<td>MediumOfPerformance ; MusicPart ; MusicMedium ; MusicEnsemble</td>
<td>&#8220;transcribed&#8221; ; &#8220;recorded&#8221; ; &#8220;published&#8221; ; &#8220;inferred&#8221; ; &#8220;editorial&#8221; ; &#8220;programmatic update&#8221; ; etc.</td>
<td></td>
<td></td>
</tr>
<tr>
<td>sourceNote</td>
<td>MediumOfPerformance ; MusicPart ; MusicMedium ; MusicEnsemble</td>
<td>literal</td>
<td></td>
<td>“First page of music”</td>
</tr>
<tr>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>alternative</td>
<td>MediumOfPerformance ; MusicPart ; MusicMedium ; MusicEnsemble</td>
<td>&#8220;Is alternative&#8221; ; &#8220;Is not alternative&#8221; ; &#8220;Performer&#8217;s choice&#8221; ; &#8220;Unspecified&#8221; ; &#8220;Unknown&#8221;</td>
<td></td>
<td></td>
</tr>
<tr>
<td>alternativeType</td>
<td>MediumOfPerformance ; MusicPart ; MusicMedium ; MusicEnsemble</td>
<td>URI</td>
<td>* hook for the full consideration of types of musical alternation/arrangement/transcription/adaptation</td>
<td></td>
</tr>
<tr>
<td>alternativeNote</td>
<td>MediumOfPerformance ; MusicPart ; MusicMedium ; MusicEnsemble</td>
<td>literal</td>
<td></td>
<td>&#8220;identical&#8221; ; &#8220;arranged for viola&#8221; ; &#8220;transcribed for solo piano&#8221; [concerto, jazz] ; &#8220;piano reduction&#8221; [orchestral accompaniment] ; &#8220;adapted for the violin&#8221; [folk music] ; &#8220;combined percussion part for one player&#8221;</td>
</tr>
<tr>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>partNumber</td>
<td>MusicPart</td>
<td>whole number &gt;=0</td>
<td></td>
<td>“Violin 1” ; “Percussion 2”</td>
</tr>
<tr>
<td>playerToAPart</td>
<td>MusicPart</td>
<td>&#8220;Specified&#8221; ; &#8220;Multiple&#8221; ; &#8220;Performer&#8217;s choice&#8221; ; &#8220;Unspecified&#8221; ; &#8220;Unknown&#8221;</td>
<td></td>
<td></td>
</tr>
<tr>
<td>playerToAPartNumber</td>
<td>MusicPart</td>
<td>whole number &gt;=0</td>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>solo</td>
<td>MusicPart ; MusicMedium ; MusicEnsemble</td>
<td>&#8220;Is solo&#8221; ; &#8220;Is not solo&#8221; ; &#8220;Performer&#8217;s choice&#8221; ; &#8220;Unspecified&#8221; ; &#8220;Unknown&#8221;</td>
<td></td>
<td></td>
</tr>
<tr>
<td>accompaniment</td>
<td>MusicPart ; MusicMedium ; MusicEnsemble</td>
<td>&#8220;Is an accompaniment&#8221; ; &#8220;Is not an accompaniment&#8221;</td>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>optional</td>
<td>MusicPart ; MusicMedium</td>
<td>&#8220;Is optional&#8221; ; &#8220;Is not optional&#8221; ; &#8220;Performer&#8217;s choice&#8221; ; &#8220;Unspecified&#8221; ; &#8220;Unknown&#8221;</td>
<td></td>
<td></td>
</tr>
<tr>
<td>ad lib</td>
<td>MusicPart ; MusicMedium</td>
<td>&#8220;Is ad lib&#8221; ; &#8220;Is not ad lib&#8221; ; &#8220;Performer&#8217;s choice&#8221; ; &#8220;Unspecified&#8221; ; &#8220;Unknown&#8221;</td>
<td></td>
<td></td>
</tr>
<tr>
<td>offstage</td>
<td>MusicPart ; MusicMedium</td>
<td>&#8220;Is offstage&#8221; ; &#8220;Is not offstage&#8221; ; &#8220;Performer&#8217;s choice&#8221; ; &#8220;Unspecified&#8221; ; &#8220;Unknown&#8221;</td>
<td></td>
<td></td>
</tr>
<tr>
<td>obligato</td>
<td>MusicPart ; MusicMedium</td>
<td>&#8220;Is an obligato part&#8221; ; &#8220;Is not an obligato part&#8221; ; &#8220;Performer&#8217;s choice&#8221; ; &#8220;Unspecified&#8221; ; &#8220;Unknown&#8221;</td>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>amplified</td>
<td>MusicPart ; MusicMedium</td>
<td>&#8220;Is amplified&#8221; ; &#8220;Is not amplified&#8221; ; &#8220;Performer&#8217;s choice&#8221; ; &#8220;Unspecified&#8221; ; &#8220;Unknown&#8221;</td>
<td></td>
<td></td>
</tr>
<tr>
<td>prerecorded</td>
<td>MusicPart ; MusicMedium</td>
<td>&#8220;Is prerecorded&#8221; ; &#8220;Is not prerecorded&#8221; ; &#8220;Performer&#8217;s choice&#8221; ; &#8220;Unspecified&#8221; ; &#8220;Unknown&#8221;</td>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>periodInstrument</td>
<td>MusicPart ; MusicMedium</td>
<td>&#8220;Is a period instrument&#8221; ; &#8220;Is not a period instrument&#8221; ; &#8220;Performer&#8217;s choice&#8221; ; &#8220;Unspecified&#8221; ; &#8220;Unknown&#8221;</td>
<td></td>
<td></td>
</tr>
<tr>
<td>periodInstrumentNote</td>
<td>MusicPart ; MusicMedium</td>
<td>URI or literal</td>
<td></td>
<td>“Baroque” [flute]</td>
</tr>
<tr>
<td>fingeringSystem</td>
<td>MusicPart ; MusicMedium</td>
<td>URI</td>
<td></td>
<td>“German” [recorder]</td>
</tr>
<tr>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>tuningSystem</td>
<td>MusicPart ; MusicMedium</td>
<td>URI</td>
<td></td>
<td>“Just intonation” ; “pythagorean” ; “equal temperament”</td>
</tr>
<tr>
<td>tuningReferencePitch</td>
<td>MusicPart ; MusicMedium</td>
<td>URI</td>
<td>The pitch name of the tuning reference pitch.</td>
<td>&#8220;A&#8221;</td>
</tr>
<tr>
<td>tuningReferenceFrequencyHz</td>
<td>MusicPart ; MusicMedium</td>
<td>number &gt;=0</td>
<td>The frequency of the tuning reference pitch in hertz.</td>
<td>“432”</td>
</tr>
<tr>
<td>scordatura</td>
<td>MusicPart ; MusicMedium</td>
<td>&#8220;Is tuned scordatura&#8221; ; &#8220;Is not tuned scordatura&#8221; ; &#8220;Performer&#8217;s choice&#8221; ; &#8220;Unspecified&#8221; ; &#8220;Unknown&#8221;</td>
<td>Tuning of a western string instrument which deviates from the standard tuning.</td>
<td></td>
</tr>
<tr>
<td>tuningNote</td>
<td>MusicPart ; MusicMedium</td>
<td>literal</td>
<td></td>
<td>“Piano is tuned quarter tone flat” ; &#8220;Drop D&#8221; [guitar]</td>
</tr>
<tr>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>handsNumber</td>
<td>MusicPart ; MusicMedium</td>
<td>whole number &gt;=1</td>
<td>Number of hands playing an instrument</td>
<td></td>
</tr>
<tr>
<td>handsSide</td>
<td>MusicPart ; MusicMedium ; MusicPerformer</td>
<td>&#8220;Left&#8221; ; &#8220;Right&#8221; ; &#8220;Performer&#8217;s choice&#8221; ; &#8220;Unspecified&#8221; ; &#8220;Unknown&#8221;</td>
<td>Which hand is being used for playing an instrument</td>
<td></td>
</tr>
<tr>
<td>handsNote</td>
<td>MusicPart ; MusicMedium ; MusicPerformer</td>
<td>literal</td>
<td></td>
<td>&#8220;piano (2), 3 hands&#8221;</td>
</tr>
<tr>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>doubleBassCExtension</td>
<td>MusicPart ; MusicMedium</td>
<td>&#8220;Requires a C Extention&#8221; ; &#8220;Does not requires a C Extension&#8221; ; &#8220;Performer&#8217;s choice&#8221; ; &#8220;Unspecified&#8221; ; &#8220;Unknown&#8221;</td>
<td></td>
<td></td>
</tr>
<tr>
<td>fluteBFoot</td>
<td>MusicPart ; MusicMedium</td>
<td>&#8220;Requires a B Foot&#8221; ; &#8220;Does not require a B Foot&#8221; ; &#8220;Performer&#8217;s choice&#8221; ; &#8220;Unspecified&#8221; ; &#8220;Unknown&#8221;</td>
<td></td>
<td></td>
</tr>
<tr>
<td>instrumentMute</td>
<td>MusicPart ; MusicMedium</td>
<td>URI</td>
<td></td>
<td></td>
</tr>
<tr>
<td>instrumentMuteNote</td>
<td>MusicPart ; MusicMedium</td>
<td>literal</td>
<td></td>
<td></td>
</tr>
<tr>
<td>instrumentDimension</td>
<td>MusicPart ; MusicMedium</td>
<td>URI</td>
<td>* hook for measurements of musical instruments</td>
<td></td>
</tr>
<tr>
<td>instrumentDimensionNote</td>
<td>MusicPart ; MusicMedium</td>
<td>literal</td>
<td></td>
<td>“26 inch” [timpani]</td>
</tr>
<tr>
<td>instrumentSize</td>
<td>MusicPart ; MusicMedium</td>
<td>URI</td>
<td>* hook for instrument sizes</td>
<td></td>
</tr>
<tr>
<td>instrumentSizeNote</td>
<td>MusicPart ; MusicMedium</td>
<td>literal</td>
<td></td>
<td>“Three-quarter” [guitar] ; “Concert” [ukelele]</td>
</tr>
<tr>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>instrumentPitch</td>
<td>MusicPart ; MusicMedium</td>
<td>URI</td>
<td>Pitch of single-pitched musical instruments</td>
<td>&#8220;C4&#8221; [crotale]</td>
</tr>
<tr>
<td>instrumentTransposition</td>
<td>MusicPart ; MusicMedium</td>
<td>URI</td>
<td>Key of transposing instruments</td>
<td>“A” [clarinet]</td>
</tr>
<tr>
<td>instrumentTranspositionNote</td>
<td>MusicPart ; MusicMedium</td>
<td>literal</td>
<td></td>
<td>“Clarinet in A”</td>
</tr>
<tr>
<td>instrumentRangeNumber</td>
<td>MusicPart ; MusicMedium</td>
<td>whole number &gt;=0</td>
<td>Pitch range of a musical instrument in number of half steps</td>
<td>&#8220;60&#8221; [marimba]</td>
</tr>
<tr>
<td>instrumentRangeLowest</td>
<td>MusicPart ; MusicMedium</td>
<td>URI</td>
<td>Lowest pitch of a musical instrument</td>
<td>&#8220;C2&#8221; [marimba]</td>
</tr>
<tr>
<td>instrumentRangeHighest</td>
<td>MusicPart ; MusicMedium</td>
<td>URI</td>
<td>Highest pitch of a musical instrument</td>
<td>&#8220;C7&#8221; [marimba]</td>
</tr>
<tr>
<td>instrumentNote</td>
<td>MusicPart ; MusicMedium</td>
<td>literal</td>
<td></td>
<td>“5 octaves&#8221; [marimba]</td>
</tr>
<tr>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>voiceType</td>
<td>MusicPart ; MusicMedium</td>
<td>URI</td>
<td></td>
<td>&#8220;Mezzo soprano&#8221; ; &#8220;Contralto&#8221;</td>
</tr>
<tr>
<td>voiceWeight</td>
<td>MusicPart ; MusicMedium</td>
<td>URI</td>
<td></td>
<td>&#8220;Spinto&#8221; ; &#8220;Soubrette&#8221;</td>
</tr>
<tr>
<td>voiceTessitura</td>
<td>MusicPart ; MusicMedium</td>
<td>URI</td>
<td></td>
<td>&#8220;High&#8221; ; &#8220;Medium&#8221; ; &#8220;Low&#8221;</td>
</tr>
<tr>
<td>voicePitchLowest</td>
<td>MusicPart ; MusicMedium</td>
<td>URI</td>
<td>Lowest pitch required of the vocalist</td>
<td></td>
</tr>
<tr>
<td>voicePitchHighest</td>
<td>MusicPart ; MusicMedium</td>
<td>URI</td>
<td>Highest pitch required of the vocalist</td>
<td></td>
</tr>
<tr>
<td>voiceNote</td>
<td>MusicPart ; MusicMedium</td>
<td>literal</td>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>technicalRequirement</td>
<td>MusicPart ; MusicMedium</td>
<td>URI</td>
<td>* hook for computer / recording carrier / playback device information</td>
<td></td>
</tr>
<tr>
<td>technicalRequirementNote</td>
<td>MusicPart ; MusicMedium</td>
<td>literal</td>
<td></td>
<td>&#8220;Requires an 8 track player&#8221;</td>
</tr>
</tbody>
</table>
</div>
<h2>Next Steps</h2>
<p>With the OnVIE model laid out conceptually in this paper, the next steps would be to formalize the ontology with modeler software, and, with the help of the library community, integrate into library linked data editors and test a range of use cases to further fine tune semantics, data constraints, and documentation. In the course testing, standardized vocabularies can be developed for the many characterizations in the list of refinements, possibly in alignment with open platforms such as Wikidata. Some suggestions for these “hooks” can be found in the “Notes” column in Table 3. Finally, pathways to publishing and maintaining the ontology can be explored.</p>
<p>Further analysis can be made in relation to the UNIMARC encoding standard, as well as to library-adjacent ontologies such as DoReMus, developed for analysis and visualization of music data, the Music Ontology, which focuses on capturing production of musical events, and MusicBrainz, which is widely used for sound recordings. As none of these ontologies currently includes a model built out for medium of performance, developing a mechanism to hook OnVIE on to them would be a worthwhile investigation. Another potentially fruitful area of study would be to align MusicParts in OnVIE with other ontologies where the concept is also used, such as the “Observations” object in the “Musicological Objects” layer in Lewis et al. (<a id="ref20" href="../index.html%3Fp=16608.html#note20">2022</a>).</p>
<h2>Conclusion</h2>
<p>Although linked data are designed to be machine-actionable, it is humans who ultimately employ the mediums with their voices, instruments, and other tools, to create music. It is also humans who are ultimately responsible for expressing and actuating each part of a musical work. This new Ontology for Voices, Instruments, and Ensembles, when hooked on to linked data bibliographic systems, will enable a medium of performance access point at a fine level of precision and completeness. Library users will be provided a more straightforward path not only toward identifying and selecting music resources, but also toward discovering additional insights into the evolution of performing forces in the history of music making, a whole new area of humanistic studies previously hidden in plain sight.</p>
<h2>Bibliography</h2>
<p><a id="note14" href="../index.html%3Fp=16608.html#ref14">Corigliano, J. (2011)</a>. Chiaroscuro: For two pianos (one tuned down a 1/4 tone) (ED 4435, HL 50490191). G. Schirmer.</p>
<p><a id="note2" href="../index.html%3Fp=16608.html#ref2">Coyle, K. (2011)</a>. MARC as metadata: A start. Code4lib Journal, 14. <a href="../index.html%3Fp=5468.html">https://journal.code4lib.org/articles/5468</a>.</p>
<p><a id="note5" href="../index.html%3Fp=16608.html#ref5">Elmer, M. (1960)</a>. The music catalog as a reference tool. Library Trends, 8(4), 529-538. <a href="https://www.ideals.illinois.edu/bitstream/handle/2142/5907/librarytrendsv8i4f_opt.pdf">https://www.ideals.illinois.edu/bitstream/handle/2142/5907/librarytrendsv8i4f_opt.pdf</a>.</p>
<p><a id="note16" href="../index.html%3Fp=16608.html#ref16">Haas, G. F. (2009)</a>. Trois hommages: Für zwei Klaviere (im Vierteltonabstand gestimmt) zu zwei Händen (1982/84) (UE 34 693). Universal Edition.</p>
<p><a id="note17" href="../index.html%3Fp=16608.html#ref17">Heath, D. (1986)</a>. Out of the cool: For flute (or violin) and piano (CH55693). Chester Music.</p>
<p><a id="note23" href="../index.html%3Fp=16608.html#ref23">Lewis, D., Shibata, E., Saccomano, M., Rosendahl, L., Kepper, J., Hankinson, A., Siegert, C., and Page, K. (2022)</a>. A model for annotating musical versions and arrangements across multiple documents and media. In 9th International Conference on Digital Libraries for Musicology (DLfM2022) (pp. 10-18). Association for Computing Machinery. <a href="https://doi.org/10.1145/3543882.3543891">https://doi.org/10.1145/3543882.3543891</a>.</p>
<p><a id="note9" href="../index.html%3Fp=16608.html#ref9">Library of Congress. (2012)</a>. Summary of programmatic changes to the LC/NACO Authority File: What LC-PCC RDA catalogers need to know. <a href="https://www.loc.gov/aba/rda/pdf/lcnaf_rdaphase.pdf">https://www.loc.gov/aba/rda/pdf/lcnaf_rdaphase.pdf</a>.</p>
<p><a id="note7" href="../index.html%3Fp=16608.html#ref7">Library of Congress. (2014)</a>. Library of Congress launches Medium of Performance Thesaurus for music. <a href="https://www.loc.gov/catdir/cpso/medprf-list-launch.html">https://www.loc.gov/catdir/cpso/medprf-list-launch.html</a>.</p>
<p><a id="note8" href="../index.html%3Fp=16608.html#ref8">Library of Congress. (2020)</a>. Content designator history. In 382 &#8211; Medium of Performance. <a href="https://www.loc.gov/marc/bibliographic/bd382.html">https://www.loc.gov/marc/bibliographic/bd382.html</a>.</p>
<p><a id="note10" href="../index.html%3Fp=16608.html#ref10">Mullin, C. (2018)</a>. An amicable divorce: Programmatic derivation of faceted data from Library of Congress Subject Headings for music. Cataloging &amp; Classification Quarterly, 56(7), 607-627. <a href="https://doi.org/10.1080/01639374.2018.1516709">https://doi.org/10.1080/01639374.2018.1516709</a>.</p>
<p><a id="note6" href="../index.html%3Fp=16608.html#ref6">Newcomer, N. L., Belford, R., Kulczak, D., Szeto, K., Matthews, J., &amp; Shaw, M. (2013)</a>. Music discovery requirements: A guide to optimizing interfaces. Notes, 69(3), 494-524. <a href="http://dx.doi.org/10.1353/not.2013.0017">http://dx.doi.org/10.1353/not.2013.0017</a>.</p>
<p><a id="note12" href="../index.html%3Fp=16608.html#ref12">Online Computer Library Center. (2022, May 24)</a>. OCLC 989164116. A publicly accessible version of this record as imported by University of California, Berkeley can be retrieved at <a href="https://search.library.berkeley.edu/discovery/sourceRecord?vid=01UCS_BER:UCB&amp;docId=alma991033194509706532&amp;recordOwner=01UCS_NETWORK">https://search.library.berkeley.edu/discovery/sourceRecord?vid=01UCS_BER:UCB&amp;docId=alma991033194509706532&amp;recordOwner=01UCS_NETWORK</a>.</p>
<p><a id="note1" href="../index.html%3Fp=16608.html#ref1">Ostrove, G. E. (2001)</a>. Music subject cataloging and form/genre implementation at the Library of Congress. Cataloging &amp; Classification Quarterly, 32(2), 91-106. <a href="https://doi.org/10.1300/J104v32n02_08">https://doi.org/10.1300/J104v32n02_08</a>.</p>
<p><a id="note25" href="../index.html%3Fp=16608.html#ref25">Performed Music Ontology: Documentation (2021, May 6)</a>. <a href="https://github.com/LD4P/PerformedMusicOntology/tree/main/Documentation">https://github.com/LD4P/PerformedMusicOntology/tree/main/Documentation</a>.</p>
<p><a id="note13" href="../index.html%3Fp=16608.html#ref13">RDA Toolkit. (2022)</a>. American Library Association. <a href="https://access.rdatoolkit.org/">https://access.rdatoolkit.org/</a>.</p>
<p><a id="note3" href="../index.html%3Fp=16608.html#ref3">Subject Analysis Committee. (2017)</a>. A Brave New (Faceted) World: Towards Full Implementation of Library of Congress Faceted Vocabularies. Association for Library Collections &amp; Technical Services. <a href="http://hdl.handle.net/11213/8146">http://hdl.handle.net/11213/8146</a>.</p>
<p><a id="note11" href="../index.html%3Fp=16608.html#ref11">Subject Analysis Committee. (2022)</a>. Retrospective Implementation of Library of Congress Faceted Vocabularies. Association for Library Collections &amp; Technical Services. <a href="http://hdl.handle.net/11213/17998">http://hdl.handle.net/11213/17998</a>.</p>
<p><a id="note18" href="../index.html%3Fp=16608.html#ref18">Swanson, C. M. (2003)</a>. Adding to the viola repertoire by arranging: A study on methods of arranging music for viola from clarinet, with an original arrangement of the Saint-Saens Clarinet Sonata in E-flat, Op. 167 (UMI number: 3107045) [Doctoral dissertation, University of Arizona]. ProQuest Information and Learning. <a href="http://hdl.handle.net/10150/280389">http://hdl.handle.net/10150/280389</a>.</p>
<p><a id="note19" href="../index.html%3Fp=16608.html#ref19">Szeto K. (2010a)</a>. Concerto for violin and chamber ensemble arranged after Robert Schumann’s Scherzo from symphony no. 2. Alexander Street Press Classical Scores Library, Volume IV. <a href="https://search.alexanderstreet.com/preview/work/bibliographic_entity%7Cscore%7C3643958">https://search.alexanderstreet.com/preview/work/bibliographic_entity%7Cscore%7C3643958</a>.</p>
<p><a id="note20" href="../index.html%3Fp=16608.html#ref20">Szeto K. (2010b)</a>. Robert Schumann&#8217;s symphony no. 2 in C major arranged for chamber ensemble. Alexander Street Press Classical Scores Library, Volume IV. <a href="https://search.alexanderstreet.com/preview/work/bibliographic_entity%7Cscore%7C3643956">https://search.alexanderstreet.com/preview/work/bibliographic_entity%7Cscore%7C3643956</a>.</p>
<p><a id="note21" href="../index.html%3Fp=16608.html#ref21">Szeto K. (2013)</a>. Leoš Janácek: Ouvertüre zur Oper &#8220;Aus einem Totenhaus&#8221; für Solovioline und Ensemble (UE 36 249). Universal Edition.</p>
<p><a id="note15" href="../index.html%3Fp=16608.html#ref15">Szeto, K. (2016, October 15)</a>. Untangling medium of performance for the linked data environment [presentation]. New York State-Ontario Chapter of the Music Library Association Fall Meeting, University of Toronto, Ontario, Canada. <a href="https://academicworks.cuny.edu/bb_pubs/1251/">https://academicworks.cuny.edu/bb_pubs/1251/</a>.</p>
<p><a id="note24" href="../index.html%3Fp=16608.html#ref24">Szeto, K., Adams, A. D., Billet, K. E., Busselen, C., Kishimoto, K. S., LoPrete, A. A., McFall, L., Rondeau, S., Snyder, T. L., Soe Nyun, J. L., Vanden Dries, W. R., &amp; Vermeij, H. (2016)</a>. Report of the CMC BIBFRAME Task Force to the Board of the Music Library Association. <a href="https://cmc.wp.musiclibraryassoc.org/wp-content/uploads/sites/5/2019/02/201602Task_Force_Report.pdf">https://cmc.wp.musiclibraryassoc.org/wp-content/uploads/sites/5/2019/02/201602Task_Force_Report.pdf</a>.</p>
<p><a id="note4" href="../index.html%3Fp=16608.html#ref4">Szeto, K. (2017)</a>. The mystery of the Schubert Song. Notes, 74(1), 9-23. <a href="https://doi.org/10.1353/not.2017.0071">https://doi.org/10.1353/not.2017.0071</a>.</p>
<p><a id="note22" href="../index.html%3Fp=16608.html#ref22">Weiß, C., Zalkow, F., Arifi-Müller, V., Müller, M., Koops, H. V., Volk, A., &amp; Grohganz, H. G. (2021)</a>. Schubert Winterreise Dataset: A Multimodal scenario for music analysis. Journal on Computing and Cultural Heritage, 14(2), 1-18. <a href="https://doi.org/10.1145/3429743">https://doi.org/10.1145/3429743</a>.</p>
<h2 class="abouttheauthor">About the Author</h2>
<p><a href="mailto:kimmy.szeto@baruch.cuny.edu">Kimmy Szeto</a> is Associate Professor and Metadata Librarian at Baruch College, City University of New York, where he manages metadata for digital resources. His recent research focuses on the technical and conceptual tensions between cataloging practice and the linked data environment. Outside the library and academia, Kimmy can be heard as a chamber arranger of symphonic works and as a collaborative pianist in concert halls and theaters around New York City.</p>
					</div>
														</div>
				<!-- You can start editing here. -->

<div class="comments">
	<p class="subscriptionlinks">Subscribe to comments: <a href="16608/feed">For this article</a> | <a href="http://feeds.feedburner.com/c4lj/comments">For all articles</a></p>

			<!-- If comments are open, but there are no comments. -->

	 

<h3 id="respond">Leave a Reply</h3>


<form action="https://journal.code4lib.org/wp-comments-post.php" method="post" id="commentform">


<p><input type="text" name="author" id="author" value=""/>
<label for="author">Name (required)</label></p>

<p><input type="text" name="email" id="email" value="" />
<label for="email">Mail (will not be published) (required)</label></p>

<p><input type="text" name="url" id="url" value="" />
<label for="url">Website</label></p>


<p><textarea autocomplete="new-password"  aria-label="Comment box" id="f127f6ccbe"  name="f127f6ccbe"   cols="50" rows="10"></textarea><textarea id="comment" aria-label="hp-comment" aria-hidden="true" name="comment" autocomplete="new-password" style="padding:0 !important;clip:rect(1px, 1px, 1px, 1px) !important;position:absolute !important;white-space:nowrap !important;height:1px !important;width:1px !important;overflow:hidden !important;" tabindex="-1"></textarea><script data-noptimize>document.getElementById("comment").setAttribute( "id", "afb0e5e0682ddab3b9e75f2ffd7f08fa" );document.getElementById("f127f6ccbe").setAttribute( "id", "comment" );</script></p>

<p><input name="submit" type="submit" id="submit"  value="Submit Comment" />
<input type="hidden" name="comment_post_ID" value="16608" />
</p>
<p style="display: none;"><input type="hidden" id="akismet_comment_nonce" name="akismet_comment_nonce" value="fa4414fefc" /></p><p style="display: none !important;" class="akismet-fields-container" data-prefix="ak_"><label>&#916;<textarea name="ak_hp_textarea" cols="45" rows="8" maxlength="100"></textarea></label><input type="hidden" id="ak_js_1" name="ak_js" value="165"/><script>document.getElementById( "ak_js_1" ).setAttribute( "value", ( new Date() ).getTime() );</script></p>
</form>


</div>
							</div>

			<div id="meta">
				<div id="issn">
					<p>ISSN 1940-5758</p>
				</div>
				<div class="search-sidebar">
				<form method="get" id="searchform" action="../index.html">
					<div>
						<input type="text" value="" aria-labelledby="searchsubmit" name="s" id="s" />
						<input type="submit" value="Search" id="searchsubmit"/>
					</div>
				</form>
				</div>
				<div id="archives">
					<h2>Current Issue</h2>
						<ul>
							<li><a href="../issues/issues/issue60.html">Issue 60, 2025-04-14</a></li>
						</ul>

					<h2>Previous Issues</h2>
						<ul>
              <li><a href="../issues/issues/issue59.html">Issue 59, 2024-10-07</a></li><li><a href="../issues/issues/issue58.html">Issue 58, 2023-12-04</a></li><li><a href="../issues/issues/issue57.html">Issue 57, 2023-08-29</a></li><li><a href="../issues/issues/issue56.html">Issue 56, 2023-04-21</a></li>              <li><a href="../index.html%3Fp=2476.html">Older Issues</a></li>
						</ul>
				</div>
				<div id="forauthors">
					<h2>For Authors</h2>
					<ul>
						<li class="page_item page-item-4"><a href="../index.html%3Fp=4.html">Call for Submissions</a></li>
<li class="page_item page-item-7"><a href="../index.html%3Fp=7.html">Article Guidelines</a></li>
					</ul>
				</div>
			</div>
						<div id="footer">
				<p id="login"><a href="../wp-login.php.html">Log in</a></p>
				<p id="copyright">This work is licensed under a <a rel="license" href="http://creativecommons.org/licenses/by/3.0/us/">Creative Commons Attribution 3.0 United States License</a>.<br /><a rel="license" href="http://creativecommons.org/licenses/by/3.0/us/"><img alt="Creative Commons License" src="http://i.creativecommons.org/l/by/3.0/us/80x15.png" /></a></p>
			</div>
			<script type="speculationrules">
{"prefetch":[{"source":"document","where":{"and":[{"href_matches":"\/*"},{"not":{"href_matches":["\/wp-*.php","\/wp-admin\/*","\/wp-content\/uploads\/*","\/wp-content\/*","\/wp-content\/plugins\/*","\/wp-content\/themes\/c4lj-theme\/*","\/*\\?(.+)"]}},{"not":{"selector_matches":"a[rel~=\"nofollow\"]"}},{"not":{"selector_matches":".no-prefetch, .no-prefetch a"}}]},"eagerness":"conservative"}]}
</script>
<script defer type="text/javascript" src="../wp-content/plugins/akismet/_inc/akismet-frontend.js%3Fver=1748382734" id="akismet-frontend-js"></script>
		</div>
	</body>
</html>
