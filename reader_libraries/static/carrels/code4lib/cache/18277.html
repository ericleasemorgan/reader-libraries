<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN"
"http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en-US">
	<head>
		<meta http-equiv="Content-Type" content="text/html; charset=UTF-8" />

		<title>The Code4Lib Journal &#8211; Taming the Generative AI Wild West: Integrating Knowledge Graphs in Digital Library Systems</title>

		<meta name="viewport" content="width=device-width, initial-scale=1" />
		<meta name="generator" content="WordPress 6.8.1" /> <!-- leave this for stats -->
    <link rel="shortcut icon" href="../wp-content/themes/c4lj-theme/images/favicon.ico" />
		<link rel="stylesheet" href="../wp-content/themes/c4lj-theme/style.css" type="text/css" media="screen, print" />
		<!--[if lte IE 7]>
		<link rel="stylesheet" href="https://journal.code4lib.org/wp-content/themes/c4lj-theme/fix-ie7.css" type="text/css" media="screen" />
		<![endif]-->
		<!--[if lte IE 6]>
		<link rel="stylesheet" href="https://journal.code4lib.org/wp-content/themes/c4lj-theme/fix-ie6.css" type="text/css" media="screen" />
		<![endif]-->
		<link rel="stylesheet" href="../wp-content/themes/c4lj-theme/print.css" type="text/css" media="print" />
		<link rel="alternate" type="application/rss+xml" title="The Code4Lib Journal Syndication Feed" href="http://feeds.feedburner.com/c4lj" />
		<link rel="pingback" href="https://journal.code4lib.org/xmlrpc.php" />

<!-- Google Scholar Stuff -->
	<meta name="citation_title" content="Taming the Generative AI Wild West: Integrating Knowledge Graphs in Digital Library Systems">
 <meta name="citation_author" content="Jennifer D’Souza">
<meta name="citation_publication_date" content="2025/04/14">
	<meta name="citation_journal_title" content="Code4Lib Journal">
		<meta name="citation_issue" content="60">
<!-- end  Google Scholar Stuff -->

<meta name='robots' content='max-image-preview:large' />
	<style>img:is([sizes="auto" i], [sizes^="auto," i]) { contain-intrinsic-size: 3000px 1500px }</style>
	<link rel="alternate" type="application/rss+xml" title="The Code4Lib Journal &raquo; Taming the Generative AI Wild West: Integrating Knowledge Graphs in Digital Library Systems Comments Feed" href="18277/feed" />
<script type="text/javascript">
/* <![CDATA[ */
window._wpemojiSettings = {"baseUrl":"https:\/\/s.w.org\/images\/core\/emoji\/15.1.0\/72x72\/","ext":".png","svgUrl":"https:\/\/s.w.org\/images\/core\/emoji\/15.1.0\/svg\/","svgExt":".svg","source":{"concatemoji":"https:\/\/journal.code4lib.org\/wp-includes\/js\/wp-emoji-release.min.js?ver=6.8.1"}};
/*! This file is auto-generated */
!function(i,n){var o,s,e;function c(e){try{var t={supportTests:e,timestamp:(new Date).valueOf()};sessionStorage.setItem(o,JSON.stringify(t))}catch(e){}}function p(e,t,n){e.clearRect(0,0,e.canvas.width,e.canvas.height),e.fillText(t,0,0);var t=new Uint32Array(e.getImageData(0,0,e.canvas.width,e.canvas.height).data),r=(e.clearRect(0,0,e.canvas.width,e.canvas.height),e.fillText(n,0,0),new Uint32Array(e.getImageData(0,0,e.canvas.width,e.canvas.height).data));return t.every(function(e,t){return e===r[t]})}function u(e,t,n){switch(t){case"flag":return n(e,"\ud83c\udff3\ufe0f\u200d\u26a7\ufe0f","\ud83c\udff3\ufe0f\u200b\u26a7\ufe0f")?!1:!n(e,"\ud83c\uddfa\ud83c\uddf3","\ud83c\uddfa\u200b\ud83c\uddf3")&&!n(e,"\ud83c\udff4\udb40\udc67\udb40\udc62\udb40\udc65\udb40\udc6e\udb40\udc67\udb40\udc7f","\ud83c\udff4\u200b\udb40\udc67\u200b\udb40\udc62\u200b\udb40\udc65\u200b\udb40\udc6e\u200b\udb40\udc67\u200b\udb40\udc7f");case"emoji":return!n(e,"\ud83d\udc26\u200d\ud83d\udd25","\ud83d\udc26\u200b\ud83d\udd25")}return!1}function f(e,t,n){var r="undefined"!=typeof WorkerGlobalScope&&self instanceof WorkerGlobalScope?new OffscreenCanvas(300,150):i.createElement("canvas"),a=r.getContext("2d",{willReadFrequently:!0}),o=(a.textBaseline="top",a.font="600 32px Arial",{});return e.forEach(function(e){o[e]=t(a,e,n)}),o}function t(e){var t=i.createElement("script");t.src=e,t.defer=!0,i.head.appendChild(t)}"undefined"!=typeof Promise&&(o="wpEmojiSettingsSupports",s=["flag","emoji"],n.supports={everything:!0,everythingExceptFlag:!0},e=new Promise(function(e){i.addEventListener("DOMContentLoaded",e,{once:!0})}),new Promise(function(t){var n=function(){try{var e=JSON.parse(sessionStorage.getItem(o));if("object"==typeof e&&"number"==typeof e.timestamp&&(new Date).valueOf()<e.timestamp+604800&&"object"==typeof e.supportTests)return e.supportTests}catch(e){}return null}();if(!n){if("undefined"!=typeof Worker&&"undefined"!=typeof OffscreenCanvas&&"undefined"!=typeof URL&&URL.createObjectURL&&"undefined"!=typeof Blob)try{var e="postMessage("+f.toString()+"("+[JSON.stringify(s),u.toString(),p.toString()].join(",")+"));",r=new Blob([e],{type:"text/javascript"}),a=new Worker(URL.createObjectURL(r),{name:"wpTestEmojiSupports"});return void(a.onmessage=function(e){c(n=e.data),a.terminate(),t(n)})}catch(e){}c(n=f(s,u,p))}t(n)}).then(function(e){for(var t in e)n.supports[t]=e[t],n.supports.everything=n.supports.everything&&n.supports[t],"flag"!==t&&(n.supports.everythingExceptFlag=n.supports.everythingExceptFlag&&n.supports[t]);n.supports.everythingExceptFlag=n.supports.everythingExceptFlag&&!n.supports.flag,n.DOMReady=!1,n.readyCallback=function(){n.DOMReady=!0}}).then(function(){return e}).then(function(){var e;n.supports.everything||(n.readyCallback(),(e=n.source||{}).concatemoji?t(e.concatemoji):e.wpemoji&&e.twemoji&&(t(e.twemoji),t(e.wpemoji)))}))}((window,document),window._wpemojiSettings);
/* ]]> */
</script>
<style id='wp-emoji-styles-inline-css' type='text/css'>

	img.wp-smiley, img.emoji {
		display: inline !important;
		border: none !important;
		box-shadow: none !important;
		height: 1em !important;
		width: 1em !important;
		margin: 0 0.07em !important;
		vertical-align: -0.1em !important;
		background: none !important;
		padding: 0 !important;
	}
</style>
<link rel='stylesheet' id='wp-block-library-css' href='../wp-includes/css/dist/block-library/style.min.css%3Fver=6.8.1.css' type='text/css' media='all' />
<style id='classic-theme-styles-inline-css' type='text/css'>
/*! This file is auto-generated */
.wp-block-button__link{color:#fff;background-color:#32373c;border-radius:9999px;box-shadow:none;text-decoration:none;padding:calc(.667em + 2px) calc(1.333em + 2px);font-size:1.125em}.wp-block-file__button{background:#32373c;color:#fff;text-decoration:none}
</style>
<style id='global-styles-inline-css' type='text/css'>
:root{--wp--preset--aspect-ratio--square: 1;--wp--preset--aspect-ratio--4-3: 4/3;--wp--preset--aspect-ratio--3-4: 3/4;--wp--preset--aspect-ratio--3-2: 3/2;--wp--preset--aspect-ratio--2-3: 2/3;--wp--preset--aspect-ratio--16-9: 16/9;--wp--preset--aspect-ratio--9-16: 9/16;--wp--preset--color--black: #000000;--wp--preset--color--cyan-bluish-gray: #abb8c3;--wp--preset--color--white: #ffffff;--wp--preset--color--pale-pink: #f78da7;--wp--preset--color--vivid-red: #cf2e2e;--wp--preset--color--luminous-vivid-orange: #ff6900;--wp--preset--color--luminous-vivid-amber: #fcb900;--wp--preset--color--light-green-cyan: #7bdcb5;--wp--preset--color--vivid-green-cyan: #00d084;--wp--preset--color--pale-cyan-blue: #8ed1fc;--wp--preset--color--vivid-cyan-blue: #0693e3;--wp--preset--color--vivid-purple: #9b51e0;--wp--preset--gradient--vivid-cyan-blue-to-vivid-purple: linear-gradient(135deg,rgba(6,147,227,1) 0%,rgb(155,81,224) 100%);--wp--preset--gradient--light-green-cyan-to-vivid-green-cyan: linear-gradient(135deg,rgb(122,220,180) 0%,rgb(0,208,130) 100%);--wp--preset--gradient--luminous-vivid-amber-to-luminous-vivid-orange: linear-gradient(135deg,rgba(252,185,0,1) 0%,rgba(255,105,0,1) 100%);--wp--preset--gradient--luminous-vivid-orange-to-vivid-red: linear-gradient(135deg,rgba(255,105,0,1) 0%,rgb(207,46,46) 100%);--wp--preset--gradient--very-light-gray-to-cyan-bluish-gray: linear-gradient(135deg,rgb(238,238,238) 0%,rgb(169,184,195) 100%);--wp--preset--gradient--cool-to-warm-spectrum: linear-gradient(135deg,rgb(74,234,220) 0%,rgb(151,120,209) 20%,rgb(207,42,186) 40%,rgb(238,44,130) 60%,rgb(251,105,98) 80%,rgb(254,248,76) 100%);--wp--preset--gradient--blush-light-purple: linear-gradient(135deg,rgb(255,206,236) 0%,rgb(152,150,240) 100%);--wp--preset--gradient--blush-bordeaux: linear-gradient(135deg,rgb(254,205,165) 0%,rgb(254,45,45) 50%,rgb(107,0,62) 100%);--wp--preset--gradient--luminous-dusk: linear-gradient(135deg,rgb(255,203,112) 0%,rgb(199,81,192) 50%,rgb(65,88,208) 100%);--wp--preset--gradient--pale-ocean: linear-gradient(135deg,rgb(255,245,203) 0%,rgb(182,227,212) 50%,rgb(51,167,181) 100%);--wp--preset--gradient--electric-grass: linear-gradient(135deg,rgb(202,248,128) 0%,rgb(113,206,126) 100%);--wp--preset--gradient--midnight: linear-gradient(135deg,rgb(2,3,129) 0%,rgb(40,116,252) 100%);--wp--preset--font-size--small: 13px;--wp--preset--font-size--medium: 20px;--wp--preset--font-size--large: 36px;--wp--preset--font-size--x-large: 42px;--wp--preset--spacing--20: 0.44rem;--wp--preset--spacing--30: 0.67rem;--wp--preset--spacing--40: 1rem;--wp--preset--spacing--50: 1.5rem;--wp--preset--spacing--60: 2.25rem;--wp--preset--spacing--70: 3.38rem;--wp--preset--spacing--80: 5.06rem;--wp--preset--shadow--natural: 6px 6px 9px rgba(0, 0, 0, 0.2);--wp--preset--shadow--deep: 12px 12px 50px rgba(0, 0, 0, 0.4);--wp--preset--shadow--sharp: 6px 6px 0px rgba(0, 0, 0, 0.2);--wp--preset--shadow--outlined: 6px 6px 0px -3px rgba(255, 255, 255, 1), 6px 6px rgba(0, 0, 0, 1);--wp--preset--shadow--crisp: 6px 6px 0px rgba(0, 0, 0, 1);}:where(.is-layout-flex){gap: 0.5em;}:where(.is-layout-grid){gap: 0.5em;}body .is-layout-flex{display: flex;}.is-layout-flex{flex-wrap: wrap;align-items: center;}.is-layout-flex > :is(*, div){margin: 0;}body .is-layout-grid{display: grid;}.is-layout-grid > :is(*, div){margin: 0;}:where(.wp-block-columns.is-layout-flex){gap: 2em;}:where(.wp-block-columns.is-layout-grid){gap: 2em;}:where(.wp-block-post-template.is-layout-flex){gap: 1.25em;}:where(.wp-block-post-template.is-layout-grid){gap: 1.25em;}.has-black-color{color: var(--wp--preset--color--black) !important;}.has-cyan-bluish-gray-color{color: var(--wp--preset--color--cyan-bluish-gray) !important;}.has-white-color{color: var(--wp--preset--color--white) !important;}.has-pale-pink-color{color: var(--wp--preset--color--pale-pink) !important;}.has-vivid-red-color{color: var(--wp--preset--color--vivid-red) !important;}.has-luminous-vivid-orange-color{color: var(--wp--preset--color--luminous-vivid-orange) !important;}.has-luminous-vivid-amber-color{color: var(--wp--preset--color--luminous-vivid-amber) !important;}.has-light-green-cyan-color{color: var(--wp--preset--color--light-green-cyan) !important;}.has-vivid-green-cyan-color{color: var(--wp--preset--color--vivid-green-cyan) !important;}.has-pale-cyan-blue-color{color: var(--wp--preset--color--pale-cyan-blue) !important;}.has-vivid-cyan-blue-color{color: var(--wp--preset--color--vivid-cyan-blue) !important;}.has-vivid-purple-color{color: var(--wp--preset--color--vivid-purple) !important;}.has-black-background-color{background-color: var(--wp--preset--color--black) !important;}.has-cyan-bluish-gray-background-color{background-color: var(--wp--preset--color--cyan-bluish-gray) !important;}.has-white-background-color{background-color: var(--wp--preset--color--white) !important;}.has-pale-pink-background-color{background-color: var(--wp--preset--color--pale-pink) !important;}.has-vivid-red-background-color{background-color: var(--wp--preset--color--vivid-red) !important;}.has-luminous-vivid-orange-background-color{background-color: var(--wp--preset--color--luminous-vivid-orange) !important;}.has-luminous-vivid-amber-background-color{background-color: var(--wp--preset--color--luminous-vivid-amber) !important;}.has-light-green-cyan-background-color{background-color: var(--wp--preset--color--light-green-cyan) !important;}.has-vivid-green-cyan-background-color{background-color: var(--wp--preset--color--vivid-green-cyan) !important;}.has-pale-cyan-blue-background-color{background-color: var(--wp--preset--color--pale-cyan-blue) !important;}.has-vivid-cyan-blue-background-color{background-color: var(--wp--preset--color--vivid-cyan-blue) !important;}.has-vivid-purple-background-color{background-color: var(--wp--preset--color--vivid-purple) !important;}.has-black-border-color{border-color: var(--wp--preset--color--black) !important;}.has-cyan-bluish-gray-border-color{border-color: var(--wp--preset--color--cyan-bluish-gray) !important;}.has-white-border-color{border-color: var(--wp--preset--color--white) !important;}.has-pale-pink-border-color{border-color: var(--wp--preset--color--pale-pink) !important;}.has-vivid-red-border-color{border-color: var(--wp--preset--color--vivid-red) !important;}.has-luminous-vivid-orange-border-color{border-color: var(--wp--preset--color--luminous-vivid-orange) !important;}.has-luminous-vivid-amber-border-color{border-color: var(--wp--preset--color--luminous-vivid-amber) !important;}.has-light-green-cyan-border-color{border-color: var(--wp--preset--color--light-green-cyan) !important;}.has-vivid-green-cyan-border-color{border-color: var(--wp--preset--color--vivid-green-cyan) !important;}.has-pale-cyan-blue-border-color{border-color: var(--wp--preset--color--pale-cyan-blue) !important;}.has-vivid-cyan-blue-border-color{border-color: var(--wp--preset--color--vivid-cyan-blue) !important;}.has-vivid-purple-border-color{border-color: var(--wp--preset--color--vivid-purple) !important;}.has-vivid-cyan-blue-to-vivid-purple-gradient-background{background: var(--wp--preset--gradient--vivid-cyan-blue-to-vivid-purple) !important;}.has-light-green-cyan-to-vivid-green-cyan-gradient-background{background: var(--wp--preset--gradient--light-green-cyan-to-vivid-green-cyan) !important;}.has-luminous-vivid-amber-to-luminous-vivid-orange-gradient-background{background: var(--wp--preset--gradient--luminous-vivid-amber-to-luminous-vivid-orange) !important;}.has-luminous-vivid-orange-to-vivid-red-gradient-background{background: var(--wp--preset--gradient--luminous-vivid-orange-to-vivid-red) !important;}.has-very-light-gray-to-cyan-bluish-gray-gradient-background{background: var(--wp--preset--gradient--very-light-gray-to-cyan-bluish-gray) !important;}.has-cool-to-warm-spectrum-gradient-background{background: var(--wp--preset--gradient--cool-to-warm-spectrum) !important;}.has-blush-light-purple-gradient-background{background: var(--wp--preset--gradient--blush-light-purple) !important;}.has-blush-bordeaux-gradient-background{background: var(--wp--preset--gradient--blush-bordeaux) !important;}.has-luminous-dusk-gradient-background{background: var(--wp--preset--gradient--luminous-dusk) !important;}.has-pale-ocean-gradient-background{background: var(--wp--preset--gradient--pale-ocean) !important;}.has-electric-grass-gradient-background{background: var(--wp--preset--gradient--electric-grass) !important;}.has-midnight-gradient-background{background: var(--wp--preset--gradient--midnight) !important;}.has-small-font-size{font-size: var(--wp--preset--font-size--small) !important;}.has-medium-font-size{font-size: var(--wp--preset--font-size--medium) !important;}.has-large-font-size{font-size: var(--wp--preset--font-size--large) !important;}.has-x-large-font-size{font-size: var(--wp--preset--font-size--x-large) !important;}
:where(.wp-block-post-template.is-layout-flex){gap: 1.25em;}:where(.wp-block-post-template.is-layout-grid){gap: 1.25em;}
:where(.wp-block-columns.is-layout-flex){gap: 2em;}:where(.wp-block-columns.is-layout-grid){gap: 2em;}
:root :where(.wp-block-pullquote){font-size: 1.5em;line-height: 1.6;}
</style>
<style id='akismet-widget-style-inline-css' type='text/css'>

			.a-stats {
				--akismet-color-mid-green: #357b49;
				--akismet-color-white: #fff;
				--akismet-color-light-grey: #f6f7f7;

				max-width: 350px;
				width: auto;
			}

			.a-stats * {
				all: unset;
				box-sizing: border-box;
			}

			.a-stats strong {
				font-weight: 600;
			}

			.a-stats a.a-stats__link,
			.a-stats a.a-stats__link:visited,
			.a-stats a.a-stats__link:active {
				background: var(--akismet-color-mid-green);
				border: none;
				box-shadow: none;
				border-radius: 8px;
				color: var(--akismet-color-white);
				cursor: pointer;
				display: block;
				font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', 'Roboto', 'Oxygen-Sans', 'Ubuntu', 'Cantarell', 'Helvetica Neue', sans-serif;
				font-weight: 500;
				padding: 12px;
				text-align: center;
				text-decoration: none;
				transition: all 0.2s ease;
			}

			/* Extra specificity to deal with TwentyTwentyOne focus style */
			.widget .a-stats a.a-stats__link:focus {
				background: var(--akismet-color-mid-green);
				color: var(--akismet-color-white);
				text-decoration: none;
			}

			.a-stats a.a-stats__link:hover {
				filter: brightness(110%);
				box-shadow: 0 4px 12px rgba(0, 0, 0, 0.06), 0 0 2px rgba(0, 0, 0, 0.16);
			}

			.a-stats .count {
				color: var(--akismet-color-white);
				display: block;
				font-size: 1.5em;
				line-height: 1.4;
				padding: 0 13px;
				white-space: nowrap;
			}
		
</style>
<link rel="https://api.w.org/" href="../wp-json/index.html" /><link rel="alternate" title="JSON" type="application/json" href="../wp-json/wp/v2/posts/18277" /><link rel="EditURI" type="application/rsd+xml" title="RSD" href="https://journal.code4lib.org/xmlrpc.php?rsd" />
<link rel="canonical" href="../index.html%3Fp=18277.html" />
<link rel='shortlink' href='../index.html%3Fp=18277.html' />
<link rel="alternate" title="oEmbed (JSON)" type="application/json+oembed" href="../wp-json/oembed/1.0/embed%3Furl=https:%252F%252Fjournal.code4lib.org%252Farticles%252F18277" />
<link rel="alternate" title="oEmbed (XML)" type="text/xml+oembed" href="../wp-json/oembed/1.0/embed%3Furl=https:%252F%252Fjournal.code4lib.org%252Farticles%252F18277&amp;format=xml" />
<style>
@media all and (max-width : 768px) {
.syntaxhighlighter a, .syntaxhighlighter div, .syntaxhighlighter code, .syntaxhighlighter table, .syntaxhighlighter table td, .syntaxhighlighter table tr, .syntaxhighlighter table tbody, .syntaxhighlighter table thead, .syntaxhighlighter table caption, .syntaxhighlighter textarea
{
	font-size: 0.95em !important;
}
}
</style>
	</head>
	<body>
		<div id="page">
			<div id="header">
				<div id="headerbackground">
					<h1><a href="../index.html"><img src="../wp-content/themes/c4lj-theme/images/logo.png" alt="The Code4Lib Journal" /></a></h1>
				</div>
				<div id="about">
					<ul>
						<li class="page_item page-item-5"><a href="../index.html%3Fp=5.html">Mission</a></li>
<li class="page_item page-item-6"><a href="../editorial-committee/index.html">Editorial Committee</a></li>
<li class="page_item page-item-8"><a href="../process/index.html">Process and Structure</a></li>
						<li><a href="http://code4lib.org/">Code4Lib</a></li>
					</ul>
				</div>
				<div class="mobile-search">
					<form method="get" id="searchform" action="../index.html">
						<div>
							<input type="text" value="" aria-labelledby="searchsubmit" name="s" id="s" />
							<input type="submit" value="Search" id="searchsubmit" />
						</div>
					</form>
				</div>
			</div>

			<div id="content">
								<div class="article" id="post-18277">
					<p id="issueDesignation"><a href="../issues/issues/issue60.html">Issue 60, 2025-04-14</a></p>
					<h1 class="articletitle">Taming the Generative AI Wild West: Integrating Knowledge Graphs in Digital Library Systems</h1>
					<div class="abstract">
						<p>Since the 17th century, scientific publishing has been document-centric, leaving knowledge—such as methods and best practices—largely unstructured and not easily machine-interpretable, despite digital availability. Traditional practices reduce content to keyword indexes, masking richer insights. Advances in semantic technologies, like knowledge graphs, can enhance the structure of scientific records, addressing challenges in a research landscape where millions of contributions are published annually, often as pseudo-digitized PDFs. As a case in point, generative AI Large Language Models (LLMs) like OpenAI&#8217;s GPT and Meta AI&#8217;s LLAMA exemplify rapid innovation, yet critical information about LLMs remains scattered across articles, blogs, and code repositories. This highlights the need for knowledge-graph-based publishing to make scientific knowledge truly FAIR (Findable, Accessible, Interoperable, Reusable). This article explores semantic publishing workflows, enabling structured descriptions and comparisons of LLMs that support automated research insights—similar to product descriptions on e-commerce platforms. Demonstrated via the Open Research Knowledge Graph (ORKG) platform, a flagship project of the TIB Leibniz Information Centre for Science &#038; Technology and University Library, this approach transforms scientific documentation into machine-actionable knowledge, streamlining research access, update, search, and comparison.</p>
					</div>
					<div class="entry">
						<p>By Jennifer D’Souza</p>
<h2>Introduction</h2>
<p><em>There is a growing mountain of research. But there is increased evidence that we are being bogged down today as specialization extends. The investigator is staggered by the findings and conclusions of thousands of other workers—conclusions which he cannot find time to grasp, much less to remember, as they appear. … A RECORD if it is to be useful to science, must be continuously extended, it must be stored, and above all it must be consulted. [<a id="ref1" href="../index.html%3Fp=18277.html#note1">1</a>] </em></p>
<p>&#8212; Vannevar Bush, As We May Think (1945)</p>
<p>The sheer volume of scientific advancements poses significant challenges for researchers, who must sift through vast amounts of information to derive meaningful insights. This challenge is further compounded by the largely unstructured nature of current scientific communication, which hampers transparency, integration, peer review efficiency, and machine assistance. To overcome these limitations, research records must transition from traditional unstructured formats to machine-actionable, semantically structured representations, such as Knowledge Graphs (KGs), enabling smarter and more efficient research tools. This shift also aligns with the FAIR principles—Findable, Accessible, Interoperable, and Reusable [<a id="ref2" href="../index.html%3Fp=18277.html#note2">2</a>] —ensuring usability for both humans and machines. The Open Research Knowledge Graph (ORKG), a flagship project of the TIB Leibniz Information Centre for Science &amp; Technology and University Library, seeks to address these challenges by enabling the structured representation and comparison of scientific contributions based on their key properties. Much like e-commerce platforms that allow side-by-side product comparisons, the ORKG facilitates efficient exploration of scientific knowledge, opening new opportunities for researchers and digital libraries[<a id="ref3" href="../index.html%3Fp=18277.html#note3">3</a>][<a id="ref4" href="../index.html%3Fp=18277.html#note4">4</a>][<a id="ref5" href="../index.html%3Fp=18277.html#note5">5</a>].</p>
<p>The ORKG is a web-based platform and infrastructure designed to structure and interlink scientific knowledge using semantic technologies. Unlike traditional text-based research publishing, the ORKG, in close adherence to the FAIR principles, represents research contributions as interconnected KGs, enabling more efficient comparison, discovery, review, and synthesis of scientific findings. Figure 1 depicts the structured machine-actionable scientific information published on the ORKG. In the ORKG, researchers and librarians can submit structured descriptions of research papers, making scientific knowledge more accessible for both humans and machines. The platform is available as a service with public community access (<a href="https://orkg.org/">https://orkg.org/</a>) and is implemented via open-source software (<a href="https://gitlab.com/TIBHannover/orkg/">https://gitlab.com/TIBHannover/orkg/</a>). It integrates with persistent identifier services such as DOIs and ORCIDs for improved scientific metadata management and fosters collaboration and Open Science by enabling interdisciplinary research contributions. Additionally, ORKG provides an API as a python package (<a href="https://orkg.readthedocs.io/">https://orkg.readthedocs.io/</a>) that allows developers to integrate its capabilities and data into external applications, enhancing knowledge discovery and research automation.</p>
<p class="caption"><img decoding="async" src="../media/issue60/dsouza/Fig1.png" /><br />
<strong>Figure 1.</strong> Machine-actionable scientific knowledge capture via semantic publishing in the ORKG (red) versus non-machine-actionable, article-based publishing (gray). This figure depicts the process by which a user fills out a template of key properties of research that generates structured paper descriptions, used by the ORKG to generate comparisons of multiple studies with similar properties.</p>
<h2>Tracking the Rapid Advancements in Generative Artificial Intelligence (AI)</h2>
<p>The development of Large Language Models (LLMs) began in 2018 with OpenAI’s GPT-1 and Google’s BERT, which pioneered transformer-based architectures for language understanding. Since then, the rapid evolution of LLMs has been characterized by a wave of innovative releases, each pushing the boundaries of performance, efficiency, and accessibility[<a id="ref6" href="../index.html%3Fp=18277.html#note6">6</a>]. The year 2023 saw the release of models like Mistral 7B which introduced grouped-query attention for enhanced computational efficiency, while Mixtral 8x7B leveraged sparse mixture-of-experts architectures to optimize scalability without sacrificing performance. Other notable advancements include Meta AI’s LLaMA 2, which improved fine-tuning capabilities and context understanding, and OpenAI&#8217;s GPT-4, which significantly expanded multimodal capabilities, including image and text input. Additionally, Anthropic’s Claude series focused on safety and interpretability in alignment techniques, and Google&#8217;s Gemini models demonstrated cutting-edge integration of external tools, setting a new benchmark for task-oriented AI. There is a growing focus on open-source development, computational efficiency, extended context handling, and multimodal capabilities. These breakthroughs illustrate the relentless pace of innovation, driven by a combination of architectural refinements, expanded datasets, and collaborative efforts across the AI community. This continuous stream of innovations highlights the transformative potential of LLMs, as well as the increasing challenge of staying informed in such a rapidly evolving landscape.</p>
<p>The continuous influx of new models, techniques, and datasets demands constant vigilance and adaptability. Key information about LLMs is often scattered across scientific articles, organizational blog posts, and source code repositories, making it difficult to track developments efficiently. LLMs can be compared using key details such as model name, organization, release date, pretraining data, fine-tuning strategies, and carbon footprint. Modeling these consistent properties supports better comparison and searchability and is an excellent use case for the open research knowledge graph.</p>
<h2>Background: The Open Research Knowledge Graph</h2>
<p>Essential technical considerations when publishing KGs include defining salient entities, attributes, and relationships for generative AI models as standardized resources accessible on the web via Uniform Resource Identifiers (URIs). Informational statements about LLMs should also be serialized as structured triples conforming to the Resource Description Framework (RDF) syntax recommended by the World Wide Web Consortium (W3C) [<a id="ref7" href="../index.html%3Fp=18277.html#note7">7</a>]. Standard vocabularies, metadata, and publishing data on the web using dereferenceable URIs are crucial for semantic interoperability and linking to external datasets, enabling a true linked data ecosystem.</p>
<p>These functionalities are fully supported by the ORKG, a next-generation scholarly publishing platform. In this vein, the ORKG is not just software but also a namespace for specifying scholarly vocabularies via URIs, intuitive interfaces for defining <a href="https://orkg.org/resources">resources</a>  <a href="https://orkg.org/properties">properties</a>, <a href="https://orkg.org/classes">classes</a>, and <a href="https://orkg.org/templates">templates</a>, and backend technologies for representing the KG in <a href="https://orkg.org/api/rdf/dump">RDF syntax</a>. Additionally, its machine-actionable semantic structure supports advanced comparison views, akin to e-commerce product comparisons, and enables <a href="https://orkg.org/sparql/">SPARQL queries</a> for customized or aggregated views of structured scholarly knowledge.</p>
<p>The ORKG adopts a collaborative, dynamic knowledge creation model inspired by Wikipedia, where anyone can contribute data using vocabularies of their choice to represent entities interconnected via RDF links, forming a global, discoverable data graph. Its open-ended nature allows the content of research artifacts, such as papers and comparisons, to be edited, updated, and republished, with all versions stored for future reference. Persistent identifiers, such as DOIs, enable precise referencing of specific versions, while provenance metadata—capturing details like creator, creation date, and methods—ensures traceability, trustworthiness, and quality assessment.</p>
<p>DOIs assigned to graph components enhance discoverability through global scientific bibliometric infrastructures like DataCite and Crossref, while resources are also findable via search engines. Accessibility is ensured through HTTP protocols, REST APIs, and a user interface, with metadata accessible independently of graph data. The ORKG achieves interoperability using RDF, the W3C-recommended standard for machine-readable knowledge representation, and fosters reusability by automatically generating provenance metadata and publishing graph data under a CC BY-SA license. These features collectively support efficient, trustworthy, and FAIR-compliant scientific knowledge dissemination.</p>
<h2>Taming the Generative AI Wild West: A Catalog of LLMs on the ORKG</h2>
<p>Publishing information about LLMs on the ORKG begins with defining standard properties for their structured and comparable description. Drawing inspiration from Hugging Face, a central hub for open-source LLMs and their model cards, the author developed a standardized vocabulary and schema to support knowledge capture and semantic representation.</p>
<h3>4.1. The LLM Specification ORKG Template</h3>
<p>Standardized Nomenclature. To ensure consistency, we established a controlled vocabulary that forms the foundation of the LLM Specification Schema. Properties were derived from Hugging Face model cards, with additional LLM-specific predicates added to the ORKG web namespace to expand the vocabulary. To align these properties with external ontologies, the RDF same-as relation was employed to establish equivalences across predicates.</p>
<p>Use of ORKG Templates. For uniform recording of LLM information, we created a form-based template comprising predetermined properties. This template system leverages recurring subgraph property patterns in the ORKG, enabling the consistent specification of relevant attributes across multiple contributions. The template includes 27 structured properties that comprehensively describe LLMs, including:</p>
<ul>
<li><strong>Identification:</strong> <a href="https://orkg.org/property/HAS_MODEL">model name</a>, <a href="https://orkg.org/property/P7121">model family</a>,<a href="https://orkg.org/property/P18097"> organization</a>, and <a href="https://orkg.org/property/P49020">date created.</a></li>
<li><strong>Development Details:</strong> <a href="https://orkg.org/property/P103000">pretraining architecture</a>, <a href="https://orkg.org/property/P103001">pretraining task</a>,<a href="https://orkg.org/property/P41655"> pretraining corpus</a>, <a href="https://orkg.org/property/P163013">size of training corpus</a> (in tokens in billions), <a href="https://orkg.org/property/P163011">knowledge cutoff date</a> and <a href="https://orkg.org/property/P15156">innovation.</a></li>
<li><strong>Fine-Tuning:</strong> <a href="https://orkg.org/property/P116000">fine-tuning task</a> and <a href="https://orkg.org/property/P163012">fine-tuning data for refinement</a>.</li>
<li><strong>Technical Specifications:</strong> <a href="https://orkg.org/property/P105017">optimizer</a>, <a href="https://orkg.org/property/P43065">tokenizer</a>, <a href="https://orkg.org/property/P103002">number of parameters</a>, <a href="https://orkg.org/property/P110076">maximum number of parameters</a> (in million), and <a href="https://orkg.org/property/P163009">context length (in tokens)</a>.</li>
<li><strong>Language and Usage:</strong><a href="https://orkg.org/property/P163010"> supported language</a>, <a href="https://orkg.org/property/extension">extension,</a> and <a href="https://orkg.org/property/P37544">application.</a></li>
<li><strong>Infrastructure and Impact:</strong> <a href="https://orkg.org/property/P119138">hardware used</a>, <a href="https://orkg.org/property/P119137">hardware description</a>, and <a href="https://orkg.org/property/P119142">carbon emitted (tCO2eq)</a>.</li>
<li><strong>Transparency and Licensing:</strong> Availability of the <a href="https://orkg.org/property/HAS_SOURCE_CODE">source code</a>, <a href="https://orkg.org/property/P103003">blog post</a>, <a href="https://orkg.org/property/license">license</a>, and the <a href="https://orkg.org/property/P32">research problem addressed</a>.</li>
</ul>
<p>These properties ensure a holistic representation of LLMs, enabling structured comparisons and detailed analysis. For example, transparency is supported by attributes such as source code availability, while environmental impact is captured through carbon emissions data.</p>
<p>The <strong>ORKG LLM Specification Schema</strong>, which encapsulates these 27 properties, is accessible <a href="https://orkg.org/template/R609825/">on the ORKG platform</a>. This schema empowers researchers to record, compare, and analyze LLMs with precision and consistency, fostering greater transparency and accessibility in the study of generative AI.</p>
<h3>4.2. The ORKG Catalog of LLM-centric Papers, Comparisons, Visualizations, and Review</h3>
<p>Different papers on LLMs are published as structured semantic descriptions in the ORKG using the <a href="https://orkg.org/about/20/Papers">ORKG papers</a> module and then aggregated as <a href="https://orkg.org/about/15/Comparisons">ORKG Comparisons</a> of research. Comparisons are the core type of ORKG content and give a condensed overview on the state-of-the-art for a particular research question. Contributions towards the problem are organized in a tabular view and can be compared and filtered along different properties.<a href="https://orkg.org/comparison/R1355333"> Here is a published comparison of 92 LLMs</a> with respect to their structured, machine-actionable descriptions published as one research comparison on the ORKG. The comparison includes metadata such as a title, creator, and a short description paragraph. The unique aspect of ORKG Comparisons is that they can be published at any granularity. For instance, if there are structured descriptions of the early OpenAI LLMs, viz. GPT-1, 2, and 3, I can aggregate them as an ORKG Comparison. This is depicted in Figure 2 below.</p>
<p class="caption"><img decoding="async" src="../media/issue60/dsouza/Fig2.jpg" /><br />
<strong>Figure 2.</strong> A comparison of early OpenAI Large Language Models (LLMs), <a href="https://orkg.org/comparison/R606160">accessible on the ORKG platform</a>.</p>
<p>Additionally, the machine-actionability afforded by this fine-grained semantic information in the ORKG supports dynamic interactions, such as computing visualizations from the data of any comparison. For instance, the author created another comparison titled “<a href="https://orkg.org/comparison/R1355351">A Catalog of DeepMind&#8217;s LLMs including their seminal Chinchilla model</a>” ( based on their early models—AlphaFold, Gopher, Chinchilla, GopherCite, Flamingo, Gato, and Sparrow. Figure 3 below depicts a column chart, comparing, for each model, the parameter size of the largest variant (measured in millions). This showcases how machine-actionable scientific knowledge in a structured digital library can provide quick insights into specific research questions. For instance, one could explore questions like “What was the largest model size released by DeepMind?” or “What was the maximum variation in LLM sizes across DeepMind’s models?”</p>
<p class="caption"><img decoding="async" src="../media/issue60/dsouza/Fig3.jpg" /><br />
<strong>Figure 3.</strong> A column chart comparing the parameter sizes (in millions) of seven early DeepMind models—AlphaFold, Gopher, Chinchilla, GopherCite, Flamingo, Gato, and Sparrow—based on the ORKG comparison “A Catalog of DeepMind&#8217;s LLMs including their seminal Chinchilla model” (<a href="https://orkg.org/comparison/R1355351">https://orkg.org/comparison/R1355351</a>). The chart dynamically visualizes machine-actionable data from the ORKG platform and hovering over any bar in the chart shows the underlying data stored in the ORKG for that specific plot. The resource is published at <a href="https://orkg.org/resource/R1355283">https://orkg.org/resource/R1355283</a>.</p>
<p>Finally, the ORKG offers <strong>Reviews</strong>, a tool designed for authoring and publishing review articles that facilitates community-based creation of dynamic, living articles by utilizing comparisons from the open research knowledge graph to deliver machine-actionable knowledge. For example, the review available at <a href="https://orkg.org/review/R640001">https://orkg.org/review/R640001</a> aggregates multiple LLM comparisons. It provides granular insights into the features of LLMs developed by various organizations while also integrating these into a broader comparison of all models. This approach is ideal for review articles, enabling detailed analyses of studies or, in this case, comparisons of the LLMs reviewed.</p>
<h3>4.3. Queryability</h3>
<p>SPARQL queries can be used to generate smaller, specific views of the data. For example, the query below might be translated into a natural language question as follows: which LLM models were created in 2023? This query returns a table (limited to the first 100 results) of paper titles, their accompanying LLM, and the LLM creation date. Natural extensions of this query would be to change the year, and even to be able to specify a range of dates in the form of yyyy-mm-dd within which to search. This is an open query endpoint available to any user of the web.</p>
<pre>PREFIX orkgp: &lt;http://orkg.org/orkg/predicate/&gt;
PREFIX orkgc: &lt;http://orkg.org/orkg/class/&gt;
PREFIX orkgr: &lt;http://orkg.org/orkg/resource/&gt;
SELECT ?paper_label ?model_label ?date_created
WHERE {
    orkgr:R609337 orkgp:compareContribution ?contribution .
    ?contribution orkgp:HAS_MODEL ?model .
    ?model rdfs:label ?model_label .
    ?paper orkgp:P31 ?contribution .
    ?paper rdfs:label ?paper_label .
    ?contribution orkgp:P49020 ?date_created .
    FILTER(STRSTARTS(STR(?date_created), "2023"))
}
LIMIT 100
</pre>
<p>While this paper outlines the use case for LLM, the possibilities and opportunities for interlinking information on the web are substantial.</p>
<h2>Related Work</h2>
<p>The closest representation of the information captured via the Transformer model or LLM ORKG Template are model cards for these models released on HuggingFace Hub [<a id="ref8" href="../index.html%3Fp=18277.html#note8">8</a>],. However, the model cards and fine-grained knowledge representation in KGs like ORKG differ significantly in terms of discoverability, reproducibility, and sharing. Model cards are again human-readable documents offering project explanations, but their discoverability is limited to keyword-based searches in repositories, and they often lack the semantic structure needed for precise, automated discovery. While recommendations for model cards involve filling out relevant values for model properties, this structured representation, while it might improve human readability to quickly gloss over the features of a model, lacks machine-actionability since they remain embedded within a document. In contrast, KGs provide machine-readable, structured, and semantically rich representations that enhance discoverability through advanced querying and metadata tagging. They excel in reproducibility by capturing detailed, standardized metadata, tracking updates, and linking methods and datasets transparently. Furthermore, KGs enable seamless sharing and integration within interconnected systems, promoting collaboration and interoperability, unlike the static and standalone nature of any text document regardless of which format it is prescribed to be written in for better human readability.</p>
<p>Despite its advantages, implementing a structured, KG-based approach for model representation presents challenges, particularly in ensuring the quality of articles authored from structured reviews. While ORKG enhances discoverability and reproducibility through machine-readable key aspects of the scientific content, expert oversight remains essential for translating structured data into high-quality narratives. Sustainability is another key factor—unlike volunteer-driven efforts, ORKG benefits from state funding as the flagship project of the TIB, ensuring long-term development. This support enables continuous improvements in automation and usability, reducing the effort required for researchers to contribute structured knowledge. By integrating machine-assisted extraction, incentivizing contributions, and aligning with scholarly publishing workflows, ORKG fosters broader adoption. Thus, it provides a sustainable and scalable framework for improving model discoverability, reproducibility, and knowledge sharing.</p>
<h2>Conclusion</h2>
<p>This article highlights the transformative potential of using knowledge graphs, specifically the Open Research Knowledge Graph (ORKG), to represent and manage information about generative AI technologies such as Large Language Models (LLMs). By adopting a structured, semantic, and machine-actionable approach, the ORKG ensures that the resulting knowledge adheres to FAIR principles—Findable, Accessible, Interoperable, and Reusable.</p>
<p>The KG-based representation demonstrated in this article is not only applicable to LLMs but is easily transferable to other scientific domains. The ORKG platform exemplifies the versatility of a modern digital library, offering generic infrastructure that enables users from any field to model their research as structured knowledge using templates, papers, comparisons, visualizations, and reviews. These living records can be edited and curated collaboratively, ensuring that the knowledge remains dynamic, up-to-date, and accessible to both humans and machines.</p>
<p>By addressing the challenges of fragmented, unstructured knowledge, this approach mitigates the creation of information silos and fosters greater transparency, reproducibility, and usability. Ultimately, leveraging the ORKG and similar platforms paves the way for a more interconnected and machine-actionable future in scientific knowledge dissemination and discovery.</p>
<h2>References</h2>
<p>[<a id="note1" href="../index.html%3Fp=18277.html#ref1">1</a>] Bush, V. (1945). As We May Think. <em>The Atlantic</em>. Retrieved from <a href="https://www.theatlantic.com/magazine/archive/1945/07/as-we-may-think/303881/">https://www.theatlantic.com/magazine/archive/1945/07/as-we-may-think/303881/</a></p>
<p>[<a id="note2" href="../index.html%3Fp=18277.html#ref2">2</a>] Wilkinson MD, Dumontier M, Aalbersberg IJ, Appleton G, Axton M, Baak A, Blomberg N, Boiten JW, da Silva Santos LB, Bourne PE, et al. 2016. The FAIR Guiding Principles for Scientific Data Management and Stewardship. <em>Scientific Data.</em> 3(1):1–9.</p>
<p>[<a id="note3" href="../index.html%3Fp=18277.html#ref3">3</a>] Auer S, Oelen A, Haris M, Stocker M, D’Souza J, Farfar KE, Vogt L, Prinz M, Wiens V, Jaradeh MY. 2020. Improving Access to Scientific Literature with Knowledge Graphs. <em>Bibliothek Forschung und Praxis.</em> 44(3):516–529.</p>
<p>[<a id="note4" href="../index.html%3Fp=18277.html#ref4">4</a>] Stocker M, Oelen A, Jaradeh MY, Haris M, Arab Oghli O, Heidari G, Hussein H, Lorenz AL, Kabenamualu S, Farfar KE, Prinz M, Karras O, D’Souza J, Vogt L, Auer S. 2023. FAIR scientific information with the Open Research Knowledge Graph. <em>FAIR Connect.</em> 1(1):19–21. <a href="https://doi.org/10.3233/fc-221513.">https://doi.org/10.3233/fc-221513.</a></p>
<p>[<a id="note5" href="../index.html%3Fp=18277.html#ref5">5</a>] D&#8217;Souza J, Hussein H, Evans J, Vogt L, Karras O, Ilangovan V, Lorenz AL, Auer S. 2024. Quality Assessment of Research Comparisons in the Open Research Knowledge Graph: A Case Study. <em>JLIS.it.</em> 15(1):126–143.</p>
<p>[<a id="note6" href="../index.html%3Fp=18277.html#ref6">6</a>] Fourrier, C. (2023). 2023, Year of Open LLMs. <em>Hugging Face.</em> Retrieved from<a href="https://huggingface.co/blog/2023-in-llms"> https://huggingface.co/blog/2023-in-llms</a></p>
<p>[<a id="note7" href="../index.html%3Fp=18277.html#ref7">7</a>] Cyganiak, R., Wood, D., &amp; Lanthaler, M. (2014). RDF 1.1 Concepts and Abstract Syntax. <em>World Wide Web Consortium (W3C)</em>. Retrieved from <a href="https://www.w3.org/TR/rdf11-concepts/">https://www.w3.org/TR/rdf11-concepts/</a></p>
<p>[<a id="note8" href="../index.html%3Fp=18277.html#ref8">8</a>] Hugging Face. (n.d.). Model Cards. Retrieved from <a href="https://huggingface.co/docs/hub/en/model-cards">https://huggingface.co/docs/hub/en/model-cards</a></p>
<h2 class="abouttheauthor">About the Author</h2>
<p>Dr. Jennifer D`Souza, TIB Leibniz Information Centre for Science and Technology, (M.Sc. in Computer Science, University of Texas at Dallas, 2010 and Ph.D. in Computer Science, University of Texas at Dallas, 2015). Dr. D’Souza is a senior postdoctoral researcher at TIB Leibniz Information Centre for Science and Technology, specializing in AI, NLP, and scientific knowledge extraction and organization. She leads the NLP-AI aspect of the Open Research Knowledge Graph (ORKG) and heads the SCINEXT project, advancing neuro-symbolic AI and NLP for scientific innovation extraction, funded by the German Ministry of Education and Research (BMBF). Her projects develop knowledge extraction and organization services, recently using generative AI, aimed at enhancing the strategic use of science and innovation to bolster societal R&amp;D cycles.</p>
					</div>
														</div>
				<!-- You can start editing here. -->

<div class="comments">
	<p class="subscriptionlinks">Subscribe to comments: <a href="18277/feed">For this article</a> | <a href="http://feeds.feedburner.com/c4lj/comments">For all articles</a></p>

			<!-- If comments are open, but there are no comments. -->

	 

<h3 id="respond">Leave a Reply</h3>


<form action="https://journal.code4lib.org/wp-comments-post.php" method="post" id="commentform">


<p><input type="text" name="author" id="author" value=""/>
<label for="author">Name (required)</label></p>

<p><input type="text" name="email" id="email" value="" />
<label for="email">Mail (will not be published) (required)</label></p>

<p><input type="text" name="url" id="url" value="" />
<label for="url">Website</label></p>


<p><textarea autocomplete="new-password"  aria-label="Comment box" id="f127f6ccbe"  name="f127f6ccbe"   cols="50" rows="10"></textarea><textarea id="comment" aria-label="hp-comment" aria-hidden="true" name="comment" autocomplete="new-password" style="padding:0 !important;clip:rect(1px, 1px, 1px, 1px) !important;position:absolute !important;white-space:nowrap !important;height:1px !important;width:1px !important;overflow:hidden !important;" tabindex="-1"></textarea><script data-noptimize>document.getElementById("comment").setAttribute( "id", "a33f447372322808e795bbdc9c180ecf" );document.getElementById("f127f6ccbe").setAttribute( "id", "comment" );</script></p>

<p><input name="submit" type="submit" id="submit"  value="Submit Comment" />
<input type="hidden" name="comment_post_ID" value="18277" />
</p>
<p style="display: none;"><input type="hidden" id="akismet_comment_nonce" name="akismet_comment_nonce" value="cabdea6a72" /></p><p style="display: none !important;" class="akismet-fields-container" data-prefix="ak_"><label>&#916;<textarea name="ak_hp_textarea" cols="45" rows="8" maxlength="100"></textarea></label><input type="hidden" id="ak_js_1" name="ak_js" value="230"/><script>document.getElementById( "ak_js_1" ).setAttribute( "value", ( new Date() ).getTime() );</script></p>
</form>


</div>
							</div>

			<div id="meta">
				<div id="issn">
					<p>ISSN 1940-5758</p>
				</div>
				<div class="search-sidebar">
				<form method="get" id="searchform" action="../index.html">
					<div>
						<input type="text" value="" aria-labelledby="searchsubmit" name="s" id="s" />
						<input type="submit" value="Search" id="searchsubmit"/>
					</div>
				</form>
				</div>
				<div id="archives">
					<h2>Current Issue</h2>
						<ul>
							<li><a href="../issues/issues/issue60.html">Issue 60, 2025-04-14</a></li>
						</ul>

					<h2>Previous Issues</h2>
						<ul>
              <li><a href="../issues/issues/issue59.html">Issue 59, 2024-10-07</a></li><li><a href="../issues/issues/issue58.html">Issue 58, 2023-12-04</a></li><li><a href="../issues/issues/issue57.html">Issue 57, 2023-08-29</a></li><li><a href="../issues/issues/issue56.html">Issue 56, 2023-04-21</a></li>              <li><a href="../index.html%3Fp=2476.html">Older Issues</a></li>
						</ul>
				</div>
				<div id="forauthors">
					<h2>For Authors</h2>
					<ul>
						<li class="page_item page-item-4"><a href="../index.html%3Fp=4.html">Call for Submissions</a></li>
<li class="page_item page-item-7"><a href="../index.html%3Fp=7.html">Article Guidelines</a></li>
					</ul>
				</div>
			</div>
						<div id="footer">
				<p id="login"><a href="../wp-login.php.html">Log in</a></p>
				<p id="copyright">This work is licensed under a <a rel="license" href="http://creativecommons.org/licenses/by/3.0/us/">Creative Commons Attribution 3.0 United States License</a>.<br /><a rel="license" href="http://creativecommons.org/licenses/by/3.0/us/"><img alt="Creative Commons License" src="http://i.creativecommons.org/l/by/3.0/us/80x15.png" /></a></p>
			</div>
			<script type="speculationrules">
{"prefetch":[{"source":"document","where":{"and":[{"href_matches":"\/*"},{"not":{"href_matches":["\/wp-*.php","\/wp-admin\/*","\/wp-content\/uploads\/*","\/wp-content\/*","\/wp-content\/plugins\/*","\/wp-content\/themes\/c4lj-theme\/*","\/*\\?(.+)"]}},{"not":{"selector_matches":"a[rel~=\"nofollow\"]"}},{"not":{"selector_matches":".no-prefetch, .no-prefetch a"}}]},"eagerness":"conservative"}]}
</script>
<script defer type="text/javascript" src="../wp-content/plugins/akismet/_inc/akismet-frontend.js%3Fver=1748382734" id="akismet-frontend-js"></script>
		</div>
	</body>
</html>
